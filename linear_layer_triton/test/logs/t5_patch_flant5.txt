[2024-01-06 07:53:36,349] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)



def forward(self, input_ids : torch.Tensor, labels : torch.Tensor):
    size = input_ids.size()
    getitem = size[-1]
    view = input_ids.view(-1, getitem);  input_ids = getitem = None
    shared = self.shared(view);  view = None
    getitem_1 = size[0]
    getitem_2 = size[1];  size = None
    getattr_1 = shared.device
    ones = torch.ones(getitem_1, getitem_2, device = getattr_1);  getitem_1 = getitem_2 = getattr_1 = None
    dim = ones.dim()
    eq = dim == 2;  dim = None
    dim_1 = ones.dim()
    eq_1 = dim_1 == 3;  dim_1 = None
    dim_2 = ones.dim()
    eq_2 = dim_2 == 2;  dim_2 = None
    getitem_3 = ones[(slice(None, None, None), None, None, slice(None, None, None))];  ones = None
    to = getitem_3.to(dtype = torch.float16);  getitem_3 = None
    sub = 1.0 - to;  to = None
    mul = sub * -65504.0;  sub = None
    encoder_dropout = self.encoder.dropout(shared);  shared = None
    to_1 = encoder_dropout.to(torch.float32)
    pow_1 = to_1.pow(2);  to_1 = None
    mean = pow_1.mean(-1, keepdim = True);  pow_1 = None
    add = mean + 1e-06;  mean = None
    rsqrt = torch.rsqrt(add);  add = None
    mul_1 = encoder_dropout * rsqrt;  rsqrt = None
    encoder_block_0_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "0").layer, "0").layer_norm.weight
    getattr_2 = encoder_block_0_layer_0_layer_norm_weight.dtype
    eq_3 = getattr_2 == torch.float16;  getattr_2 = None
    getattr_3 = encoder_block_0_layer_0_layer_norm_weight.dtype
    to_2 = mul_1.to(getattr_3);  mul_1 = getattr_3 = None
    mul_2 = encoder_block_0_layer_0_layer_norm_weight * to_2;  encoder_block_0_layer_0_layer_norm_weight = to_2 = None
    size_1 = mul_2.size()
    getitem_4 = size_1[slice(None, 2, None)];  size_1 = None
    getitem_5 = getitem_4[0]
    getitem_6 = getitem_4[1];  getitem_4 = None
    encoder_block_0_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.q(mul_2)
    view_1 = encoder_block_0_layer_0_self_attention_q.view(getitem_5, -1, 6, 64);  encoder_block_0_layer_0_self_attention_q = None
    transpose = view_1.transpose(1, 2);  view_1 = None
    encoder_block_0_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.k(mul_2)
    view_2 = encoder_block_0_layer_0_self_attention_k.view(getitem_5, -1, 6, 64);  encoder_block_0_layer_0_self_attention_k = None
    transpose_1 = view_2.transpose(1, 2);  view_2 = None
    encoder_block_0_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.v(mul_2);  mul_2 = None
    view_3 = encoder_block_0_layer_0_self_attention_v.view(getitem_5, -1, 6, 64);  encoder_block_0_layer_0_self_attention_v = None
    transpose_2 = view_3.transpose(1, 2);  view_3 = None
    transpose_3 = transpose_1.transpose(3, 2);  transpose_1 = None
    matmul = torch.matmul(transpose, transpose_3);  transpose = transpose_3 = None
    getattr_4 = matmul.device
    arange = torch.arange(getitem_6, dtype = torch.int64, device = getattr_4)
    getitem_7 = arange[(slice(None, None, None), None)];  arange = None
    arange_1 = torch.arange(getitem_6, dtype = torch.int64, device = getattr_4);  getitem_6 = getattr_4 = None
    getitem_8 = arange_1[(None, slice(None, None, None))];  arange_1 = None
    sub_1 = getitem_8 - getitem_7;  getitem_8 = getitem_7 = None
    gt = sub_1 > 0
    to_3 = gt.to(torch.int64);  gt = None
    mul_3 = to_3 * 16;  to_3 = None
    add_1 = 0 + mul_3;  mul_3 = None
    abs_1 = torch.abs(sub_1);  sub_1 = None
    lt = abs_1 < 8
    float_1 = abs_1.float()
    truediv = float_1 / 8;  float_1 = None
    log = torch.log(truediv);  truediv = None
    truediv_1 = log / 2.772588722239781;  log = None
    mul_4 = truediv_1 * 8;  truediv_1 = None
    to_4 = mul_4.to(torch.int64);  mul_4 = None
    add_2 = 8 + to_4;  to_4 = None
    full_like = torch.full_like(add_2, 15)
    min_1 = torch.min(add_2, full_like);  add_2 = full_like = None
    where = torch.where(lt, abs_1, min_1);  lt = abs_1 = min_1 = None
    add_3 = add_1 + where;  add_1 = where = None
    encoder_block_0_layer_0_self_attention_relative_attention_bias = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.relative_attention_bias(add_3);  add_3 = None
    permute = encoder_block_0_layer_0_self_attention_relative_attention_bias.permute([2, 0, 1]);  encoder_block_0_layer_0_self_attention_relative_attention_bias = None
    unsqueeze = permute.unsqueeze(0);  permute = None
    add_4 = unsqueeze + mul;  unsqueeze = mul = None
    add_5 = matmul + add_4;  matmul = None
    float_2 = add_5.float()
    softmax = torch.nn.functional.softmax(float_2, dim = -1, _stacklevel = 3, dtype = None);  float_2 = None
    type_as = softmax.type_as(add_5);  softmax = add_5 = None
    dropout = torch.nn.functional.dropout(type_as, p = 0.1, training = False, inplace = False);  type_as = None
    matmul_1 = torch.matmul(dropout, transpose_2);  dropout = transpose_2 = None
    transpose_4 = matmul_1.transpose(1, 2);  matmul_1 = None
    contiguous = transpose_4.contiguous();  transpose_4 = None
    view_4 = contiguous.view(getitem_5, -1, 384);  contiguous = getitem_5 = None
    encoder_block_0_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.o(view_4);  view_4 = None
    encoder_block_0_layer_0_dropout = getattr(getattr(self.encoder.block, "0").layer, "0").dropout(encoder_block_0_layer_0_self_attention_o);  encoder_block_0_layer_0_self_attention_o = None
    add_6 = encoder_dropout + encoder_block_0_layer_0_dropout;  encoder_dropout = encoder_block_0_layer_0_dropout = None
    getattr_5 = add_6.dtype
    eq_4 = getattr_5 == torch.float16;  getattr_5 = None
    to_5 = add_6.to(torch.float32)
    pow_2 = to_5.pow(2);  to_5 = None
    mean_1 = pow_2.mean(-1, keepdim = True);  pow_2 = None
    add_7 = mean_1 + 1e-06;  mean_1 = None
    rsqrt_1 = torch.rsqrt(add_7);  add_7 = None
    mul_5 = add_6 * rsqrt_1;  rsqrt_1 = None
    encoder_block_0_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "0").layer, "1").layer_norm.weight
    getattr_6 = encoder_block_0_layer_1_layer_norm_weight.dtype
    eq_5 = getattr_6 == torch.float16;  getattr_6 = None
    getattr_7 = encoder_block_0_layer_1_layer_norm_weight.dtype
    to_6 = mul_5.to(getattr_7);  mul_5 = getattr_7 = None
    mul_6 = encoder_block_0_layer_1_layer_norm_weight * to_6;  encoder_block_0_layer_1_layer_norm_weight = to_6 = None
    encoder_block_0_layer_1_dense_relu_dense_wi_0 = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.wi_0(mul_6)
    mul_7 = 0.5 * encoder_block_0_layer_1_dense_relu_dense_wi_0
    pow_3 = torch.pow(encoder_block_0_layer_1_dense_relu_dense_wi_0, 3.0)
    mul_8 = 0.044715 * pow_3;  pow_3 = None
    add_8 = encoder_block_0_layer_1_dense_relu_dense_wi_0 + mul_8;  encoder_block_0_layer_1_dense_relu_dense_wi_0 = mul_8 = None
    mul_9 = 0.7978845608028654 * add_8;  add_8 = None
    tanh = torch.tanh(mul_9);  mul_9 = None
    add_9 = 1.0 + tanh;  tanh = None
    mul_10 = mul_7 * add_9;  mul_7 = add_9 = None
    encoder_block_0_layer_1_dense_relu_dense_wi_1 = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.wi_1(mul_6);  mul_6 = None
    mul_11 = mul_10 * encoder_block_0_layer_1_dense_relu_dense_wi_1;  mul_10 = encoder_block_0_layer_1_dense_relu_dense_wi_1 = None
    encoder_block_0_layer_1_dense_relu_dense_dropout = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.dropout(mul_11);  mul_11 = None
    encoder_block_0_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.wo.weight
    encoder_block_0_layer_1_dense_relu_dense_wo = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.wo(encoder_block_0_layer_1_dense_relu_dense_dropout);  encoder_block_0_layer_1_dense_relu_dense_dropout = None
    encoder_block_0_layer_1_dropout = getattr(getattr(self.encoder.block, "0").layer, "1").dropout(encoder_block_0_layer_1_dense_relu_dense_wo);  encoder_block_0_layer_1_dense_relu_dense_wo = None
    add_10 = add_6 + encoder_block_0_layer_1_dropout;  add_6 = encoder_block_0_layer_1_dropout = None
    getattr_8 = add_10.dtype
    eq_6 = getattr_8 == torch.float16;  getattr_8 = None
    to_7 = add_10.to(torch.float32)
    pow_4 = to_7.pow(2);  to_7 = None
    mean_2 = pow_4.mean(-1, keepdim = True);  pow_4 = None
    add_11 = mean_2 + 1e-06;  mean_2 = None
    rsqrt_2 = torch.rsqrt(add_11);  add_11 = None
    mul_12 = add_10 * rsqrt_2;  rsqrt_2 = None
    encoder_block_1_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "1").layer, "0").layer_norm.weight
    getattr_9 = encoder_block_1_layer_0_layer_norm_weight.dtype
    eq_7 = getattr_9 == torch.float16;  getattr_9 = None
    getattr_10 = encoder_block_1_layer_0_layer_norm_weight.dtype
    to_8 = mul_12.to(getattr_10);  mul_12 = getattr_10 = None
    mul_13 = encoder_block_1_layer_0_layer_norm_weight * to_8;  encoder_block_1_layer_0_layer_norm_weight = to_8 = None
    size_2 = mul_13.size()
    getitem_9 = size_2[slice(None, 2, None)];  size_2 = None
    getitem_10 = getitem_9[0]
    getitem_11 = getitem_9[1];  getitem_9 = None
    encoder_block_1_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.q(mul_13)
    view_5 = encoder_block_1_layer_0_self_attention_q.view(getitem_10, -1, 6, 64);  encoder_block_1_layer_0_self_attention_q = None
    transpose_5 = view_5.transpose(1, 2);  view_5 = None
    encoder_block_1_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.k(mul_13)
    view_6 = encoder_block_1_layer_0_self_attention_k.view(getitem_10, -1, 6, 64);  encoder_block_1_layer_0_self_attention_k = None
    transpose_6 = view_6.transpose(1, 2);  view_6 = None
    encoder_block_1_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.v(mul_13);  mul_13 = None
    view_7 = encoder_block_1_layer_0_self_attention_v.view(getitem_10, -1, 6, 64);  encoder_block_1_layer_0_self_attention_v = None
    transpose_7 = view_7.transpose(1, 2);  view_7 = None
    transpose_8 = transpose_6.transpose(3, 2);  transpose_6 = None
    matmul_2 = torch.matmul(transpose_5, transpose_8);  transpose_5 = transpose_8 = None
    add_12 = matmul_2 + add_4;  matmul_2 = None
    float_3 = add_12.float()
    softmax_1 = torch.nn.functional.softmax(float_3, dim = -1, _stacklevel = 3, dtype = None);  float_3 = None
    type_as_1 = softmax_1.type_as(add_12);  softmax_1 = add_12 = None
    dropout_1 = torch.nn.functional.dropout(type_as_1, p = 0.1, training = False, inplace = False);  type_as_1 = None
    matmul_3 = torch.matmul(dropout_1, transpose_7);  dropout_1 = transpose_7 = None
    transpose_9 = matmul_3.transpose(1, 2);  matmul_3 = None
    contiguous_1 = transpose_9.contiguous();  transpose_9 = None
    view_8 = contiguous_1.view(getitem_10, -1, 384);  contiguous_1 = getitem_10 = None
    encoder_block_1_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.o(view_8);  view_8 = None
    encoder_block_1_layer_0_dropout = getattr(getattr(self.encoder.block, "1").layer, "0").dropout(encoder_block_1_layer_0_self_attention_o);  encoder_block_1_layer_0_self_attention_o = None
    add_13 = add_10 + encoder_block_1_layer_0_dropout;  add_10 = encoder_block_1_layer_0_dropout = None
    getattr_11 = add_13.dtype
    eq_8 = getattr_11 == torch.float16;  getattr_11 = None
    to_9 = add_13.to(torch.float32)
    pow_5 = to_9.pow(2);  to_9 = None
    mean_3 = pow_5.mean(-1, keepdim = True);  pow_5 = None
    add_14 = mean_3 + 1e-06;  mean_3 = None
    rsqrt_3 = torch.rsqrt(add_14);  add_14 = None
    mul_14 = add_13 * rsqrt_3;  rsqrt_3 = None
    encoder_block_1_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "1").layer, "1").layer_norm.weight
    getattr_12 = encoder_block_1_layer_1_layer_norm_weight.dtype
    eq_9 = getattr_12 == torch.float16;  getattr_12 = None
    getattr_13 = encoder_block_1_layer_1_layer_norm_weight.dtype
    to_10 = mul_14.to(getattr_13);  mul_14 = getattr_13 = None
    mul_15 = encoder_block_1_layer_1_layer_norm_weight * to_10;  encoder_block_1_layer_1_layer_norm_weight = to_10 = None
    encoder_block_1_layer_1_dense_relu_dense_wi_0 = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.wi_0(mul_15)
    mul_16 = 0.5 * encoder_block_1_layer_1_dense_relu_dense_wi_0
    pow_6 = torch.pow(encoder_block_1_layer_1_dense_relu_dense_wi_0, 3.0)
    mul_17 = 0.044715 * pow_6;  pow_6 = None
    add_15 = encoder_block_1_layer_1_dense_relu_dense_wi_0 + mul_17;  encoder_block_1_layer_1_dense_relu_dense_wi_0 = mul_17 = None
    mul_18 = 0.7978845608028654 * add_15;  add_15 = None
    tanh_1 = torch.tanh(mul_18);  mul_18 = None
    add_16 = 1.0 + tanh_1;  tanh_1 = None
    mul_19 = mul_16 * add_16;  mul_16 = add_16 = None
    encoder_block_1_layer_1_dense_relu_dense_wi_1 = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.wi_1(mul_15);  mul_15 = None
    mul_20 = mul_19 * encoder_block_1_layer_1_dense_relu_dense_wi_1;  mul_19 = encoder_block_1_layer_1_dense_relu_dense_wi_1 = None
    encoder_block_1_layer_1_dense_relu_dense_dropout = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.dropout(mul_20);  mul_20 = None
    encoder_block_1_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.wo.weight
    encoder_block_1_layer_1_dense_relu_dense_wo = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.wo(encoder_block_1_layer_1_dense_relu_dense_dropout);  encoder_block_1_layer_1_dense_relu_dense_dropout = None
    encoder_block_1_layer_1_dropout = getattr(getattr(self.encoder.block, "1").layer, "1").dropout(encoder_block_1_layer_1_dense_relu_dense_wo);  encoder_block_1_layer_1_dense_relu_dense_wo = None
    add_17 = add_13 + encoder_block_1_layer_1_dropout;  add_13 = encoder_block_1_layer_1_dropout = None
    getattr_14 = add_17.dtype
    eq_10 = getattr_14 == torch.float16;  getattr_14 = None
    to_11 = add_17.to(torch.float32)
    pow_7 = to_11.pow(2);  to_11 = None
    mean_4 = pow_7.mean(-1, keepdim = True);  pow_7 = None
    add_18 = mean_4 + 1e-06;  mean_4 = None
    rsqrt_4 = torch.rsqrt(add_18);  add_18 = None
    mul_21 = add_17 * rsqrt_4;  rsqrt_4 = None
    encoder_block_2_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "2").layer, "0").layer_norm.weight
    getattr_15 = encoder_block_2_layer_0_layer_norm_weight.dtype
    eq_11 = getattr_15 == torch.float16;  getattr_15 = None
    getattr_16 = encoder_block_2_layer_0_layer_norm_weight.dtype
    to_12 = mul_21.to(getattr_16);  mul_21 = getattr_16 = None
    mul_22 = encoder_block_2_layer_0_layer_norm_weight * to_12;  encoder_block_2_layer_0_layer_norm_weight = to_12 = None
    size_3 = mul_22.size()
    getitem_12 = size_3[slice(None, 2, None)];  size_3 = None
    getitem_13 = getitem_12[0]
    getitem_14 = getitem_12[1];  getitem_12 = None
    encoder_block_2_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.q(mul_22)
    view_9 = encoder_block_2_layer_0_self_attention_q.view(getitem_13, -1, 6, 64);  encoder_block_2_layer_0_self_attention_q = None
    transpose_10 = view_9.transpose(1, 2);  view_9 = None
    encoder_block_2_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.k(mul_22)
    view_10 = encoder_block_2_layer_0_self_attention_k.view(getitem_13, -1, 6, 64);  encoder_block_2_layer_0_self_attention_k = None
    transpose_11 = view_10.transpose(1, 2);  view_10 = None
    encoder_block_2_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.v(mul_22);  mul_22 = None
    view_11 = encoder_block_2_layer_0_self_attention_v.view(getitem_13, -1, 6, 64);  encoder_block_2_layer_0_self_attention_v = None
    transpose_12 = view_11.transpose(1, 2);  view_11 = None
    transpose_13 = transpose_11.transpose(3, 2);  transpose_11 = None
    matmul_4 = torch.matmul(transpose_10, transpose_13);  transpose_10 = transpose_13 = None
    add_19 = matmul_4 + add_4;  matmul_4 = None
    float_4 = add_19.float()
    softmax_2 = torch.nn.functional.softmax(float_4, dim = -1, _stacklevel = 3, dtype = None);  float_4 = None
    type_as_2 = softmax_2.type_as(add_19);  softmax_2 = add_19 = None
    dropout_2 = torch.nn.functional.dropout(type_as_2, p = 0.1, training = False, inplace = False);  type_as_2 = None
    matmul_5 = torch.matmul(dropout_2, transpose_12);  dropout_2 = transpose_12 = None
    transpose_14 = matmul_5.transpose(1, 2);  matmul_5 = None
    contiguous_2 = transpose_14.contiguous();  transpose_14 = None
    view_12 = contiguous_2.view(getitem_13, -1, 384);  contiguous_2 = getitem_13 = None
    encoder_block_2_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.o(view_12);  view_12 = None
    encoder_block_2_layer_0_dropout = getattr(getattr(self.encoder.block, "2").layer, "0").dropout(encoder_block_2_layer_0_self_attention_o);  encoder_block_2_layer_0_self_attention_o = None
    add_20 = add_17 + encoder_block_2_layer_0_dropout;  add_17 = encoder_block_2_layer_0_dropout = None
    getattr_17 = add_20.dtype
    eq_12 = getattr_17 == torch.float16;  getattr_17 = None
    to_13 = add_20.to(torch.float32)
    pow_8 = to_13.pow(2);  to_13 = None
    mean_5 = pow_8.mean(-1, keepdim = True);  pow_8 = None
    add_21 = mean_5 + 1e-06;  mean_5 = None
    rsqrt_5 = torch.rsqrt(add_21);  add_21 = None
    mul_23 = add_20 * rsqrt_5;  rsqrt_5 = None
    encoder_block_2_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "2").layer, "1").layer_norm.weight
    getattr_18 = encoder_block_2_layer_1_layer_norm_weight.dtype
    eq_13 = getattr_18 == torch.float16;  getattr_18 = None
    getattr_19 = encoder_block_2_layer_1_layer_norm_weight.dtype
    to_14 = mul_23.to(getattr_19);  mul_23 = getattr_19 = None
    mul_24 = encoder_block_2_layer_1_layer_norm_weight * to_14;  encoder_block_2_layer_1_layer_norm_weight = to_14 = None
    encoder_block_2_layer_1_dense_relu_dense_wi_0 = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.wi_0(mul_24)
    mul_25 = 0.5 * encoder_block_2_layer_1_dense_relu_dense_wi_0
    pow_9 = torch.pow(encoder_block_2_layer_1_dense_relu_dense_wi_0, 3.0)
    mul_26 = 0.044715 * pow_9;  pow_9 = None
    add_22 = encoder_block_2_layer_1_dense_relu_dense_wi_0 + mul_26;  encoder_block_2_layer_1_dense_relu_dense_wi_0 = mul_26 = None
    mul_27 = 0.7978845608028654 * add_22;  add_22 = None
    tanh_2 = torch.tanh(mul_27);  mul_27 = None
    add_23 = 1.0 + tanh_2;  tanh_2 = None
    mul_28 = mul_25 * add_23;  mul_25 = add_23 = None
    encoder_block_2_layer_1_dense_relu_dense_wi_1 = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.wi_1(mul_24);  mul_24 = None
    mul_29 = mul_28 * encoder_block_2_layer_1_dense_relu_dense_wi_1;  mul_28 = encoder_block_2_layer_1_dense_relu_dense_wi_1 = None
    encoder_block_2_layer_1_dense_relu_dense_dropout = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.dropout(mul_29);  mul_29 = None
    encoder_block_2_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.wo.weight
    encoder_block_2_layer_1_dense_relu_dense_wo = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.wo(encoder_block_2_layer_1_dense_relu_dense_dropout);  encoder_block_2_layer_1_dense_relu_dense_dropout = None
    encoder_block_2_layer_1_dropout = getattr(getattr(self.encoder.block, "2").layer, "1").dropout(encoder_block_2_layer_1_dense_relu_dense_wo);  encoder_block_2_layer_1_dense_relu_dense_wo = None
    add_24 = add_20 + encoder_block_2_layer_1_dropout;  add_20 = encoder_block_2_layer_1_dropout = None
    getattr_20 = add_24.dtype
    eq_14 = getattr_20 == torch.float16;  getattr_20 = None
    to_15 = add_24.to(torch.float32)
    pow_10 = to_15.pow(2);  to_15 = None
    mean_6 = pow_10.mean(-1, keepdim = True);  pow_10 = None
    add_25 = mean_6 + 1e-06;  mean_6 = None
    rsqrt_6 = torch.rsqrt(add_25);  add_25 = None
    mul_30 = add_24 * rsqrt_6;  rsqrt_6 = None
    encoder_block_3_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "3").layer, "0").layer_norm.weight
    getattr_21 = encoder_block_3_layer_0_layer_norm_weight.dtype
    eq_15 = getattr_21 == torch.float16;  getattr_21 = None
    getattr_22 = encoder_block_3_layer_0_layer_norm_weight.dtype
    to_16 = mul_30.to(getattr_22);  mul_30 = getattr_22 = None
    mul_31 = encoder_block_3_layer_0_layer_norm_weight * to_16;  encoder_block_3_layer_0_layer_norm_weight = to_16 = None
    size_4 = mul_31.size()
    getitem_15 = size_4[slice(None, 2, None)];  size_4 = None
    getitem_16 = getitem_15[0]
    getitem_17 = getitem_15[1];  getitem_15 = None
    encoder_block_3_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.q(mul_31)
    view_13 = encoder_block_3_layer_0_self_attention_q.view(getitem_16, -1, 6, 64);  encoder_block_3_layer_0_self_attention_q = None
    transpose_15 = view_13.transpose(1, 2);  view_13 = None
    encoder_block_3_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.k(mul_31)
    view_14 = encoder_block_3_layer_0_self_attention_k.view(getitem_16, -1, 6, 64);  encoder_block_3_layer_0_self_attention_k = None
    transpose_16 = view_14.transpose(1, 2);  view_14 = None
    encoder_block_3_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.v(mul_31);  mul_31 = None
    view_15 = encoder_block_3_layer_0_self_attention_v.view(getitem_16, -1, 6, 64);  encoder_block_3_layer_0_self_attention_v = None
    transpose_17 = view_15.transpose(1, 2);  view_15 = None
    transpose_18 = transpose_16.transpose(3, 2);  transpose_16 = None
    matmul_6 = torch.matmul(transpose_15, transpose_18);  transpose_15 = transpose_18 = None
    add_26 = matmul_6 + add_4;  matmul_6 = None
    float_5 = add_26.float()
    softmax_3 = torch.nn.functional.softmax(float_5, dim = -1, _stacklevel = 3, dtype = None);  float_5 = None
    type_as_3 = softmax_3.type_as(add_26);  softmax_3 = add_26 = None
    dropout_3 = torch.nn.functional.dropout(type_as_3, p = 0.1, training = False, inplace = False);  type_as_3 = None
    matmul_7 = torch.matmul(dropout_3, transpose_17);  dropout_3 = transpose_17 = None
    transpose_19 = matmul_7.transpose(1, 2);  matmul_7 = None
    contiguous_3 = transpose_19.contiguous();  transpose_19 = None
    view_16 = contiguous_3.view(getitem_16, -1, 384);  contiguous_3 = getitem_16 = None
    encoder_block_3_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.o(view_16);  view_16 = None
    encoder_block_3_layer_0_dropout = getattr(getattr(self.encoder.block, "3").layer, "0").dropout(encoder_block_3_layer_0_self_attention_o);  encoder_block_3_layer_0_self_attention_o = None
    add_27 = add_24 + encoder_block_3_layer_0_dropout;  add_24 = encoder_block_3_layer_0_dropout = None
    getattr_23 = add_27.dtype
    eq_16 = getattr_23 == torch.float16;  getattr_23 = None
    to_17 = add_27.to(torch.float32)
    pow_11 = to_17.pow(2);  to_17 = None
    mean_7 = pow_11.mean(-1, keepdim = True);  pow_11 = None
    add_28 = mean_7 + 1e-06;  mean_7 = None
    rsqrt_7 = torch.rsqrt(add_28);  add_28 = None
    mul_32 = add_27 * rsqrt_7;  rsqrt_7 = None
    encoder_block_3_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "3").layer, "1").layer_norm.weight
    getattr_24 = encoder_block_3_layer_1_layer_norm_weight.dtype
    eq_17 = getattr_24 == torch.float16;  getattr_24 = None
    getattr_25 = encoder_block_3_layer_1_layer_norm_weight.dtype
    to_18 = mul_32.to(getattr_25);  mul_32 = getattr_25 = None
    mul_33 = encoder_block_3_layer_1_layer_norm_weight * to_18;  encoder_block_3_layer_1_layer_norm_weight = to_18 = None
    encoder_block_3_layer_1_dense_relu_dense_wi_0 = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.wi_0(mul_33)
    mul_34 = 0.5 * encoder_block_3_layer_1_dense_relu_dense_wi_0
    pow_12 = torch.pow(encoder_block_3_layer_1_dense_relu_dense_wi_0, 3.0)
    mul_35 = 0.044715 * pow_12;  pow_12 = None
    add_29 = encoder_block_3_layer_1_dense_relu_dense_wi_0 + mul_35;  encoder_block_3_layer_1_dense_relu_dense_wi_0 = mul_35 = None
    mul_36 = 0.7978845608028654 * add_29;  add_29 = None
    tanh_3 = torch.tanh(mul_36);  mul_36 = None
    add_30 = 1.0 + tanh_3;  tanh_3 = None
    mul_37 = mul_34 * add_30;  mul_34 = add_30 = None
    encoder_block_3_layer_1_dense_relu_dense_wi_1 = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.wi_1(mul_33);  mul_33 = None
    mul_38 = mul_37 * encoder_block_3_layer_1_dense_relu_dense_wi_1;  mul_37 = encoder_block_3_layer_1_dense_relu_dense_wi_1 = None
    encoder_block_3_layer_1_dense_relu_dense_dropout = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.dropout(mul_38);  mul_38 = None
    encoder_block_3_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.wo.weight
    encoder_block_3_layer_1_dense_relu_dense_wo = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.wo(encoder_block_3_layer_1_dense_relu_dense_dropout);  encoder_block_3_layer_1_dense_relu_dense_dropout = None
    encoder_block_3_layer_1_dropout = getattr(getattr(self.encoder.block, "3").layer, "1").dropout(encoder_block_3_layer_1_dense_relu_dense_wo);  encoder_block_3_layer_1_dense_relu_dense_wo = None
    add_31 = add_27 + encoder_block_3_layer_1_dropout;  add_27 = encoder_block_3_layer_1_dropout = None
    getattr_26 = add_31.dtype
    eq_18 = getattr_26 == torch.float16;  getattr_26 = None
    to_19 = add_31.to(torch.float32)
    pow_13 = to_19.pow(2);  to_19 = None
    mean_8 = pow_13.mean(-1, keepdim = True);  pow_13 = None
    add_32 = mean_8 + 1e-06;  mean_8 = None
    rsqrt_8 = torch.rsqrt(add_32);  add_32 = None
    mul_39 = add_31 * rsqrt_8;  rsqrt_8 = None
    encoder_block_4_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "4").layer, "0").layer_norm.weight
    getattr_27 = encoder_block_4_layer_0_layer_norm_weight.dtype
    eq_19 = getattr_27 == torch.float16;  getattr_27 = None
    getattr_28 = encoder_block_4_layer_0_layer_norm_weight.dtype
    to_20 = mul_39.to(getattr_28);  mul_39 = getattr_28 = None
    mul_40 = encoder_block_4_layer_0_layer_norm_weight * to_20;  encoder_block_4_layer_0_layer_norm_weight = to_20 = None
    size_5 = mul_40.size()
    getitem_18 = size_5[slice(None, 2, None)];  size_5 = None
    getitem_19 = getitem_18[0]
    getitem_20 = getitem_18[1];  getitem_18 = None
    encoder_block_4_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.q(mul_40)
    view_17 = encoder_block_4_layer_0_self_attention_q.view(getitem_19, -1, 6, 64);  encoder_block_4_layer_0_self_attention_q = None
    transpose_20 = view_17.transpose(1, 2);  view_17 = None
    encoder_block_4_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.k(mul_40)
    view_18 = encoder_block_4_layer_0_self_attention_k.view(getitem_19, -1, 6, 64);  encoder_block_4_layer_0_self_attention_k = None
    transpose_21 = view_18.transpose(1, 2);  view_18 = None
    encoder_block_4_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.v(mul_40);  mul_40 = None
    view_19 = encoder_block_4_layer_0_self_attention_v.view(getitem_19, -1, 6, 64);  encoder_block_4_layer_0_self_attention_v = None
    transpose_22 = view_19.transpose(1, 2);  view_19 = None
    transpose_23 = transpose_21.transpose(3, 2);  transpose_21 = None
    matmul_8 = torch.matmul(transpose_20, transpose_23);  transpose_20 = transpose_23 = None
    add_33 = matmul_8 + add_4;  matmul_8 = None
    float_6 = add_33.float()
    softmax_4 = torch.nn.functional.softmax(float_6, dim = -1, _stacklevel = 3, dtype = None);  float_6 = None
    type_as_4 = softmax_4.type_as(add_33);  softmax_4 = add_33 = None
    dropout_4 = torch.nn.functional.dropout(type_as_4, p = 0.1, training = False, inplace = False);  type_as_4 = None
    matmul_9 = torch.matmul(dropout_4, transpose_22);  dropout_4 = transpose_22 = None
    transpose_24 = matmul_9.transpose(1, 2);  matmul_9 = None
    contiguous_4 = transpose_24.contiguous();  transpose_24 = None
    view_20 = contiguous_4.view(getitem_19, -1, 384);  contiguous_4 = getitem_19 = None
    encoder_block_4_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.o(view_20);  view_20 = None
    encoder_block_4_layer_0_dropout = getattr(getattr(self.encoder.block, "4").layer, "0").dropout(encoder_block_4_layer_0_self_attention_o);  encoder_block_4_layer_0_self_attention_o = None
    add_34 = add_31 + encoder_block_4_layer_0_dropout;  add_31 = encoder_block_4_layer_0_dropout = None
    getattr_29 = add_34.dtype
    eq_20 = getattr_29 == torch.float16;  getattr_29 = None
    to_21 = add_34.to(torch.float32)
    pow_14 = to_21.pow(2);  to_21 = None
    mean_9 = pow_14.mean(-1, keepdim = True);  pow_14 = None
    add_35 = mean_9 + 1e-06;  mean_9 = None
    rsqrt_9 = torch.rsqrt(add_35);  add_35 = None
    mul_41 = add_34 * rsqrt_9;  rsqrt_9 = None
    encoder_block_4_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "4").layer, "1").layer_norm.weight
    getattr_30 = encoder_block_4_layer_1_layer_norm_weight.dtype
    eq_21 = getattr_30 == torch.float16;  getattr_30 = None
    getattr_31 = encoder_block_4_layer_1_layer_norm_weight.dtype
    to_22 = mul_41.to(getattr_31);  mul_41 = getattr_31 = None
    mul_42 = encoder_block_4_layer_1_layer_norm_weight * to_22;  encoder_block_4_layer_1_layer_norm_weight = to_22 = None
    encoder_block_4_layer_1_dense_relu_dense_wi_0 = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.wi_0(mul_42)
    mul_43 = 0.5 * encoder_block_4_layer_1_dense_relu_dense_wi_0
    pow_15 = torch.pow(encoder_block_4_layer_1_dense_relu_dense_wi_0, 3.0)
    mul_44 = 0.044715 * pow_15;  pow_15 = None
    add_36 = encoder_block_4_layer_1_dense_relu_dense_wi_0 + mul_44;  encoder_block_4_layer_1_dense_relu_dense_wi_0 = mul_44 = None
    mul_45 = 0.7978845608028654 * add_36;  add_36 = None
    tanh_4 = torch.tanh(mul_45);  mul_45 = None
    add_37 = 1.0 + tanh_4;  tanh_4 = None
    mul_46 = mul_43 * add_37;  mul_43 = add_37 = None
    encoder_block_4_layer_1_dense_relu_dense_wi_1 = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.wi_1(mul_42);  mul_42 = None
    mul_47 = mul_46 * encoder_block_4_layer_1_dense_relu_dense_wi_1;  mul_46 = encoder_block_4_layer_1_dense_relu_dense_wi_1 = None
    encoder_block_4_layer_1_dense_relu_dense_dropout = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.dropout(mul_47);  mul_47 = None
    encoder_block_4_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.wo.weight
    encoder_block_4_layer_1_dense_relu_dense_wo = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.wo(encoder_block_4_layer_1_dense_relu_dense_dropout);  encoder_block_4_layer_1_dense_relu_dense_dropout = None
    encoder_block_4_layer_1_dropout = getattr(getattr(self.encoder.block, "4").layer, "1").dropout(encoder_block_4_layer_1_dense_relu_dense_wo);  encoder_block_4_layer_1_dense_relu_dense_wo = None
    add_38 = add_34 + encoder_block_4_layer_1_dropout;  add_34 = encoder_block_4_layer_1_dropout = None
    getattr_32 = add_38.dtype
    eq_22 = getattr_32 == torch.float16;  getattr_32 = None
    to_23 = add_38.to(torch.float32)
    pow_16 = to_23.pow(2);  to_23 = None
    mean_10 = pow_16.mean(-1, keepdim = True);  pow_16 = None
    add_39 = mean_10 + 1e-06;  mean_10 = None
    rsqrt_10 = torch.rsqrt(add_39);  add_39 = None
    mul_48 = add_38 * rsqrt_10;  rsqrt_10 = None
    encoder_block_5_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "5").layer, "0").layer_norm.weight
    getattr_33 = encoder_block_5_layer_0_layer_norm_weight.dtype
    eq_23 = getattr_33 == torch.float16;  getattr_33 = None
    getattr_34 = encoder_block_5_layer_0_layer_norm_weight.dtype
    to_24 = mul_48.to(getattr_34);  mul_48 = getattr_34 = None
    mul_49 = encoder_block_5_layer_0_layer_norm_weight * to_24;  encoder_block_5_layer_0_layer_norm_weight = to_24 = None
    size_6 = mul_49.size()
    getitem_21 = size_6[slice(None, 2, None)];  size_6 = None
    getitem_22 = getitem_21[0]
    getitem_23 = getitem_21[1];  getitem_21 = None
    encoder_block_5_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.q(mul_49)
    view_21 = encoder_block_5_layer_0_self_attention_q.view(getitem_22, -1, 6, 64);  encoder_block_5_layer_0_self_attention_q = None
    transpose_25 = view_21.transpose(1, 2);  view_21 = None
    encoder_block_5_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.k(mul_49)
    view_22 = encoder_block_5_layer_0_self_attention_k.view(getitem_22, -1, 6, 64);  encoder_block_5_layer_0_self_attention_k = None
    transpose_26 = view_22.transpose(1, 2);  view_22 = None
    encoder_block_5_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.v(mul_49);  mul_49 = None
    view_23 = encoder_block_5_layer_0_self_attention_v.view(getitem_22, -1, 6, 64);  encoder_block_5_layer_0_self_attention_v = None
    transpose_27 = view_23.transpose(1, 2);  view_23 = None
    transpose_28 = transpose_26.transpose(3, 2);  transpose_26 = None
    matmul_10 = torch.matmul(transpose_25, transpose_28);  transpose_25 = transpose_28 = None
    add_40 = matmul_10 + add_4;  matmul_10 = None
    float_7 = add_40.float()
    softmax_5 = torch.nn.functional.softmax(float_7, dim = -1, _stacklevel = 3, dtype = None);  float_7 = None
    type_as_5 = softmax_5.type_as(add_40);  softmax_5 = add_40 = None
    dropout_5 = torch.nn.functional.dropout(type_as_5, p = 0.1, training = False, inplace = False);  type_as_5 = None
    matmul_11 = torch.matmul(dropout_5, transpose_27);  dropout_5 = transpose_27 = None
    transpose_29 = matmul_11.transpose(1, 2);  matmul_11 = None
    contiguous_5 = transpose_29.contiguous();  transpose_29 = None
    view_24 = contiguous_5.view(getitem_22, -1, 384);  contiguous_5 = getitem_22 = None
    encoder_block_5_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.o(view_24);  view_24 = None
    encoder_block_5_layer_0_dropout = getattr(getattr(self.encoder.block, "5").layer, "0").dropout(encoder_block_5_layer_0_self_attention_o);  encoder_block_5_layer_0_self_attention_o = None
    add_41 = add_38 + encoder_block_5_layer_0_dropout;  add_38 = encoder_block_5_layer_0_dropout = None
    getattr_35 = add_41.dtype
    eq_24 = getattr_35 == torch.float16;  getattr_35 = None
    to_25 = add_41.to(torch.float32)
    pow_17 = to_25.pow(2);  to_25 = None
    mean_11 = pow_17.mean(-1, keepdim = True);  pow_17 = None
    add_42 = mean_11 + 1e-06;  mean_11 = None
    rsqrt_11 = torch.rsqrt(add_42);  add_42 = None
    mul_50 = add_41 * rsqrt_11;  rsqrt_11 = None
    encoder_block_5_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "5").layer, "1").layer_norm.weight
    getattr_36 = encoder_block_5_layer_1_layer_norm_weight.dtype
    eq_25 = getattr_36 == torch.float16;  getattr_36 = None
    getattr_37 = encoder_block_5_layer_1_layer_norm_weight.dtype
    to_26 = mul_50.to(getattr_37);  mul_50 = getattr_37 = None
    mul_51 = encoder_block_5_layer_1_layer_norm_weight * to_26;  encoder_block_5_layer_1_layer_norm_weight = to_26 = None
    encoder_block_5_layer_1_dense_relu_dense_wi_0 = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.wi_0(mul_51)
    mul_52 = 0.5 * encoder_block_5_layer_1_dense_relu_dense_wi_0
    pow_18 = torch.pow(encoder_block_5_layer_1_dense_relu_dense_wi_0, 3.0)
    mul_53 = 0.044715 * pow_18;  pow_18 = None
    add_43 = encoder_block_5_layer_1_dense_relu_dense_wi_0 + mul_53;  encoder_block_5_layer_1_dense_relu_dense_wi_0 = mul_53 = None
    mul_54 = 0.7978845608028654 * add_43;  add_43 = None
    tanh_5 = torch.tanh(mul_54);  mul_54 = None
    add_44 = 1.0 + tanh_5;  tanh_5 = None
    mul_55 = mul_52 * add_44;  mul_52 = add_44 = None
    encoder_block_5_layer_1_dense_relu_dense_wi_1 = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.wi_1(mul_51);  mul_51 = None
    mul_56 = mul_55 * encoder_block_5_layer_1_dense_relu_dense_wi_1;  mul_55 = encoder_block_5_layer_1_dense_relu_dense_wi_1 = None
    encoder_block_5_layer_1_dense_relu_dense_dropout = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.dropout(mul_56);  mul_56 = None
    encoder_block_5_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.wo.weight
    encoder_block_5_layer_1_dense_relu_dense_wo = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.wo(encoder_block_5_layer_1_dense_relu_dense_dropout);  encoder_block_5_layer_1_dense_relu_dense_dropout = None
    encoder_block_5_layer_1_dropout = getattr(getattr(self.encoder.block, "5").layer, "1").dropout(encoder_block_5_layer_1_dense_relu_dense_wo);  encoder_block_5_layer_1_dense_relu_dense_wo = None
    add_45 = add_41 + encoder_block_5_layer_1_dropout;  add_41 = encoder_block_5_layer_1_dropout = None
    getattr_38 = add_45.dtype
    eq_26 = getattr_38 == torch.float16;  getattr_38 = None
    to_27 = add_45.to(torch.float32)
    pow_19 = to_27.pow(2);  to_27 = None
    mean_12 = pow_19.mean(-1, keepdim = True);  pow_19 = None
    add_46 = mean_12 + 1e-06;  mean_12 = None
    rsqrt_12 = torch.rsqrt(add_46);  add_46 = None
    mul_57 = add_45 * rsqrt_12;  rsqrt_12 = None
    encoder_block_6_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "6").layer, "0").layer_norm.weight
    getattr_39 = encoder_block_6_layer_0_layer_norm_weight.dtype
    eq_27 = getattr_39 == torch.float16;  getattr_39 = None
    getattr_40 = encoder_block_6_layer_0_layer_norm_weight.dtype
    to_28 = mul_57.to(getattr_40);  mul_57 = getattr_40 = None
    mul_58 = encoder_block_6_layer_0_layer_norm_weight * to_28;  encoder_block_6_layer_0_layer_norm_weight = to_28 = None
    size_7 = mul_58.size()
    getitem_24 = size_7[slice(None, 2, None)];  size_7 = None
    getitem_25 = getitem_24[0]
    getitem_26 = getitem_24[1];  getitem_24 = None
    encoder_block_6_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "6").layer, "0").SelfAttention.q(mul_58)
    view_25 = encoder_block_6_layer_0_self_attention_q.view(getitem_25, -1, 6, 64);  encoder_block_6_layer_0_self_attention_q = None
    transpose_30 = view_25.transpose(1, 2);  view_25 = None
    encoder_block_6_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "6").layer, "0").SelfAttention.k(mul_58)
    view_26 = encoder_block_6_layer_0_self_attention_k.view(getitem_25, -1, 6, 64);  encoder_block_6_layer_0_self_attention_k = None
    transpose_31 = view_26.transpose(1, 2);  view_26 = None
    encoder_block_6_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "6").layer, "0").SelfAttention.v(mul_58);  mul_58 = None
    view_27 = encoder_block_6_layer_0_self_attention_v.view(getitem_25, -1, 6, 64);  encoder_block_6_layer_0_self_attention_v = None
    transpose_32 = view_27.transpose(1, 2);  view_27 = None
    transpose_33 = transpose_31.transpose(3, 2);  transpose_31 = None
    matmul_12 = torch.matmul(transpose_30, transpose_33);  transpose_30 = transpose_33 = None
    add_47 = matmul_12 + add_4;  matmul_12 = None
    float_8 = add_47.float()
    softmax_6 = torch.nn.functional.softmax(float_8, dim = -1, _stacklevel = 3, dtype = None);  float_8 = None
    type_as_6 = softmax_6.type_as(add_47);  softmax_6 = add_47 = None
    dropout_6 = torch.nn.functional.dropout(type_as_6, p = 0.1, training = False, inplace = False);  type_as_6 = None
    matmul_13 = torch.matmul(dropout_6, transpose_32);  dropout_6 = transpose_32 = None
    transpose_34 = matmul_13.transpose(1, 2);  matmul_13 = None
    contiguous_6 = transpose_34.contiguous();  transpose_34 = None
    view_28 = contiguous_6.view(getitem_25, -1, 384);  contiguous_6 = getitem_25 = None
    encoder_block_6_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "6").layer, "0").SelfAttention.o(view_28);  view_28 = None
    encoder_block_6_layer_0_dropout = getattr(getattr(self.encoder.block, "6").layer, "0").dropout(encoder_block_6_layer_0_self_attention_o);  encoder_block_6_layer_0_self_attention_o = None
    add_48 = add_45 + encoder_block_6_layer_0_dropout;  add_45 = encoder_block_6_layer_0_dropout = None
    getattr_41 = add_48.dtype
    eq_28 = getattr_41 == torch.float16;  getattr_41 = None
    to_29 = add_48.to(torch.float32)
    pow_20 = to_29.pow(2);  to_29 = None
    mean_13 = pow_20.mean(-1, keepdim = True);  pow_20 = None
    add_49 = mean_13 + 1e-06;  mean_13 = None
    rsqrt_13 = torch.rsqrt(add_49);  add_49 = None
    mul_59 = add_48 * rsqrt_13;  rsqrt_13 = None
    encoder_block_6_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "6").layer, "1").layer_norm.weight
    getattr_42 = encoder_block_6_layer_1_layer_norm_weight.dtype
    eq_29 = getattr_42 == torch.float16;  getattr_42 = None
    getattr_43 = encoder_block_6_layer_1_layer_norm_weight.dtype
    to_30 = mul_59.to(getattr_43);  mul_59 = getattr_43 = None
    mul_60 = encoder_block_6_layer_1_layer_norm_weight * to_30;  encoder_block_6_layer_1_layer_norm_weight = to_30 = None
    encoder_block_6_layer_1_dense_relu_dense_wi_0 = getattr(getattr(self.encoder.block, "6").layer, "1").DenseReluDense.wi_0(mul_60)
    mul_61 = 0.5 * encoder_block_6_layer_1_dense_relu_dense_wi_0
    pow_21 = torch.pow(encoder_block_6_layer_1_dense_relu_dense_wi_0, 3.0)
    mul_62 = 0.044715 * pow_21;  pow_21 = None
    add_50 = encoder_block_6_layer_1_dense_relu_dense_wi_0 + mul_62;  encoder_block_6_layer_1_dense_relu_dense_wi_0 = mul_62 = None
    mul_63 = 0.7978845608028654 * add_50;  add_50 = None
    tanh_6 = torch.tanh(mul_63);  mul_63 = None
    add_51 = 1.0 + tanh_6;  tanh_6 = None
    mul_64 = mul_61 * add_51;  mul_61 = add_51 = None
    encoder_block_6_layer_1_dense_relu_dense_wi_1 = getattr(getattr(self.encoder.block, "6").layer, "1").DenseReluDense.wi_1(mul_60);  mul_60 = None
    mul_65 = mul_64 * encoder_block_6_layer_1_dense_relu_dense_wi_1;  mul_64 = encoder_block_6_layer_1_dense_relu_dense_wi_1 = None
    encoder_block_6_layer_1_dense_relu_dense_dropout = getattr(getattr(self.encoder.block, "6").layer, "1").DenseReluDense.dropout(mul_65);  mul_65 = None
    encoder_block_6_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "6").layer, "1").DenseReluDense.wo.weight
    encoder_block_6_layer_1_dense_relu_dense_wo = getattr(getattr(self.encoder.block, "6").layer, "1").DenseReluDense.wo(encoder_block_6_layer_1_dense_relu_dense_dropout);  encoder_block_6_layer_1_dense_relu_dense_dropout = None
    encoder_block_6_layer_1_dropout = getattr(getattr(self.encoder.block, "6").layer, "1").dropout(encoder_block_6_layer_1_dense_relu_dense_wo);  encoder_block_6_layer_1_dense_relu_dense_wo = None
    add_52 = add_48 + encoder_block_6_layer_1_dropout;  add_48 = encoder_block_6_layer_1_dropout = None
    getattr_44 = add_52.dtype
    eq_30 = getattr_44 == torch.float16;  getattr_44 = None
    to_31 = add_52.to(torch.float32)
    pow_22 = to_31.pow(2);  to_31 = None
    mean_14 = pow_22.mean(-1, keepdim = True);  pow_22 = None
    add_53 = mean_14 + 1e-06;  mean_14 = None
    rsqrt_14 = torch.rsqrt(add_53);  add_53 = None
    mul_66 = add_52 * rsqrt_14;  rsqrt_14 = None
    encoder_block_7_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "7").layer, "0").layer_norm.weight
    getattr_45 = encoder_block_7_layer_0_layer_norm_weight.dtype
    eq_31 = getattr_45 == torch.float16;  getattr_45 = None
    getattr_46 = encoder_block_7_layer_0_layer_norm_weight.dtype
    to_32 = mul_66.to(getattr_46);  mul_66 = getattr_46 = None
    mul_67 = encoder_block_7_layer_0_layer_norm_weight * to_32;  encoder_block_7_layer_0_layer_norm_weight = to_32 = None
    size_8 = mul_67.size()
    getitem_27 = size_8[slice(None, 2, None)];  size_8 = None
    getitem_28 = getitem_27[0]
    getitem_29 = getitem_27[1];  getitem_27 = None
    encoder_block_7_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "7").layer, "0").SelfAttention.q(mul_67)
    view_29 = encoder_block_7_layer_0_self_attention_q.view(getitem_28, -1, 6, 64);  encoder_block_7_layer_0_self_attention_q = None
    transpose_35 = view_29.transpose(1, 2);  view_29 = None
    encoder_block_7_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "7").layer, "0").SelfAttention.k(mul_67)
    view_30 = encoder_block_7_layer_0_self_attention_k.view(getitem_28, -1, 6, 64);  encoder_block_7_layer_0_self_attention_k = None
    transpose_36 = view_30.transpose(1, 2);  view_30 = None
    encoder_block_7_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "7").layer, "0").SelfAttention.v(mul_67);  mul_67 = None
    view_31 = encoder_block_7_layer_0_self_attention_v.view(getitem_28, -1, 6, 64);  encoder_block_7_layer_0_self_attention_v = None
    transpose_37 = view_31.transpose(1, 2);  view_31 = None
    transpose_38 = transpose_36.transpose(3, 2);  transpose_36 = None
    matmul_14 = torch.matmul(transpose_35, transpose_38);  transpose_35 = transpose_38 = None
    add_54 = matmul_14 + add_4;  matmul_14 = add_4 = None
    float_9 = add_54.float()
    softmax_7 = torch.nn.functional.softmax(float_9, dim = -1, _stacklevel = 3, dtype = None);  float_9 = None
    type_as_7 = softmax_7.type_as(add_54);  softmax_7 = add_54 = None
    dropout_7 = torch.nn.functional.dropout(type_as_7, p = 0.1, training = False, inplace = False);  type_as_7 = None
    matmul_15 = torch.matmul(dropout_7, transpose_37);  dropout_7 = transpose_37 = None
    transpose_39 = matmul_15.transpose(1, 2);  matmul_15 = None
    contiguous_7 = transpose_39.contiguous();  transpose_39 = None
    view_32 = contiguous_7.view(getitem_28, -1, 384);  contiguous_7 = getitem_28 = None
    encoder_block_7_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "7").layer, "0").SelfAttention.o(view_32);  view_32 = None
    encoder_block_7_layer_0_dropout = getattr(getattr(self.encoder.block, "7").layer, "0").dropout(encoder_block_7_layer_0_self_attention_o);  encoder_block_7_layer_0_self_attention_o = None
    add_55 = add_52 + encoder_block_7_layer_0_dropout;  add_52 = encoder_block_7_layer_0_dropout = None
    getattr_47 = add_55.dtype
    eq_32 = getattr_47 == torch.float16;  getattr_47 = None
    to_33 = add_55.to(torch.float32)
    pow_23 = to_33.pow(2);  to_33 = None
    mean_15 = pow_23.mean(-1, keepdim = True);  pow_23 = None
    add_56 = mean_15 + 1e-06;  mean_15 = None
    rsqrt_15 = torch.rsqrt(add_56);  add_56 = None
    mul_68 = add_55 * rsqrt_15;  rsqrt_15 = None
    encoder_block_7_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "7").layer, "1").layer_norm.weight
    getattr_48 = encoder_block_7_layer_1_layer_norm_weight.dtype
    eq_33 = getattr_48 == torch.float16;  getattr_48 = None
    getattr_49 = encoder_block_7_layer_1_layer_norm_weight.dtype
    to_34 = mul_68.to(getattr_49);  mul_68 = getattr_49 = None
    mul_69 = encoder_block_7_layer_1_layer_norm_weight * to_34;  encoder_block_7_layer_1_layer_norm_weight = to_34 = None
    encoder_block_7_layer_1_dense_relu_dense_wi_0 = getattr(getattr(self.encoder.block, "7").layer, "1").DenseReluDense.wi_0(mul_69)
    mul_70 = 0.5 * encoder_block_7_layer_1_dense_relu_dense_wi_0
    pow_24 = torch.pow(encoder_block_7_layer_1_dense_relu_dense_wi_0, 3.0)
    mul_71 = 0.044715 * pow_24;  pow_24 = None
    add_57 = encoder_block_7_layer_1_dense_relu_dense_wi_0 + mul_71;  encoder_block_7_layer_1_dense_relu_dense_wi_0 = mul_71 = None
    mul_72 = 0.7978845608028654 * add_57;  add_57 = None
    tanh_7 = torch.tanh(mul_72);  mul_72 = None
    add_58 = 1.0 + tanh_7;  tanh_7 = None
    mul_73 = mul_70 * add_58;  mul_70 = add_58 = None
    encoder_block_7_layer_1_dense_relu_dense_wi_1 = getattr(getattr(self.encoder.block, "7").layer, "1").DenseReluDense.wi_1(mul_69);  mul_69 = None
    mul_74 = mul_73 * encoder_block_7_layer_1_dense_relu_dense_wi_1;  mul_73 = encoder_block_7_layer_1_dense_relu_dense_wi_1 = None
    encoder_block_7_layer_1_dense_relu_dense_dropout = getattr(getattr(self.encoder.block, "7").layer, "1").DenseReluDense.dropout(mul_74);  mul_74 = None
    encoder_block_7_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "7").layer, "1").DenseReluDense.wo.weight
    encoder_block_7_layer_1_dense_relu_dense_wo = getattr(getattr(self.encoder.block, "7").layer, "1").DenseReluDense.wo(encoder_block_7_layer_1_dense_relu_dense_dropout);  encoder_block_7_layer_1_dense_relu_dense_dropout = None
    encoder_block_7_layer_1_dropout = getattr(getattr(self.encoder.block, "7").layer, "1").dropout(encoder_block_7_layer_1_dense_relu_dense_wo);  encoder_block_7_layer_1_dense_relu_dense_wo = None
    add_59 = add_55 + encoder_block_7_layer_1_dropout;  add_55 = encoder_block_7_layer_1_dropout = None
    getattr_50 = add_59.dtype
    eq_34 = getattr_50 == torch.float16;  getattr_50 = None
    to_35 = add_59.to(torch.float32)
    pow_25 = to_35.pow(2);  to_35 = None
    mean_16 = pow_25.mean(-1, keepdim = True);  pow_25 = None
    add_60 = mean_16 + 1e-06;  mean_16 = None
    rsqrt_16 = torch.rsqrt(add_60);  add_60 = None
    mul_75 = add_59 * rsqrt_16;  add_59 = rsqrt_16 = None
    encoder_final_layer_norm_weight = self.encoder.final_layer_norm.weight
    getattr_51 = encoder_final_layer_norm_weight.dtype
    eq_35 = getattr_51 == torch.float16;  getattr_51 = None
    getattr_52 = encoder_final_layer_norm_weight.dtype
    to_36 = mul_75.to(getattr_52);  mul_75 = getattr_52 = None
    mul_76 = encoder_final_layer_norm_weight * to_36;  encoder_final_layer_norm_weight = to_36 = None
    encoder_dropout_1 = self.encoder.dropout(mul_76);  mul_76 = None
    size_9 = labels.size()
    getitem_30 = size_9[slice(None, -1, None)];  size_9 = None
    add_61 = getitem_30 + (1,);  getitem_30 = None
    full = torch.full(add_61, 0);  add_61 = None
    getitem_31 = labels[(Ellipsis, slice(None, -1, None))]
    cat = torch.cat([full, getitem_31], dim = -1);  full = getitem_31 = None
    eq_36 = cat == -100
    masked_fill_ = cat.masked_fill_(eq_36, 0);  eq_36 = None
    size_10 = cat.size()
    getitem_32 = size_10[-1]
    view_33 = cat.view(-1, getitem_32);  cat = getitem_32 = None
    shared_1 = self.shared(view_33);  view_33 = None
    getitem_33 = size_10[0]
    getitem_34 = size_10[1]
    getattr_53 = shared_1.device
    ones_1 = torch.ones(getitem_33, getitem_34, device = getattr_53);  getitem_34 = getattr_53 = None
    size_11 = encoder_dropout_1.size()
    getitem_35 = size_11[1];  size_11 = None
    getattr_54 = shared_1.device
    ones_2 = torch.ones(getitem_33, getitem_35, device = getattr_54, dtype = torch.int64);  getitem_33 = getitem_35 = getattr_54 = None
    dim_3 = ones_1.dim()
    eq_37 = dim_3 == 2;  dim_3 = None
    dim_4 = ones_1.dim()
    eq_38 = dim_4 == 3;  dim_4 = None
    dim_5 = ones_1.dim()
    eq_39 = dim_5 == 2;  dim_5 = None
    getitem_36 = size_10[0]
    getitem_37 = size_10[1];  size_10 = None
    getattr_55 = ones_1.device
    arange_2 = torch.arange(getitem_37, device = getattr_55);  getattr_55 = None
    getitem_38 = arange_2[(None, None, slice(None, None, None))]
    repeat = getitem_38.repeat(getitem_36, getitem_37, 1);  getitem_38 = getitem_36 = getitem_37 = None
    getitem_39 = arange_2[(None, slice(None, None, None), None)];  arange_2 = None
    le = repeat <= getitem_39;  repeat = getitem_39 = None
    getattr_56 = ones_1.dtype
    to_37 = le.to(getattr_56);  le = getattr_56 = None
    size_12 = to_37.size()
    getitem_40 = size_12[1];  size_12 = None
    size_13 = ones_1.size()
    getitem_41 = size_13[1];  size_13 = None
    lt_1 = getitem_40 < getitem_41;  getitem_40 = getitem_41 = None
    getitem_42 = to_37[(slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  to_37 = None
    getitem_43 = ones_1[(slice(None, None, None), None, None, slice(None, None, None))];  ones_1 = None
    mul_77 = getitem_42 * getitem_43;  getitem_42 = getitem_43 = None
    to_38 = mul_77.to(dtype = torch.float16);  mul_77 = None
    sub_2 = 1.0 - to_38;  to_38 = None
    mul_78 = sub_2 * -65504.0;  sub_2 = None
    size_14 = encoder_dropout_1.size()
    getitem_44 = size_14[0]
    getitem_45 = size_14[1]
    getitem_46 = size_14[2];  size_14 = None
    dim_6 = ones_2.dim()
    eq_40 = dim_6 == 3;  dim_6 = None
    dim_7 = ones_2.dim()
    eq_41 = dim_7 == 2;  dim_7 = None
    getitem_47 = ones_2[(slice(None, None, None), None, None, slice(None, None, None))];  ones_2 = None
    to_39 = getitem_47.to(dtype = torch.float16);  getitem_47 = None
    sub_3 = 1.0 - to_39;  to_39 = None
    mul_79 = sub_3 * -65504.0;  sub_3 = None
    decoder_dropout = self.decoder.dropout(shared_1);  shared_1 = None
    to_40 = decoder_dropout.to(torch.float32)
    pow_26 = to_40.pow(2);  to_40 = None
    mean_17 = pow_26.mean(-1, keepdim = True);  pow_26 = None
    add_62 = mean_17 + 1e-06;  mean_17 = None
    rsqrt_17 = torch.rsqrt(add_62);  add_62 = None
    mul_80 = decoder_dropout * rsqrt_17;  rsqrt_17 = None
    decoder_block_0_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "0").layer, "0").layer_norm.weight
    getattr_57 = decoder_block_0_layer_0_layer_norm_weight.dtype
    eq_42 = getattr_57 == torch.float16;  getattr_57 = None
    getattr_58 = decoder_block_0_layer_0_layer_norm_weight.dtype
    to_41 = mul_80.to(getattr_58);  mul_80 = getattr_58 = None
    mul_81 = decoder_block_0_layer_0_layer_norm_weight * to_41;  decoder_block_0_layer_0_layer_norm_weight = to_41 = None
    size_15 = mul_81.size()
    getitem_48 = size_15[slice(None, 2, None)];  size_15 = None
    getitem_49 = getitem_48[0]
    getitem_50 = getitem_48[1];  getitem_48 = None
    decoder_block_0_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.q(mul_81)
    view_34 = decoder_block_0_layer_0_self_attention_q.view(getitem_49, -1, 6, 64);  decoder_block_0_layer_0_self_attention_q = None
    transpose_40 = view_34.transpose(1, 2);  view_34 = None
    decoder_block_0_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.k(mul_81)
    view_35 = decoder_block_0_layer_0_self_attention_k.view(getitem_49, -1, 6, 64);  decoder_block_0_layer_0_self_attention_k = None
    transpose_41 = view_35.transpose(1, 2);  view_35 = None
    decoder_block_0_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.v(mul_81);  mul_81 = None
    view_36 = decoder_block_0_layer_0_self_attention_v.view(getitem_49, -1, 6, 64);  decoder_block_0_layer_0_self_attention_v = None
    transpose_42 = view_36.transpose(1, 2);  view_36 = None
    transpose_43 = transpose_41.transpose(3, 2)
    matmul_16 = torch.matmul(transpose_40, transpose_43);  transpose_40 = transpose_43 = None
    getattr_59 = matmul_16.device
    arange_3 = torch.arange(getitem_50, dtype = torch.int64, device = getattr_59)
    getitem_51 = arange_3[(slice(None, None, None), None)];  arange_3 = None
    arange_4 = torch.arange(getitem_50, dtype = torch.int64, device = getattr_59);  getitem_50 = getattr_59 = None
    getitem_52 = arange_4[(None, slice(None, None, None))];  arange_4 = None
    sub_4 = getitem_52 - getitem_51;  getitem_52 = getitem_51 = None
    zeros_like = torch.zeros_like(sub_4)
    min_2 = torch.min(sub_4, zeros_like);  sub_4 = zeros_like = None
    neg = -min_2;  min_2 = None
    lt_2 = neg < 16
    float_10 = neg.float()
    truediv_2 = float_10 / 16;  float_10 = None
    log_1 = torch.log(truediv_2);  truediv_2 = None
    truediv_3 = log_1 / 2.0794415416798357;  log_1 = None
    mul_82 = truediv_3 * 16;  truediv_3 = None
    to_42 = mul_82.to(torch.int64);  mul_82 = None
    add_63 = 16 + to_42;  to_42 = None
    full_like_1 = torch.full_like(add_63, 31)
    min_3 = torch.min(add_63, full_like_1);  add_63 = full_like_1 = None
    where_1 = torch.where(lt_2, neg, min_3);  lt_2 = neg = min_3 = None
    add_64 = 0 + where_1;  where_1 = None
    decoder_block_0_layer_0_self_attention_relative_attention_bias = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.relative_attention_bias(add_64);  add_64 = None
    permute_1 = decoder_block_0_layer_0_self_attention_relative_attention_bias.permute([2, 0, 1]);  decoder_block_0_layer_0_self_attention_relative_attention_bias = None
    unsqueeze_1 = permute_1.unsqueeze(0);  permute_1 = None
    add_65 = unsqueeze_1 + mul_78;  unsqueeze_1 = mul_78 = None
    add_66 = matmul_16 + add_65;  matmul_16 = None
    float_11 = add_66.float()
    softmax_8 = torch.nn.functional.softmax(float_11, dim = -1, _stacklevel = 3, dtype = None);  float_11 = None
    type_as_8 = softmax_8.type_as(add_66);  softmax_8 = add_66 = None
    dropout_8 = torch.nn.functional.dropout(type_as_8, p = 0.1, training = False, inplace = False);  type_as_8 = None
    matmul_17 = torch.matmul(dropout_8, transpose_42);  dropout_8 = None
    transpose_44 = matmul_17.transpose(1, 2);  matmul_17 = None
    contiguous_8 = transpose_44.contiguous();  transpose_44 = None
    view_37 = contiguous_8.view(getitem_49, -1, 384);  contiguous_8 = getitem_49 = None
    decoder_block_0_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.o(view_37);  view_37 = None
    decoder_block_0_layer_0_dropout = getattr(getattr(self.decoder.block, "0").layer, "0").dropout(decoder_block_0_layer_0_self_attention_o);  decoder_block_0_layer_0_self_attention_o = None
    add_67 = decoder_dropout + decoder_block_0_layer_0_dropout;  decoder_dropout = decoder_block_0_layer_0_dropout = None
    getattr_60 = add_67.dtype
    eq_43 = getattr_60 == torch.float16;  getattr_60 = None
    size_16 = transpose_41.size()
    getitem_53 = size_16[2];  size_16 = None
    to_43 = add_67.to(torch.float32)
    pow_27 = to_43.pow(2);  to_43 = None
    mean_18 = pow_27.mean(-1, keepdim = True);  pow_27 = None
    add_68 = mean_18 + 1e-06;  mean_18 = None
    rsqrt_18 = torch.rsqrt(add_68);  add_68 = None
    mul_83 = add_67 * rsqrt_18;  rsqrt_18 = None
    decoder_block_0_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "0").layer, "1").layer_norm.weight
    getattr_61 = decoder_block_0_layer_1_layer_norm_weight.dtype
    eq_44 = getattr_61 == torch.float16;  getattr_61 = None
    getattr_62 = decoder_block_0_layer_1_layer_norm_weight.dtype
    to_44 = mul_83.to(getattr_62);  mul_83 = getattr_62 = None
    mul_84 = decoder_block_0_layer_1_layer_norm_weight * to_44;  decoder_block_0_layer_1_layer_norm_weight = to_44 = None
    size_17 = mul_84.size()
    getitem_54 = size_17[slice(None, 2, None)];  size_17 = None
    getitem_55 = getitem_54[0]
    getitem_56 = getitem_54[1];  getitem_54 = None
    size_18 = encoder_dropout_1.size()
    getitem_57 = size_18[1];  size_18 = None
    decoder_block_0_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.q(mul_84);  mul_84 = None
    view_38 = decoder_block_0_layer_1_enc_dec_attention_q.view(getitem_55, -1, 6, 64);  decoder_block_0_layer_1_enc_dec_attention_q = None
    transpose_45 = view_38.transpose(1, 2);  view_38 = None
    decoder_block_0_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_39 = decoder_block_0_layer_1_enc_dec_attention_k.view(getitem_55, -1, 6, 64);  decoder_block_0_layer_1_enc_dec_attention_k = None
    transpose_46 = view_39.transpose(1, 2);  view_39 = None
    decoder_block_0_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_40 = decoder_block_0_layer_1_enc_dec_attention_v.view(getitem_55, -1, 6, 64);  decoder_block_0_layer_1_enc_dec_attention_v = None
    transpose_47 = view_40.transpose(1, 2);  view_40 = None
    transpose_48 = transpose_46.transpose(3, 2)
    matmul_18 = torch.matmul(transpose_45, transpose_48);  transpose_45 = transpose_48 = None
    getattr_63 = matmul_18.device
    getattr_64 = matmul_18.dtype
    zeros = torch.zeros((1, 6, getitem_56, getitem_57), device = getattr_63, dtype = getattr_64);  getitem_56 = getitem_57 = getattr_63 = getattr_64 = None
    add_69 = zeros + mul_79;  zeros = mul_79 = None
    add_70 = matmul_18 + add_69;  matmul_18 = None
    float_12 = add_70.float()
    softmax_9 = torch.nn.functional.softmax(float_12, dim = -1, _stacklevel = 3, dtype = None);  float_12 = None
    type_as_9 = softmax_9.type_as(add_70);  softmax_9 = add_70 = None
    dropout_9 = torch.nn.functional.dropout(type_as_9, p = 0.1, training = False, inplace = False);  type_as_9 = None
    matmul_19 = torch.matmul(dropout_9, transpose_47);  dropout_9 = None
    transpose_49 = matmul_19.transpose(1, 2);  matmul_19 = None
    contiguous_9 = transpose_49.contiguous();  transpose_49 = None
    view_41 = contiguous_9.view(getitem_55, -1, 384);  contiguous_9 = getitem_55 = None
    decoder_block_0_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.o(view_41);  view_41 = None
    decoder_block_0_layer_1_dropout = getattr(getattr(self.decoder.block, "0").layer, "1").dropout(decoder_block_0_layer_1_enc_dec_attention_o);  decoder_block_0_layer_1_enc_dec_attention_o = None
    add_71 = add_67 + decoder_block_0_layer_1_dropout;  add_67 = decoder_block_0_layer_1_dropout = None
    getattr_65 = add_71.dtype
    eq_45 = getattr_65 == torch.float16;  getattr_65 = None
    to_45 = add_71.to(torch.float32)
    pow_28 = to_45.pow(2);  to_45 = None
    mean_19 = pow_28.mean(-1, keepdim = True);  pow_28 = None
    add_72 = mean_19 + 1e-06;  mean_19 = None
    rsqrt_19 = torch.rsqrt(add_72);  add_72 = None
    mul_85 = add_71 * rsqrt_19;  rsqrt_19 = None
    decoder_block_0_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "0").layer, "2").layer_norm.weight
    getattr_66 = decoder_block_0_layer_2_layer_norm_weight.dtype
    eq_46 = getattr_66 == torch.float16;  getattr_66 = None
    getattr_67 = decoder_block_0_layer_2_layer_norm_weight.dtype
    to_46 = mul_85.to(getattr_67);  mul_85 = getattr_67 = None
    mul_86 = decoder_block_0_layer_2_layer_norm_weight * to_46;  decoder_block_0_layer_2_layer_norm_weight = to_46 = None
    decoder_block_0_layer_2_dense_relu_dense_wi_0 = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.wi_0(mul_86)
    mul_87 = 0.5 * decoder_block_0_layer_2_dense_relu_dense_wi_0
    pow_29 = torch.pow(decoder_block_0_layer_2_dense_relu_dense_wi_0, 3.0)
    mul_88 = 0.044715 * pow_29;  pow_29 = None
    add_73 = decoder_block_0_layer_2_dense_relu_dense_wi_0 + mul_88;  decoder_block_0_layer_2_dense_relu_dense_wi_0 = mul_88 = None
    mul_89 = 0.7978845608028654 * add_73;  add_73 = None
    tanh_8 = torch.tanh(mul_89);  mul_89 = None
    add_74 = 1.0 + tanh_8;  tanh_8 = None
    mul_90 = mul_87 * add_74;  mul_87 = add_74 = None
    decoder_block_0_layer_2_dense_relu_dense_wi_1 = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.wi_1(mul_86);  mul_86 = None
    mul_91 = mul_90 * decoder_block_0_layer_2_dense_relu_dense_wi_1;  mul_90 = decoder_block_0_layer_2_dense_relu_dense_wi_1 = None
    decoder_block_0_layer_2_dense_relu_dense_dropout = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.dropout(mul_91);  mul_91 = None
    decoder_block_0_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.wo.weight
    decoder_block_0_layer_2_dense_relu_dense_wo = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.wo(decoder_block_0_layer_2_dense_relu_dense_dropout);  decoder_block_0_layer_2_dense_relu_dense_dropout = None
    decoder_block_0_layer_2_dropout = getattr(getattr(self.decoder.block, "0").layer, "2").dropout(decoder_block_0_layer_2_dense_relu_dense_wo);  decoder_block_0_layer_2_dense_relu_dense_wo = None
    add_75 = add_71 + decoder_block_0_layer_2_dropout;  add_71 = decoder_block_0_layer_2_dropout = None
    getattr_68 = add_75.dtype
    eq_47 = getattr_68 == torch.float16;  getattr_68 = None
    to_47 = add_75.to(torch.float32)
    pow_30 = to_47.pow(2);  to_47 = None
    mean_20 = pow_30.mean(-1, keepdim = True);  pow_30 = None
    add_76 = mean_20 + 1e-06;  mean_20 = None
    rsqrt_20 = torch.rsqrt(add_76);  add_76 = None
    mul_92 = add_75 * rsqrt_20;  rsqrt_20 = None
    decoder_block_1_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "1").layer, "0").layer_norm.weight
    getattr_69 = decoder_block_1_layer_0_layer_norm_weight.dtype
    eq_48 = getattr_69 == torch.float16;  getattr_69 = None
    getattr_70 = decoder_block_1_layer_0_layer_norm_weight.dtype
    to_48 = mul_92.to(getattr_70);  mul_92 = getattr_70 = None
    mul_93 = decoder_block_1_layer_0_layer_norm_weight * to_48;  decoder_block_1_layer_0_layer_norm_weight = to_48 = None
    size_19 = mul_93.size()
    getitem_58 = size_19[slice(None, 2, None)];  size_19 = None
    getitem_59 = getitem_58[0]
    getitem_60 = getitem_58[1];  getitem_58 = None
    decoder_block_1_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.q(mul_93)
    view_42 = decoder_block_1_layer_0_self_attention_q.view(getitem_59, -1, 6, 64);  decoder_block_1_layer_0_self_attention_q = None
    transpose_50 = view_42.transpose(1, 2);  view_42 = None
    decoder_block_1_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.k(mul_93)
    view_43 = decoder_block_1_layer_0_self_attention_k.view(getitem_59, -1, 6, 64);  decoder_block_1_layer_0_self_attention_k = None
    transpose_51 = view_43.transpose(1, 2);  view_43 = None
    decoder_block_1_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.v(mul_93);  mul_93 = None
    view_44 = decoder_block_1_layer_0_self_attention_v.view(getitem_59, -1, 6, 64);  decoder_block_1_layer_0_self_attention_v = None
    transpose_52 = view_44.transpose(1, 2);  view_44 = None
    transpose_53 = transpose_51.transpose(3, 2)
    matmul_20 = torch.matmul(transpose_50, transpose_53);  transpose_50 = transpose_53 = None
    add_77 = matmul_20 + add_65;  matmul_20 = None
    float_13 = add_77.float()
    softmax_10 = torch.nn.functional.softmax(float_13, dim = -1, _stacklevel = 3, dtype = None);  float_13 = None
    type_as_10 = softmax_10.type_as(add_77);  softmax_10 = add_77 = None
    dropout_10 = torch.nn.functional.dropout(type_as_10, p = 0.1, training = False, inplace = False);  type_as_10 = None
    matmul_21 = torch.matmul(dropout_10, transpose_52);  dropout_10 = None
    transpose_54 = matmul_21.transpose(1, 2);  matmul_21 = None
    contiguous_10 = transpose_54.contiguous();  transpose_54 = None
    view_45 = contiguous_10.view(getitem_59, -1, 384);  contiguous_10 = getitem_59 = None
    decoder_block_1_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.o(view_45);  view_45 = None
    decoder_block_1_layer_0_dropout = getattr(getattr(self.decoder.block, "1").layer, "0").dropout(decoder_block_1_layer_0_self_attention_o);  decoder_block_1_layer_0_self_attention_o = None
    add_78 = add_75 + decoder_block_1_layer_0_dropout;  add_75 = decoder_block_1_layer_0_dropout = None
    getattr_71 = add_78.dtype
    eq_49 = getattr_71 == torch.float16;  getattr_71 = None
    size_20 = transpose_51.size()
    getitem_61 = size_20[2];  size_20 = None
    to_49 = add_78.to(torch.float32)
    pow_31 = to_49.pow(2);  to_49 = None
    mean_21 = pow_31.mean(-1, keepdim = True);  pow_31 = None
    add_79 = mean_21 + 1e-06;  mean_21 = None
    rsqrt_21 = torch.rsqrt(add_79);  add_79 = None
    mul_94 = add_78 * rsqrt_21;  rsqrt_21 = None
    decoder_block_1_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "1").layer, "1").layer_norm.weight
    getattr_72 = decoder_block_1_layer_1_layer_norm_weight.dtype
    eq_50 = getattr_72 == torch.float16;  getattr_72 = None
    getattr_73 = decoder_block_1_layer_1_layer_norm_weight.dtype
    to_50 = mul_94.to(getattr_73);  mul_94 = getattr_73 = None
    mul_95 = decoder_block_1_layer_1_layer_norm_weight * to_50;  decoder_block_1_layer_1_layer_norm_weight = to_50 = None
    size_21 = mul_95.size()
    getitem_62 = size_21[slice(None, 2, None)];  size_21 = None
    getitem_63 = getitem_62[0]
    getitem_64 = getitem_62[1];  getitem_62 = None
    size_22 = encoder_dropout_1.size()
    getitem_65 = size_22[1];  size_22 = None
    decoder_block_1_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.q(mul_95);  mul_95 = None
    view_46 = decoder_block_1_layer_1_enc_dec_attention_q.view(getitem_63, -1, 6, 64);  decoder_block_1_layer_1_enc_dec_attention_q = None
    transpose_55 = view_46.transpose(1, 2);  view_46 = None
    decoder_block_1_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_47 = decoder_block_1_layer_1_enc_dec_attention_k.view(getitem_63, -1, 6, 64);  decoder_block_1_layer_1_enc_dec_attention_k = None
    transpose_56 = view_47.transpose(1, 2);  view_47 = None
    decoder_block_1_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_48 = decoder_block_1_layer_1_enc_dec_attention_v.view(getitem_63, -1, 6, 64);  decoder_block_1_layer_1_enc_dec_attention_v = None
    transpose_57 = view_48.transpose(1, 2);  view_48 = None
    transpose_58 = transpose_56.transpose(3, 2)
    matmul_22 = torch.matmul(transpose_55, transpose_58);  transpose_55 = transpose_58 = None
    add_80 = matmul_22 + add_69;  matmul_22 = None
    float_14 = add_80.float()
    softmax_11 = torch.nn.functional.softmax(float_14, dim = -1, _stacklevel = 3, dtype = None);  float_14 = None
    type_as_11 = softmax_11.type_as(add_80);  softmax_11 = add_80 = None
    dropout_11 = torch.nn.functional.dropout(type_as_11, p = 0.1, training = False, inplace = False);  type_as_11 = None
    matmul_23 = torch.matmul(dropout_11, transpose_57);  dropout_11 = None
    transpose_59 = matmul_23.transpose(1, 2);  matmul_23 = None
    contiguous_11 = transpose_59.contiguous();  transpose_59 = None
    view_49 = contiguous_11.view(getitem_63, -1, 384);  contiguous_11 = getitem_63 = None
    decoder_block_1_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.o(view_49);  view_49 = None
    decoder_block_1_layer_1_dropout = getattr(getattr(self.decoder.block, "1").layer, "1").dropout(decoder_block_1_layer_1_enc_dec_attention_o);  decoder_block_1_layer_1_enc_dec_attention_o = None
    add_81 = add_78 + decoder_block_1_layer_1_dropout;  add_78 = decoder_block_1_layer_1_dropout = None
    getattr_74 = add_81.dtype
    eq_51 = getattr_74 == torch.float16;  getattr_74 = None
    to_51 = add_81.to(torch.float32)
    pow_32 = to_51.pow(2);  to_51 = None
    mean_22 = pow_32.mean(-1, keepdim = True);  pow_32 = None
    add_82 = mean_22 + 1e-06;  mean_22 = None
    rsqrt_22 = torch.rsqrt(add_82);  add_82 = None
    mul_96 = add_81 * rsqrt_22;  rsqrt_22 = None
    decoder_block_1_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "1").layer, "2").layer_norm.weight
    getattr_75 = decoder_block_1_layer_2_layer_norm_weight.dtype
    eq_52 = getattr_75 == torch.float16;  getattr_75 = None
    getattr_76 = decoder_block_1_layer_2_layer_norm_weight.dtype
    to_52 = mul_96.to(getattr_76);  mul_96 = getattr_76 = None
    mul_97 = decoder_block_1_layer_2_layer_norm_weight * to_52;  decoder_block_1_layer_2_layer_norm_weight = to_52 = None
    decoder_block_1_layer_2_dense_relu_dense_wi_0 = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.wi_0(mul_97)
    mul_98 = 0.5 * decoder_block_1_layer_2_dense_relu_dense_wi_0
    pow_33 = torch.pow(decoder_block_1_layer_2_dense_relu_dense_wi_0, 3.0)
    mul_99 = 0.044715 * pow_33;  pow_33 = None
    add_83 = decoder_block_1_layer_2_dense_relu_dense_wi_0 + mul_99;  decoder_block_1_layer_2_dense_relu_dense_wi_0 = mul_99 = None
    mul_100 = 0.7978845608028654 * add_83;  add_83 = None
    tanh_9 = torch.tanh(mul_100);  mul_100 = None
    add_84 = 1.0 + tanh_9;  tanh_9 = None
    mul_101 = mul_98 * add_84;  mul_98 = add_84 = None
    decoder_block_1_layer_2_dense_relu_dense_wi_1 = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.wi_1(mul_97);  mul_97 = None
    mul_102 = mul_101 * decoder_block_1_layer_2_dense_relu_dense_wi_1;  mul_101 = decoder_block_1_layer_2_dense_relu_dense_wi_1 = None
    decoder_block_1_layer_2_dense_relu_dense_dropout = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.dropout(mul_102);  mul_102 = None
    decoder_block_1_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.wo.weight
    decoder_block_1_layer_2_dense_relu_dense_wo = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.wo(decoder_block_1_layer_2_dense_relu_dense_dropout);  decoder_block_1_layer_2_dense_relu_dense_dropout = None
    decoder_block_1_layer_2_dropout = getattr(getattr(self.decoder.block, "1").layer, "2").dropout(decoder_block_1_layer_2_dense_relu_dense_wo);  decoder_block_1_layer_2_dense_relu_dense_wo = None
    add_85 = add_81 + decoder_block_1_layer_2_dropout;  add_81 = decoder_block_1_layer_2_dropout = None
    getattr_77 = add_85.dtype
    eq_53 = getattr_77 == torch.float16;  getattr_77 = None
    to_53 = add_85.to(torch.float32)
    pow_34 = to_53.pow(2);  to_53 = None
    mean_23 = pow_34.mean(-1, keepdim = True);  pow_34 = None
    add_86 = mean_23 + 1e-06;  mean_23 = None
    rsqrt_23 = torch.rsqrt(add_86);  add_86 = None
    mul_103 = add_85 * rsqrt_23;  rsqrt_23 = None
    decoder_block_2_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "2").layer, "0").layer_norm.weight
    getattr_78 = decoder_block_2_layer_0_layer_norm_weight.dtype
    eq_54 = getattr_78 == torch.float16;  getattr_78 = None
    getattr_79 = decoder_block_2_layer_0_layer_norm_weight.dtype
    to_54 = mul_103.to(getattr_79);  mul_103 = getattr_79 = None
    mul_104 = decoder_block_2_layer_0_layer_norm_weight * to_54;  decoder_block_2_layer_0_layer_norm_weight = to_54 = None
    size_23 = mul_104.size()
    getitem_66 = size_23[slice(None, 2, None)];  size_23 = None
    getitem_67 = getitem_66[0]
    getitem_68 = getitem_66[1];  getitem_66 = None
    decoder_block_2_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.q(mul_104)
    view_50 = decoder_block_2_layer_0_self_attention_q.view(getitem_67, -1, 6, 64);  decoder_block_2_layer_0_self_attention_q = None
    transpose_60 = view_50.transpose(1, 2);  view_50 = None
    decoder_block_2_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.k(mul_104)
    view_51 = decoder_block_2_layer_0_self_attention_k.view(getitem_67, -1, 6, 64);  decoder_block_2_layer_0_self_attention_k = None
    transpose_61 = view_51.transpose(1, 2);  view_51 = None
    decoder_block_2_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.v(mul_104);  mul_104 = None
    view_52 = decoder_block_2_layer_0_self_attention_v.view(getitem_67, -1, 6, 64);  decoder_block_2_layer_0_self_attention_v = None
    transpose_62 = view_52.transpose(1, 2);  view_52 = None
    transpose_63 = transpose_61.transpose(3, 2)
    matmul_24 = torch.matmul(transpose_60, transpose_63);  transpose_60 = transpose_63 = None
    add_87 = matmul_24 + add_65;  matmul_24 = None
    float_15 = add_87.float()
    softmax_12 = torch.nn.functional.softmax(float_15, dim = -1, _stacklevel = 3, dtype = None);  float_15 = None
    type_as_12 = softmax_12.type_as(add_87);  softmax_12 = add_87 = None
    dropout_12 = torch.nn.functional.dropout(type_as_12, p = 0.1, training = False, inplace = False);  type_as_12 = None
    matmul_25 = torch.matmul(dropout_12, transpose_62);  dropout_12 = None
    transpose_64 = matmul_25.transpose(1, 2);  matmul_25 = None
    contiguous_12 = transpose_64.contiguous();  transpose_64 = None
    view_53 = contiguous_12.view(getitem_67, -1, 384);  contiguous_12 = getitem_67 = None
    decoder_block_2_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.o(view_53);  view_53 = None
    decoder_block_2_layer_0_dropout = getattr(getattr(self.decoder.block, "2").layer, "0").dropout(decoder_block_2_layer_0_self_attention_o);  decoder_block_2_layer_0_self_attention_o = None
    add_88 = add_85 + decoder_block_2_layer_0_dropout;  add_85 = decoder_block_2_layer_0_dropout = None
    getattr_80 = add_88.dtype
    eq_55 = getattr_80 == torch.float16;  getattr_80 = None
    size_24 = transpose_61.size()
    getitem_69 = size_24[2];  size_24 = None
    to_55 = add_88.to(torch.float32)
    pow_35 = to_55.pow(2);  to_55 = None
    mean_24 = pow_35.mean(-1, keepdim = True);  pow_35 = None
    add_89 = mean_24 + 1e-06;  mean_24 = None
    rsqrt_24 = torch.rsqrt(add_89);  add_89 = None
    mul_105 = add_88 * rsqrt_24;  rsqrt_24 = None
    decoder_block_2_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "2").layer, "1").layer_norm.weight
    getattr_81 = decoder_block_2_layer_1_layer_norm_weight.dtype
    eq_56 = getattr_81 == torch.float16;  getattr_81 = None
    getattr_82 = decoder_block_2_layer_1_layer_norm_weight.dtype
    to_56 = mul_105.to(getattr_82);  mul_105 = getattr_82 = None
    mul_106 = decoder_block_2_layer_1_layer_norm_weight * to_56;  decoder_block_2_layer_1_layer_norm_weight = to_56 = None
    size_25 = mul_106.size()
    getitem_70 = size_25[slice(None, 2, None)];  size_25 = None
    getitem_71 = getitem_70[0]
    getitem_72 = getitem_70[1];  getitem_70 = None
    size_26 = encoder_dropout_1.size()
    getitem_73 = size_26[1];  size_26 = None
    decoder_block_2_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.q(mul_106);  mul_106 = None
    view_54 = decoder_block_2_layer_1_enc_dec_attention_q.view(getitem_71, -1, 6, 64);  decoder_block_2_layer_1_enc_dec_attention_q = None
    transpose_65 = view_54.transpose(1, 2);  view_54 = None
    decoder_block_2_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_55 = decoder_block_2_layer_1_enc_dec_attention_k.view(getitem_71, -1, 6, 64);  decoder_block_2_layer_1_enc_dec_attention_k = None
    transpose_66 = view_55.transpose(1, 2);  view_55 = None
    decoder_block_2_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_56 = decoder_block_2_layer_1_enc_dec_attention_v.view(getitem_71, -1, 6, 64);  decoder_block_2_layer_1_enc_dec_attention_v = None
    transpose_67 = view_56.transpose(1, 2);  view_56 = None
    transpose_68 = transpose_66.transpose(3, 2)
    matmul_26 = torch.matmul(transpose_65, transpose_68);  transpose_65 = transpose_68 = None
    add_90 = matmul_26 + add_69;  matmul_26 = None
    float_16 = add_90.float()
    softmax_13 = torch.nn.functional.softmax(float_16, dim = -1, _stacklevel = 3, dtype = None);  float_16 = None
    type_as_13 = softmax_13.type_as(add_90);  softmax_13 = add_90 = None
    dropout_13 = torch.nn.functional.dropout(type_as_13, p = 0.1, training = False, inplace = False);  type_as_13 = None
    matmul_27 = torch.matmul(dropout_13, transpose_67);  dropout_13 = None
    transpose_69 = matmul_27.transpose(1, 2);  matmul_27 = None
    contiguous_13 = transpose_69.contiguous();  transpose_69 = None
    view_57 = contiguous_13.view(getitem_71, -1, 384);  contiguous_13 = getitem_71 = None
    decoder_block_2_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.o(view_57);  view_57 = None
    decoder_block_2_layer_1_dropout = getattr(getattr(self.decoder.block, "2").layer, "1").dropout(decoder_block_2_layer_1_enc_dec_attention_o);  decoder_block_2_layer_1_enc_dec_attention_o = None
    add_91 = add_88 + decoder_block_2_layer_1_dropout;  add_88 = decoder_block_2_layer_1_dropout = None
    getattr_83 = add_91.dtype
    eq_57 = getattr_83 == torch.float16;  getattr_83 = None
    to_57 = add_91.to(torch.float32)
    pow_36 = to_57.pow(2);  to_57 = None
    mean_25 = pow_36.mean(-1, keepdim = True);  pow_36 = None
    add_92 = mean_25 + 1e-06;  mean_25 = None
    rsqrt_25 = torch.rsqrt(add_92);  add_92 = None
    mul_107 = add_91 * rsqrt_25;  rsqrt_25 = None
    decoder_block_2_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "2").layer, "2").layer_norm.weight
    getattr_84 = decoder_block_2_layer_2_layer_norm_weight.dtype
    eq_58 = getattr_84 == torch.float16;  getattr_84 = None
    getattr_85 = decoder_block_2_layer_2_layer_norm_weight.dtype
    to_58 = mul_107.to(getattr_85);  mul_107 = getattr_85 = None
    mul_108 = decoder_block_2_layer_2_layer_norm_weight * to_58;  decoder_block_2_layer_2_layer_norm_weight = to_58 = None
    decoder_block_2_layer_2_dense_relu_dense_wi_0 = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.wi_0(mul_108)
    mul_109 = 0.5 * decoder_block_2_layer_2_dense_relu_dense_wi_0
    pow_37 = torch.pow(decoder_block_2_layer_2_dense_relu_dense_wi_0, 3.0)
    mul_110 = 0.044715 * pow_37;  pow_37 = None
    add_93 = decoder_block_2_layer_2_dense_relu_dense_wi_0 + mul_110;  decoder_block_2_layer_2_dense_relu_dense_wi_0 = mul_110 = None
    mul_111 = 0.7978845608028654 * add_93;  add_93 = None
    tanh_10 = torch.tanh(mul_111);  mul_111 = None
    add_94 = 1.0 + tanh_10;  tanh_10 = None
    mul_112 = mul_109 * add_94;  mul_109 = add_94 = None
    decoder_block_2_layer_2_dense_relu_dense_wi_1 = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.wi_1(mul_108);  mul_108 = None
    mul_113 = mul_112 * decoder_block_2_layer_2_dense_relu_dense_wi_1;  mul_112 = decoder_block_2_layer_2_dense_relu_dense_wi_1 = None
    decoder_block_2_layer_2_dense_relu_dense_dropout = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.dropout(mul_113);  mul_113 = None
    decoder_block_2_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.wo.weight
    decoder_block_2_layer_2_dense_relu_dense_wo = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.wo(decoder_block_2_layer_2_dense_relu_dense_dropout);  decoder_block_2_layer_2_dense_relu_dense_dropout = None
    decoder_block_2_layer_2_dropout = getattr(getattr(self.decoder.block, "2").layer, "2").dropout(decoder_block_2_layer_2_dense_relu_dense_wo);  decoder_block_2_layer_2_dense_relu_dense_wo = None
    add_95 = add_91 + decoder_block_2_layer_2_dropout;  add_91 = decoder_block_2_layer_2_dropout = None
    getattr_86 = add_95.dtype
    eq_59 = getattr_86 == torch.float16;  getattr_86 = None
    to_59 = add_95.to(torch.float32)
    pow_38 = to_59.pow(2);  to_59 = None
    mean_26 = pow_38.mean(-1, keepdim = True);  pow_38 = None
    add_96 = mean_26 + 1e-06;  mean_26 = None
    rsqrt_26 = torch.rsqrt(add_96);  add_96 = None
    mul_114 = add_95 * rsqrt_26;  rsqrt_26 = None
    decoder_block_3_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "3").layer, "0").layer_norm.weight
    getattr_87 = decoder_block_3_layer_0_layer_norm_weight.dtype
    eq_60 = getattr_87 == torch.float16;  getattr_87 = None
    getattr_88 = decoder_block_3_layer_0_layer_norm_weight.dtype
    to_60 = mul_114.to(getattr_88);  mul_114 = getattr_88 = None
    mul_115 = decoder_block_3_layer_0_layer_norm_weight * to_60;  decoder_block_3_layer_0_layer_norm_weight = to_60 = None
    size_27 = mul_115.size()
    getitem_74 = size_27[slice(None, 2, None)];  size_27 = None
    getitem_75 = getitem_74[0]
    getitem_76 = getitem_74[1];  getitem_74 = None
    decoder_block_3_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.q(mul_115)
    view_58 = decoder_block_3_layer_0_self_attention_q.view(getitem_75, -1, 6, 64);  decoder_block_3_layer_0_self_attention_q = None
    transpose_70 = view_58.transpose(1, 2);  view_58 = None
    decoder_block_3_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.k(mul_115)
    view_59 = decoder_block_3_layer_0_self_attention_k.view(getitem_75, -1, 6, 64);  decoder_block_3_layer_0_self_attention_k = None
    transpose_71 = view_59.transpose(1, 2);  view_59 = None
    decoder_block_3_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.v(mul_115);  mul_115 = None
    view_60 = decoder_block_3_layer_0_self_attention_v.view(getitem_75, -1, 6, 64);  decoder_block_3_layer_0_self_attention_v = None
    transpose_72 = view_60.transpose(1, 2);  view_60 = None
    transpose_73 = transpose_71.transpose(3, 2)
    matmul_28 = torch.matmul(transpose_70, transpose_73);  transpose_70 = transpose_73 = None
    add_97 = matmul_28 + add_65;  matmul_28 = None
    float_17 = add_97.float()
    softmax_14 = torch.nn.functional.softmax(float_17, dim = -1, _stacklevel = 3, dtype = None);  float_17 = None
    type_as_14 = softmax_14.type_as(add_97);  softmax_14 = add_97 = None
    dropout_14 = torch.nn.functional.dropout(type_as_14, p = 0.1, training = False, inplace = False);  type_as_14 = None
    matmul_29 = torch.matmul(dropout_14, transpose_72);  dropout_14 = None
    transpose_74 = matmul_29.transpose(1, 2);  matmul_29 = None
    contiguous_14 = transpose_74.contiguous();  transpose_74 = None
    view_61 = contiguous_14.view(getitem_75, -1, 384);  contiguous_14 = getitem_75 = None
    decoder_block_3_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.o(view_61);  view_61 = None
    decoder_block_3_layer_0_dropout = getattr(getattr(self.decoder.block, "3").layer, "0").dropout(decoder_block_3_layer_0_self_attention_o);  decoder_block_3_layer_0_self_attention_o = None
    add_98 = add_95 + decoder_block_3_layer_0_dropout;  add_95 = decoder_block_3_layer_0_dropout = None
    getattr_89 = add_98.dtype
    eq_61 = getattr_89 == torch.float16;  getattr_89 = None
    size_28 = transpose_71.size()
    getitem_77 = size_28[2];  size_28 = None
    to_61 = add_98.to(torch.float32)
    pow_39 = to_61.pow(2);  to_61 = None
    mean_27 = pow_39.mean(-1, keepdim = True);  pow_39 = None
    add_99 = mean_27 + 1e-06;  mean_27 = None
    rsqrt_27 = torch.rsqrt(add_99);  add_99 = None
    mul_116 = add_98 * rsqrt_27;  rsqrt_27 = None
    decoder_block_3_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "3").layer, "1").layer_norm.weight
    getattr_90 = decoder_block_3_layer_1_layer_norm_weight.dtype
    eq_62 = getattr_90 == torch.float16;  getattr_90 = None
    getattr_91 = decoder_block_3_layer_1_layer_norm_weight.dtype
    to_62 = mul_116.to(getattr_91);  mul_116 = getattr_91 = None
    mul_117 = decoder_block_3_layer_1_layer_norm_weight * to_62;  decoder_block_3_layer_1_layer_norm_weight = to_62 = None
    size_29 = mul_117.size()
    getitem_78 = size_29[slice(None, 2, None)];  size_29 = None
    getitem_79 = getitem_78[0]
    getitem_80 = getitem_78[1];  getitem_78 = None
    size_30 = encoder_dropout_1.size()
    getitem_81 = size_30[1];  size_30 = None
    decoder_block_3_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.q(mul_117);  mul_117 = None
    view_62 = decoder_block_3_layer_1_enc_dec_attention_q.view(getitem_79, -1, 6, 64);  decoder_block_3_layer_1_enc_dec_attention_q = None
    transpose_75 = view_62.transpose(1, 2);  view_62 = None
    decoder_block_3_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_63 = decoder_block_3_layer_1_enc_dec_attention_k.view(getitem_79, -1, 6, 64);  decoder_block_3_layer_1_enc_dec_attention_k = None
    transpose_76 = view_63.transpose(1, 2);  view_63 = None
    decoder_block_3_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_64 = decoder_block_3_layer_1_enc_dec_attention_v.view(getitem_79, -1, 6, 64);  decoder_block_3_layer_1_enc_dec_attention_v = None
    transpose_77 = view_64.transpose(1, 2);  view_64 = None
    transpose_78 = transpose_76.transpose(3, 2)
    matmul_30 = torch.matmul(transpose_75, transpose_78);  transpose_75 = transpose_78 = None
    add_100 = matmul_30 + add_69;  matmul_30 = None
    float_18 = add_100.float()
    softmax_15 = torch.nn.functional.softmax(float_18, dim = -1, _stacklevel = 3, dtype = None);  float_18 = None
    type_as_15 = softmax_15.type_as(add_100);  softmax_15 = add_100 = None
    dropout_15 = torch.nn.functional.dropout(type_as_15, p = 0.1, training = False, inplace = False);  type_as_15 = None
    matmul_31 = torch.matmul(dropout_15, transpose_77);  dropout_15 = None
    transpose_79 = matmul_31.transpose(1, 2);  matmul_31 = None
    contiguous_15 = transpose_79.contiguous();  transpose_79 = None
    view_65 = contiguous_15.view(getitem_79, -1, 384);  contiguous_15 = getitem_79 = None
    decoder_block_3_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.o(view_65);  view_65 = None
    decoder_block_3_layer_1_dropout = getattr(getattr(self.decoder.block, "3").layer, "1").dropout(decoder_block_3_layer_1_enc_dec_attention_o);  decoder_block_3_layer_1_enc_dec_attention_o = None
    add_101 = add_98 + decoder_block_3_layer_1_dropout;  add_98 = decoder_block_3_layer_1_dropout = None
    getattr_92 = add_101.dtype
    eq_63 = getattr_92 == torch.float16;  getattr_92 = None
    to_63 = add_101.to(torch.float32)
    pow_40 = to_63.pow(2);  to_63 = None
    mean_28 = pow_40.mean(-1, keepdim = True);  pow_40 = None
    add_102 = mean_28 + 1e-06;  mean_28 = None
    rsqrt_28 = torch.rsqrt(add_102);  add_102 = None
    mul_118 = add_101 * rsqrt_28;  rsqrt_28 = None
    decoder_block_3_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "3").layer, "2").layer_norm.weight
    getattr_93 = decoder_block_3_layer_2_layer_norm_weight.dtype
    eq_64 = getattr_93 == torch.float16;  getattr_93 = None
    getattr_94 = decoder_block_3_layer_2_layer_norm_weight.dtype
    to_64 = mul_118.to(getattr_94);  mul_118 = getattr_94 = None
    mul_119 = decoder_block_3_layer_2_layer_norm_weight * to_64;  decoder_block_3_layer_2_layer_norm_weight = to_64 = None
    decoder_block_3_layer_2_dense_relu_dense_wi_0 = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.wi_0(mul_119)
    mul_120 = 0.5 * decoder_block_3_layer_2_dense_relu_dense_wi_0
    pow_41 = torch.pow(decoder_block_3_layer_2_dense_relu_dense_wi_0, 3.0)
    mul_121 = 0.044715 * pow_41;  pow_41 = None
    add_103 = decoder_block_3_layer_2_dense_relu_dense_wi_0 + mul_121;  decoder_block_3_layer_2_dense_relu_dense_wi_0 = mul_121 = None
    mul_122 = 0.7978845608028654 * add_103;  add_103 = None
    tanh_11 = torch.tanh(mul_122);  mul_122 = None
    add_104 = 1.0 + tanh_11;  tanh_11 = None
    mul_123 = mul_120 * add_104;  mul_120 = add_104 = None
    decoder_block_3_layer_2_dense_relu_dense_wi_1 = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.wi_1(mul_119);  mul_119 = None
    mul_124 = mul_123 * decoder_block_3_layer_2_dense_relu_dense_wi_1;  mul_123 = decoder_block_3_layer_2_dense_relu_dense_wi_1 = None
    decoder_block_3_layer_2_dense_relu_dense_dropout = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.dropout(mul_124);  mul_124 = None
    decoder_block_3_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.wo.weight
    decoder_block_3_layer_2_dense_relu_dense_wo = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.wo(decoder_block_3_layer_2_dense_relu_dense_dropout);  decoder_block_3_layer_2_dense_relu_dense_dropout = None
    decoder_block_3_layer_2_dropout = getattr(getattr(self.decoder.block, "3").layer, "2").dropout(decoder_block_3_layer_2_dense_relu_dense_wo);  decoder_block_3_layer_2_dense_relu_dense_wo = None
    add_105 = add_101 + decoder_block_3_layer_2_dropout;  add_101 = decoder_block_3_layer_2_dropout = None
    getattr_95 = add_105.dtype
    eq_65 = getattr_95 == torch.float16;  getattr_95 = None
    to_65 = add_105.to(torch.float32)
    pow_42 = to_65.pow(2);  to_65 = None
    mean_29 = pow_42.mean(-1, keepdim = True);  pow_42 = None
    add_106 = mean_29 + 1e-06;  mean_29 = None
    rsqrt_29 = torch.rsqrt(add_106);  add_106 = None
    mul_125 = add_105 * rsqrt_29;  rsqrt_29 = None
    decoder_block_4_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "4").layer, "0").layer_norm.weight
    getattr_96 = decoder_block_4_layer_0_layer_norm_weight.dtype
    eq_66 = getattr_96 == torch.float16;  getattr_96 = None
    getattr_97 = decoder_block_4_layer_0_layer_norm_weight.dtype
    to_66 = mul_125.to(getattr_97);  mul_125 = getattr_97 = None
    mul_126 = decoder_block_4_layer_0_layer_norm_weight * to_66;  decoder_block_4_layer_0_layer_norm_weight = to_66 = None
    size_31 = mul_126.size()
    getitem_82 = size_31[slice(None, 2, None)];  size_31 = None
    getitem_83 = getitem_82[0]
    getitem_84 = getitem_82[1];  getitem_82 = None
    decoder_block_4_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.q(mul_126)
    view_66 = decoder_block_4_layer_0_self_attention_q.view(getitem_83, -1, 6, 64);  decoder_block_4_layer_0_self_attention_q = None
    transpose_80 = view_66.transpose(1, 2);  view_66 = None
    decoder_block_4_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.k(mul_126)
    view_67 = decoder_block_4_layer_0_self_attention_k.view(getitem_83, -1, 6, 64);  decoder_block_4_layer_0_self_attention_k = None
    transpose_81 = view_67.transpose(1, 2);  view_67 = None
    decoder_block_4_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.v(mul_126);  mul_126 = None
    view_68 = decoder_block_4_layer_0_self_attention_v.view(getitem_83, -1, 6, 64);  decoder_block_4_layer_0_self_attention_v = None
    transpose_82 = view_68.transpose(1, 2);  view_68 = None
    transpose_83 = transpose_81.transpose(3, 2)
    matmul_32 = torch.matmul(transpose_80, transpose_83);  transpose_80 = transpose_83 = None
    add_107 = matmul_32 + add_65;  matmul_32 = None
    float_19 = add_107.float()
    softmax_16 = torch.nn.functional.softmax(float_19, dim = -1, _stacklevel = 3, dtype = None);  float_19 = None
    type_as_16 = softmax_16.type_as(add_107);  softmax_16 = add_107 = None
    dropout_16 = torch.nn.functional.dropout(type_as_16, p = 0.1, training = False, inplace = False);  type_as_16 = None
    matmul_33 = torch.matmul(dropout_16, transpose_82);  dropout_16 = None
    transpose_84 = matmul_33.transpose(1, 2);  matmul_33 = None
    contiguous_16 = transpose_84.contiguous();  transpose_84 = None
    view_69 = contiguous_16.view(getitem_83, -1, 384);  contiguous_16 = getitem_83 = None
    decoder_block_4_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.o(view_69);  view_69 = None
    decoder_block_4_layer_0_dropout = getattr(getattr(self.decoder.block, "4").layer, "0").dropout(decoder_block_4_layer_0_self_attention_o);  decoder_block_4_layer_0_self_attention_o = None
    add_108 = add_105 + decoder_block_4_layer_0_dropout;  add_105 = decoder_block_4_layer_0_dropout = None
    getattr_98 = add_108.dtype
    eq_67 = getattr_98 == torch.float16;  getattr_98 = None
    size_32 = transpose_81.size()
    getitem_85 = size_32[2];  size_32 = None
    to_67 = add_108.to(torch.float32)
    pow_43 = to_67.pow(2);  to_67 = None
    mean_30 = pow_43.mean(-1, keepdim = True);  pow_43 = None
    add_109 = mean_30 + 1e-06;  mean_30 = None
    rsqrt_30 = torch.rsqrt(add_109);  add_109 = None
    mul_127 = add_108 * rsqrt_30;  rsqrt_30 = None
    decoder_block_4_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "4").layer, "1").layer_norm.weight
    getattr_99 = decoder_block_4_layer_1_layer_norm_weight.dtype
    eq_68 = getattr_99 == torch.float16;  getattr_99 = None
    getattr_100 = decoder_block_4_layer_1_layer_norm_weight.dtype
    to_68 = mul_127.to(getattr_100);  mul_127 = getattr_100 = None
    mul_128 = decoder_block_4_layer_1_layer_norm_weight * to_68;  decoder_block_4_layer_1_layer_norm_weight = to_68 = None
    size_33 = mul_128.size()
    getitem_86 = size_33[slice(None, 2, None)];  size_33 = None
    getitem_87 = getitem_86[0]
    getitem_88 = getitem_86[1];  getitem_86 = None
    size_34 = encoder_dropout_1.size()
    getitem_89 = size_34[1];  size_34 = None
    decoder_block_4_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.q(mul_128);  mul_128 = None
    view_70 = decoder_block_4_layer_1_enc_dec_attention_q.view(getitem_87, -1, 6, 64);  decoder_block_4_layer_1_enc_dec_attention_q = None
    transpose_85 = view_70.transpose(1, 2);  view_70 = None
    decoder_block_4_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_71 = decoder_block_4_layer_1_enc_dec_attention_k.view(getitem_87, -1, 6, 64);  decoder_block_4_layer_1_enc_dec_attention_k = None
    transpose_86 = view_71.transpose(1, 2);  view_71 = None
    decoder_block_4_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_72 = decoder_block_4_layer_1_enc_dec_attention_v.view(getitem_87, -1, 6, 64);  decoder_block_4_layer_1_enc_dec_attention_v = None
    transpose_87 = view_72.transpose(1, 2);  view_72 = None
    transpose_88 = transpose_86.transpose(3, 2)
    matmul_34 = torch.matmul(transpose_85, transpose_88);  transpose_85 = transpose_88 = None
    add_110 = matmul_34 + add_69;  matmul_34 = None
    float_20 = add_110.float()
    softmax_17 = torch.nn.functional.softmax(float_20, dim = -1, _stacklevel = 3, dtype = None);  float_20 = None
    type_as_17 = softmax_17.type_as(add_110);  softmax_17 = add_110 = None
    dropout_17 = torch.nn.functional.dropout(type_as_17, p = 0.1, training = False, inplace = False);  type_as_17 = None
    matmul_35 = torch.matmul(dropout_17, transpose_87);  dropout_17 = None
    transpose_89 = matmul_35.transpose(1, 2);  matmul_35 = None
    contiguous_17 = transpose_89.contiguous();  transpose_89 = None
    view_73 = contiguous_17.view(getitem_87, -1, 384);  contiguous_17 = getitem_87 = None
    decoder_block_4_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.o(view_73);  view_73 = None
    decoder_block_4_layer_1_dropout = getattr(getattr(self.decoder.block, "4").layer, "1").dropout(decoder_block_4_layer_1_enc_dec_attention_o);  decoder_block_4_layer_1_enc_dec_attention_o = None
    add_111 = add_108 + decoder_block_4_layer_1_dropout;  add_108 = decoder_block_4_layer_1_dropout = None
    getattr_101 = add_111.dtype
    eq_69 = getattr_101 == torch.float16;  getattr_101 = None
    to_69 = add_111.to(torch.float32)
    pow_44 = to_69.pow(2);  to_69 = None
    mean_31 = pow_44.mean(-1, keepdim = True);  pow_44 = None
    add_112 = mean_31 + 1e-06;  mean_31 = None
    rsqrt_31 = torch.rsqrt(add_112);  add_112 = None
    mul_129 = add_111 * rsqrt_31;  rsqrt_31 = None
    decoder_block_4_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "4").layer, "2").layer_norm.weight
    getattr_102 = decoder_block_4_layer_2_layer_norm_weight.dtype
    eq_70 = getattr_102 == torch.float16;  getattr_102 = None
    getattr_103 = decoder_block_4_layer_2_layer_norm_weight.dtype
    to_70 = mul_129.to(getattr_103);  mul_129 = getattr_103 = None
    mul_130 = decoder_block_4_layer_2_layer_norm_weight * to_70;  decoder_block_4_layer_2_layer_norm_weight = to_70 = None
    decoder_block_4_layer_2_dense_relu_dense_wi_0 = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.wi_0(mul_130)
    mul_131 = 0.5 * decoder_block_4_layer_2_dense_relu_dense_wi_0
    pow_45 = torch.pow(decoder_block_4_layer_2_dense_relu_dense_wi_0, 3.0)
    mul_132 = 0.044715 * pow_45;  pow_45 = None
    add_113 = decoder_block_4_layer_2_dense_relu_dense_wi_0 + mul_132;  decoder_block_4_layer_2_dense_relu_dense_wi_0 = mul_132 = None
    mul_133 = 0.7978845608028654 * add_113;  add_113 = None
    tanh_12 = torch.tanh(mul_133);  mul_133 = None
    add_114 = 1.0 + tanh_12;  tanh_12 = None
    mul_134 = mul_131 * add_114;  mul_131 = add_114 = None
    decoder_block_4_layer_2_dense_relu_dense_wi_1 = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.wi_1(mul_130);  mul_130 = None
    mul_135 = mul_134 * decoder_block_4_layer_2_dense_relu_dense_wi_1;  mul_134 = decoder_block_4_layer_2_dense_relu_dense_wi_1 = None
    decoder_block_4_layer_2_dense_relu_dense_dropout = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.dropout(mul_135);  mul_135 = None
    decoder_block_4_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.wo.weight
    decoder_block_4_layer_2_dense_relu_dense_wo = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.wo(decoder_block_4_layer_2_dense_relu_dense_dropout);  decoder_block_4_layer_2_dense_relu_dense_dropout = None
    decoder_block_4_layer_2_dropout = getattr(getattr(self.decoder.block, "4").layer, "2").dropout(decoder_block_4_layer_2_dense_relu_dense_wo);  decoder_block_4_layer_2_dense_relu_dense_wo = None
    add_115 = add_111 + decoder_block_4_layer_2_dropout;  add_111 = decoder_block_4_layer_2_dropout = None
    getattr_104 = add_115.dtype
    eq_71 = getattr_104 == torch.float16;  getattr_104 = None
    to_71 = add_115.to(torch.float32)
    pow_46 = to_71.pow(2);  to_71 = None
    mean_32 = pow_46.mean(-1, keepdim = True);  pow_46 = None
    add_116 = mean_32 + 1e-06;  mean_32 = None
    rsqrt_32 = torch.rsqrt(add_116);  add_116 = None
    mul_136 = add_115 * rsqrt_32;  rsqrt_32 = None
    decoder_block_5_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "5").layer, "0").layer_norm.weight
    getattr_105 = decoder_block_5_layer_0_layer_norm_weight.dtype
    eq_72 = getattr_105 == torch.float16;  getattr_105 = None
    getattr_106 = decoder_block_5_layer_0_layer_norm_weight.dtype
    to_72 = mul_136.to(getattr_106);  mul_136 = getattr_106 = None
    mul_137 = decoder_block_5_layer_0_layer_norm_weight * to_72;  decoder_block_5_layer_0_layer_norm_weight = to_72 = None
    size_35 = mul_137.size()
    getitem_90 = size_35[slice(None, 2, None)];  size_35 = None
    getitem_91 = getitem_90[0]
    getitem_92 = getitem_90[1];  getitem_90 = None
    decoder_block_5_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.q(mul_137)
    view_74 = decoder_block_5_layer_0_self_attention_q.view(getitem_91, -1, 6, 64);  decoder_block_5_layer_0_self_attention_q = None
    transpose_90 = view_74.transpose(1, 2);  view_74 = None
    decoder_block_5_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.k(mul_137)
    view_75 = decoder_block_5_layer_0_self_attention_k.view(getitem_91, -1, 6, 64);  decoder_block_5_layer_0_self_attention_k = None
    transpose_91 = view_75.transpose(1, 2);  view_75 = None
    decoder_block_5_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.v(mul_137);  mul_137 = None
    view_76 = decoder_block_5_layer_0_self_attention_v.view(getitem_91, -1, 6, 64);  decoder_block_5_layer_0_self_attention_v = None
    transpose_92 = view_76.transpose(1, 2);  view_76 = None
    transpose_93 = transpose_91.transpose(3, 2)
    matmul_36 = torch.matmul(transpose_90, transpose_93);  transpose_90 = transpose_93 = None
    add_117 = matmul_36 + add_65;  matmul_36 = None
    float_21 = add_117.float()
    softmax_18 = torch.nn.functional.softmax(float_21, dim = -1, _stacklevel = 3, dtype = None);  float_21 = None
    type_as_18 = softmax_18.type_as(add_117);  softmax_18 = add_117 = None
    dropout_18 = torch.nn.functional.dropout(type_as_18, p = 0.1, training = False, inplace = False);  type_as_18 = None
    matmul_37 = torch.matmul(dropout_18, transpose_92);  dropout_18 = None
    transpose_94 = matmul_37.transpose(1, 2);  matmul_37 = None
    contiguous_18 = transpose_94.contiguous();  transpose_94 = None
    view_77 = contiguous_18.view(getitem_91, -1, 384);  contiguous_18 = getitem_91 = None
    decoder_block_5_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.o(view_77);  view_77 = None
    decoder_block_5_layer_0_dropout = getattr(getattr(self.decoder.block, "5").layer, "0").dropout(decoder_block_5_layer_0_self_attention_o);  decoder_block_5_layer_0_self_attention_o = None
    add_118 = add_115 + decoder_block_5_layer_0_dropout;  add_115 = decoder_block_5_layer_0_dropout = None
    getattr_107 = add_118.dtype
    eq_73 = getattr_107 == torch.float16;  getattr_107 = None
    size_36 = transpose_91.size()
    getitem_93 = size_36[2];  size_36 = None
    to_73 = add_118.to(torch.float32)
    pow_47 = to_73.pow(2);  to_73 = None
    mean_33 = pow_47.mean(-1, keepdim = True);  pow_47 = None
    add_119 = mean_33 + 1e-06;  mean_33 = None
    rsqrt_33 = torch.rsqrt(add_119);  add_119 = None
    mul_138 = add_118 * rsqrt_33;  rsqrt_33 = None
    decoder_block_5_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "5").layer, "1").layer_norm.weight
    getattr_108 = decoder_block_5_layer_1_layer_norm_weight.dtype
    eq_74 = getattr_108 == torch.float16;  getattr_108 = None
    getattr_109 = decoder_block_5_layer_1_layer_norm_weight.dtype
    to_74 = mul_138.to(getattr_109);  mul_138 = getattr_109 = None
    mul_139 = decoder_block_5_layer_1_layer_norm_weight * to_74;  decoder_block_5_layer_1_layer_norm_weight = to_74 = None
    size_37 = mul_139.size()
    getitem_94 = size_37[slice(None, 2, None)];  size_37 = None
    getitem_95 = getitem_94[0]
    getitem_96 = getitem_94[1];  getitem_94 = None
    size_38 = encoder_dropout_1.size()
    getitem_97 = size_38[1];  size_38 = None
    decoder_block_5_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.q(mul_139);  mul_139 = None
    view_78 = decoder_block_5_layer_1_enc_dec_attention_q.view(getitem_95, -1, 6, 64);  decoder_block_5_layer_1_enc_dec_attention_q = None
    transpose_95 = view_78.transpose(1, 2);  view_78 = None
    decoder_block_5_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_79 = decoder_block_5_layer_1_enc_dec_attention_k.view(getitem_95, -1, 6, 64);  decoder_block_5_layer_1_enc_dec_attention_k = None
    transpose_96 = view_79.transpose(1, 2);  view_79 = None
    decoder_block_5_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_80 = decoder_block_5_layer_1_enc_dec_attention_v.view(getitem_95, -1, 6, 64);  decoder_block_5_layer_1_enc_dec_attention_v = None
    transpose_97 = view_80.transpose(1, 2);  view_80 = None
    transpose_98 = transpose_96.transpose(3, 2)
    matmul_38 = torch.matmul(transpose_95, transpose_98);  transpose_95 = transpose_98 = None
    add_120 = matmul_38 + add_69;  matmul_38 = None
    float_22 = add_120.float()
    softmax_19 = torch.nn.functional.softmax(float_22, dim = -1, _stacklevel = 3, dtype = None);  float_22 = None
    type_as_19 = softmax_19.type_as(add_120);  softmax_19 = add_120 = None
    dropout_19 = torch.nn.functional.dropout(type_as_19, p = 0.1, training = False, inplace = False);  type_as_19 = None
    matmul_39 = torch.matmul(dropout_19, transpose_97);  dropout_19 = None
    transpose_99 = matmul_39.transpose(1, 2);  matmul_39 = None
    contiguous_19 = transpose_99.contiguous();  transpose_99 = None
    view_81 = contiguous_19.view(getitem_95, -1, 384);  contiguous_19 = getitem_95 = None
    decoder_block_5_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.o(view_81);  view_81 = None
    decoder_block_5_layer_1_dropout = getattr(getattr(self.decoder.block, "5").layer, "1").dropout(decoder_block_5_layer_1_enc_dec_attention_o);  decoder_block_5_layer_1_enc_dec_attention_o = None
    add_121 = add_118 + decoder_block_5_layer_1_dropout;  add_118 = decoder_block_5_layer_1_dropout = None
    getattr_110 = add_121.dtype
    eq_75 = getattr_110 == torch.float16;  getattr_110 = None
    to_75 = add_121.to(torch.float32)
    pow_48 = to_75.pow(2);  to_75 = None
    mean_34 = pow_48.mean(-1, keepdim = True);  pow_48 = None
    add_122 = mean_34 + 1e-06;  mean_34 = None
    rsqrt_34 = torch.rsqrt(add_122);  add_122 = None
    mul_140 = add_121 * rsqrt_34;  rsqrt_34 = None
    decoder_block_5_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "5").layer, "2").layer_norm.weight
    getattr_111 = decoder_block_5_layer_2_layer_norm_weight.dtype
    eq_76 = getattr_111 == torch.float16;  getattr_111 = None
    getattr_112 = decoder_block_5_layer_2_layer_norm_weight.dtype
    to_76 = mul_140.to(getattr_112);  mul_140 = getattr_112 = None
    mul_141 = decoder_block_5_layer_2_layer_norm_weight * to_76;  decoder_block_5_layer_2_layer_norm_weight = to_76 = None
    decoder_block_5_layer_2_dense_relu_dense_wi_0 = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.wi_0(mul_141)
    mul_142 = 0.5 * decoder_block_5_layer_2_dense_relu_dense_wi_0
    pow_49 = torch.pow(decoder_block_5_layer_2_dense_relu_dense_wi_0, 3.0)
    mul_143 = 0.044715 * pow_49;  pow_49 = None
    add_123 = decoder_block_5_layer_2_dense_relu_dense_wi_0 + mul_143;  decoder_block_5_layer_2_dense_relu_dense_wi_0 = mul_143 = None
    mul_144 = 0.7978845608028654 * add_123;  add_123 = None
    tanh_13 = torch.tanh(mul_144);  mul_144 = None
    add_124 = 1.0 + tanh_13;  tanh_13 = None
    mul_145 = mul_142 * add_124;  mul_142 = add_124 = None
    decoder_block_5_layer_2_dense_relu_dense_wi_1 = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.wi_1(mul_141);  mul_141 = None
    mul_146 = mul_145 * decoder_block_5_layer_2_dense_relu_dense_wi_1;  mul_145 = decoder_block_5_layer_2_dense_relu_dense_wi_1 = None
    decoder_block_5_layer_2_dense_relu_dense_dropout = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.dropout(mul_146);  mul_146 = None
    decoder_block_5_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.wo.weight
    decoder_block_5_layer_2_dense_relu_dense_wo = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.wo(decoder_block_5_layer_2_dense_relu_dense_dropout);  decoder_block_5_layer_2_dense_relu_dense_dropout = None
    decoder_block_5_layer_2_dropout = getattr(getattr(self.decoder.block, "5").layer, "2").dropout(decoder_block_5_layer_2_dense_relu_dense_wo);  decoder_block_5_layer_2_dense_relu_dense_wo = None
    add_125 = add_121 + decoder_block_5_layer_2_dropout;  add_121 = decoder_block_5_layer_2_dropout = None
    getattr_113 = add_125.dtype
    eq_77 = getattr_113 == torch.float16;  getattr_113 = None
    to_77 = add_125.to(torch.float32)
    pow_50 = to_77.pow(2);  to_77 = None
    mean_35 = pow_50.mean(-1, keepdim = True);  pow_50 = None
    add_126 = mean_35 + 1e-06;  mean_35 = None
    rsqrt_35 = torch.rsqrt(add_126);  add_126 = None
    mul_147 = add_125 * rsqrt_35;  rsqrt_35 = None
    decoder_block_6_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "6").layer, "0").layer_norm.weight
    getattr_114 = decoder_block_6_layer_0_layer_norm_weight.dtype
    eq_78 = getattr_114 == torch.float16;  getattr_114 = None
    getattr_115 = decoder_block_6_layer_0_layer_norm_weight.dtype
    to_78 = mul_147.to(getattr_115);  mul_147 = getattr_115 = None
    mul_148 = decoder_block_6_layer_0_layer_norm_weight * to_78;  decoder_block_6_layer_0_layer_norm_weight = to_78 = None
    size_39 = mul_148.size()
    getitem_98 = size_39[slice(None, 2, None)];  size_39 = None
    getitem_99 = getitem_98[0]
    getitem_100 = getitem_98[1];  getitem_98 = None
    decoder_block_6_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "6").layer, "0").SelfAttention.q(mul_148)
    view_82 = decoder_block_6_layer_0_self_attention_q.view(getitem_99, -1, 6, 64);  decoder_block_6_layer_0_self_attention_q = None
    transpose_100 = view_82.transpose(1, 2);  view_82 = None
    decoder_block_6_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "6").layer, "0").SelfAttention.k(mul_148)
    view_83 = decoder_block_6_layer_0_self_attention_k.view(getitem_99, -1, 6, 64);  decoder_block_6_layer_0_self_attention_k = None
    transpose_101 = view_83.transpose(1, 2);  view_83 = None
    decoder_block_6_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "6").layer, "0").SelfAttention.v(mul_148);  mul_148 = None
    view_84 = decoder_block_6_layer_0_self_attention_v.view(getitem_99, -1, 6, 64);  decoder_block_6_layer_0_self_attention_v = None
    transpose_102 = view_84.transpose(1, 2);  view_84 = None
    transpose_103 = transpose_101.transpose(3, 2)
    matmul_40 = torch.matmul(transpose_100, transpose_103);  transpose_100 = transpose_103 = None
    add_127 = matmul_40 + add_65;  matmul_40 = None
    float_23 = add_127.float()
    softmax_20 = torch.nn.functional.softmax(float_23, dim = -1, _stacklevel = 3, dtype = None);  float_23 = None
    type_as_20 = softmax_20.type_as(add_127);  softmax_20 = add_127 = None
    dropout_20 = torch.nn.functional.dropout(type_as_20, p = 0.1, training = False, inplace = False);  type_as_20 = None
    matmul_41 = torch.matmul(dropout_20, transpose_102);  dropout_20 = None
    transpose_104 = matmul_41.transpose(1, 2);  matmul_41 = None
    contiguous_20 = transpose_104.contiguous();  transpose_104 = None
    view_85 = contiguous_20.view(getitem_99, -1, 384);  contiguous_20 = getitem_99 = None
    decoder_block_6_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "6").layer, "0").SelfAttention.o(view_85);  view_85 = None
    decoder_block_6_layer_0_dropout = getattr(getattr(self.decoder.block, "6").layer, "0").dropout(decoder_block_6_layer_0_self_attention_o);  decoder_block_6_layer_0_self_attention_o = None
    add_128 = add_125 + decoder_block_6_layer_0_dropout;  add_125 = decoder_block_6_layer_0_dropout = None
    getattr_116 = add_128.dtype
    eq_79 = getattr_116 == torch.float16;  getattr_116 = None
    size_40 = transpose_101.size()
    getitem_101 = size_40[2];  size_40 = None
    to_79 = add_128.to(torch.float32)
    pow_51 = to_79.pow(2);  to_79 = None
    mean_36 = pow_51.mean(-1, keepdim = True);  pow_51 = None
    add_129 = mean_36 + 1e-06;  mean_36 = None
    rsqrt_36 = torch.rsqrt(add_129);  add_129 = None
    mul_149 = add_128 * rsqrt_36;  rsqrt_36 = None
    decoder_block_6_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "6").layer, "1").layer_norm.weight
    getattr_117 = decoder_block_6_layer_1_layer_norm_weight.dtype
    eq_80 = getattr_117 == torch.float16;  getattr_117 = None
    getattr_118 = decoder_block_6_layer_1_layer_norm_weight.dtype
    to_80 = mul_149.to(getattr_118);  mul_149 = getattr_118 = None
    mul_150 = decoder_block_6_layer_1_layer_norm_weight * to_80;  decoder_block_6_layer_1_layer_norm_weight = to_80 = None
    size_41 = mul_150.size()
    getitem_102 = size_41[slice(None, 2, None)];  size_41 = None
    getitem_103 = getitem_102[0]
    getitem_104 = getitem_102[1];  getitem_102 = None
    size_42 = encoder_dropout_1.size()
    getitem_105 = size_42[1];  size_42 = None
    decoder_block_6_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "6").layer, "1").EncDecAttention.q(mul_150);  mul_150 = None
    view_86 = decoder_block_6_layer_1_enc_dec_attention_q.view(getitem_103, -1, 6, 64);  decoder_block_6_layer_1_enc_dec_attention_q = None
    transpose_105 = view_86.transpose(1, 2);  view_86 = None
    decoder_block_6_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "6").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_87 = decoder_block_6_layer_1_enc_dec_attention_k.view(getitem_103, -1, 6, 64);  decoder_block_6_layer_1_enc_dec_attention_k = None
    transpose_106 = view_87.transpose(1, 2);  view_87 = None
    decoder_block_6_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "6").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_88 = decoder_block_6_layer_1_enc_dec_attention_v.view(getitem_103, -1, 6, 64);  decoder_block_6_layer_1_enc_dec_attention_v = None
    transpose_107 = view_88.transpose(1, 2);  view_88 = None
    transpose_108 = transpose_106.transpose(3, 2)
    matmul_42 = torch.matmul(transpose_105, transpose_108);  transpose_105 = transpose_108 = None
    add_130 = matmul_42 + add_69;  matmul_42 = None
    float_24 = add_130.float()
    softmax_21 = torch.nn.functional.softmax(float_24, dim = -1, _stacklevel = 3, dtype = None);  float_24 = None
    type_as_21 = softmax_21.type_as(add_130);  softmax_21 = add_130 = None
    dropout_21 = torch.nn.functional.dropout(type_as_21, p = 0.1, training = False, inplace = False);  type_as_21 = None
    matmul_43 = torch.matmul(dropout_21, transpose_107);  dropout_21 = None
    transpose_109 = matmul_43.transpose(1, 2);  matmul_43 = None
    contiguous_21 = transpose_109.contiguous();  transpose_109 = None
    view_89 = contiguous_21.view(getitem_103, -1, 384);  contiguous_21 = getitem_103 = None
    decoder_block_6_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "6").layer, "1").EncDecAttention.o(view_89);  view_89 = None
    decoder_block_6_layer_1_dropout = getattr(getattr(self.decoder.block, "6").layer, "1").dropout(decoder_block_6_layer_1_enc_dec_attention_o);  decoder_block_6_layer_1_enc_dec_attention_o = None
    add_131 = add_128 + decoder_block_6_layer_1_dropout;  add_128 = decoder_block_6_layer_1_dropout = None
    getattr_119 = add_131.dtype
    eq_81 = getattr_119 == torch.float16;  getattr_119 = None
    to_81 = add_131.to(torch.float32)
    pow_52 = to_81.pow(2);  to_81 = None
    mean_37 = pow_52.mean(-1, keepdim = True);  pow_52 = None
    add_132 = mean_37 + 1e-06;  mean_37 = None
    rsqrt_37 = torch.rsqrt(add_132);  add_132 = None
    mul_151 = add_131 * rsqrt_37;  rsqrt_37 = None
    decoder_block_6_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "6").layer, "2").layer_norm.weight
    getattr_120 = decoder_block_6_layer_2_layer_norm_weight.dtype
    eq_82 = getattr_120 == torch.float16;  getattr_120 = None
    getattr_121 = decoder_block_6_layer_2_layer_norm_weight.dtype
    to_82 = mul_151.to(getattr_121);  mul_151 = getattr_121 = None
    mul_152 = decoder_block_6_layer_2_layer_norm_weight * to_82;  decoder_block_6_layer_2_layer_norm_weight = to_82 = None
    decoder_block_6_layer_2_dense_relu_dense_wi_0 = getattr(getattr(self.decoder.block, "6").layer, "2").DenseReluDense.wi_0(mul_152)
    mul_153 = 0.5 * decoder_block_6_layer_2_dense_relu_dense_wi_0
    pow_53 = torch.pow(decoder_block_6_layer_2_dense_relu_dense_wi_0, 3.0)
    mul_154 = 0.044715 * pow_53;  pow_53 = None
    add_133 = decoder_block_6_layer_2_dense_relu_dense_wi_0 + mul_154;  decoder_block_6_layer_2_dense_relu_dense_wi_0 = mul_154 = None
    mul_155 = 0.7978845608028654 * add_133;  add_133 = None
    tanh_14 = torch.tanh(mul_155);  mul_155 = None
    add_134 = 1.0 + tanh_14;  tanh_14 = None
    mul_156 = mul_153 * add_134;  mul_153 = add_134 = None
    decoder_block_6_layer_2_dense_relu_dense_wi_1 = getattr(getattr(self.decoder.block, "6").layer, "2").DenseReluDense.wi_1(mul_152);  mul_152 = None
    mul_157 = mul_156 * decoder_block_6_layer_2_dense_relu_dense_wi_1;  mul_156 = decoder_block_6_layer_2_dense_relu_dense_wi_1 = None
    decoder_block_6_layer_2_dense_relu_dense_dropout = getattr(getattr(self.decoder.block, "6").layer, "2").DenseReluDense.dropout(mul_157);  mul_157 = None
    decoder_block_6_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "6").layer, "2").DenseReluDense.wo.weight
    decoder_block_6_layer_2_dense_relu_dense_wo = getattr(getattr(self.decoder.block, "6").layer, "2").DenseReluDense.wo(decoder_block_6_layer_2_dense_relu_dense_dropout);  decoder_block_6_layer_2_dense_relu_dense_dropout = None
    decoder_block_6_layer_2_dropout = getattr(getattr(self.decoder.block, "6").layer, "2").dropout(decoder_block_6_layer_2_dense_relu_dense_wo);  decoder_block_6_layer_2_dense_relu_dense_wo = None
    add_135 = add_131 + decoder_block_6_layer_2_dropout;  add_131 = decoder_block_6_layer_2_dropout = None
    getattr_122 = add_135.dtype
    eq_83 = getattr_122 == torch.float16;  getattr_122 = None
    to_83 = add_135.to(torch.float32)
    pow_54 = to_83.pow(2);  to_83 = None
    mean_38 = pow_54.mean(-1, keepdim = True);  pow_54 = None
    add_136 = mean_38 + 1e-06;  mean_38 = None
    rsqrt_38 = torch.rsqrt(add_136);  add_136 = None
    mul_158 = add_135 * rsqrt_38;  rsqrt_38 = None
    decoder_block_7_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "7").layer, "0").layer_norm.weight
    getattr_123 = decoder_block_7_layer_0_layer_norm_weight.dtype
    eq_84 = getattr_123 == torch.float16;  getattr_123 = None
    getattr_124 = decoder_block_7_layer_0_layer_norm_weight.dtype
    to_84 = mul_158.to(getattr_124);  mul_158 = getattr_124 = None
    mul_159 = decoder_block_7_layer_0_layer_norm_weight * to_84;  decoder_block_7_layer_0_layer_norm_weight = to_84 = None
    size_43 = mul_159.size()
    getitem_106 = size_43[slice(None, 2, None)];  size_43 = None
    getitem_107 = getitem_106[0]
    getitem_108 = getitem_106[1];  getitem_106 = None
    decoder_block_7_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "7").layer, "0").SelfAttention.q(mul_159)
    view_90 = decoder_block_7_layer_0_self_attention_q.view(getitem_107, -1, 6, 64);  decoder_block_7_layer_0_self_attention_q = None
    transpose_110 = view_90.transpose(1, 2);  view_90 = None
    decoder_block_7_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "7").layer, "0").SelfAttention.k(mul_159)
    view_91 = decoder_block_7_layer_0_self_attention_k.view(getitem_107, -1, 6, 64);  decoder_block_7_layer_0_self_attention_k = None
    transpose_111 = view_91.transpose(1, 2);  view_91 = None
    decoder_block_7_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "7").layer, "0").SelfAttention.v(mul_159);  mul_159 = None
    view_92 = decoder_block_7_layer_0_self_attention_v.view(getitem_107, -1, 6, 64);  decoder_block_7_layer_0_self_attention_v = None
    transpose_112 = view_92.transpose(1, 2);  view_92 = None
    transpose_113 = transpose_111.transpose(3, 2)
    matmul_44 = torch.matmul(transpose_110, transpose_113);  transpose_110 = transpose_113 = None
    add_137 = matmul_44 + add_65;  matmul_44 = add_65 = None
    float_25 = add_137.float()
    softmax_22 = torch.nn.functional.softmax(float_25, dim = -1, _stacklevel = 3, dtype = None);  float_25 = None
    type_as_22 = softmax_22.type_as(add_137);  softmax_22 = add_137 = None
    dropout_22 = torch.nn.functional.dropout(type_as_22, p = 0.1, training = False, inplace = False);  type_as_22 = None
    matmul_45 = torch.matmul(dropout_22, transpose_112);  dropout_22 = None
    transpose_114 = matmul_45.transpose(1, 2);  matmul_45 = None
    contiguous_22 = transpose_114.contiguous();  transpose_114 = None
    view_93 = contiguous_22.view(getitem_107, -1, 384);  contiguous_22 = getitem_107 = None
    decoder_block_7_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "7").layer, "0").SelfAttention.o(view_93);  view_93 = None
    decoder_block_7_layer_0_dropout = getattr(getattr(self.decoder.block, "7").layer, "0").dropout(decoder_block_7_layer_0_self_attention_o);  decoder_block_7_layer_0_self_attention_o = None
    add_138 = add_135 + decoder_block_7_layer_0_dropout;  add_135 = decoder_block_7_layer_0_dropout = None
    getattr_125 = add_138.dtype
    eq_85 = getattr_125 == torch.float16;  getattr_125 = None
    size_44 = transpose_111.size()
    getitem_109 = size_44[2];  size_44 = None
    to_85 = add_138.to(torch.float32)
    pow_55 = to_85.pow(2);  to_85 = None
    mean_39 = pow_55.mean(-1, keepdim = True);  pow_55 = None
    add_139 = mean_39 + 1e-06;  mean_39 = None
    rsqrt_39 = torch.rsqrt(add_139);  add_139 = None
    mul_160 = add_138 * rsqrt_39;  rsqrt_39 = None
    decoder_block_7_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "7").layer, "1").layer_norm.weight
    getattr_126 = decoder_block_7_layer_1_layer_norm_weight.dtype
    eq_86 = getattr_126 == torch.float16;  getattr_126 = None
    getattr_127 = decoder_block_7_layer_1_layer_norm_weight.dtype
    to_86 = mul_160.to(getattr_127);  mul_160 = getattr_127 = None
    mul_161 = decoder_block_7_layer_1_layer_norm_weight * to_86;  decoder_block_7_layer_1_layer_norm_weight = to_86 = None
    size_45 = mul_161.size()
    getitem_110 = size_45[slice(None, 2, None)];  size_45 = None
    getitem_111 = getitem_110[0]
    getitem_112 = getitem_110[1];  getitem_110 = None
    size_46 = encoder_dropout_1.size()
    getitem_113 = size_46[1];  size_46 = None
    decoder_block_7_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "7").layer, "1").EncDecAttention.q(mul_161);  mul_161 = None
    view_94 = decoder_block_7_layer_1_enc_dec_attention_q.view(getitem_111, -1, 6, 64);  decoder_block_7_layer_1_enc_dec_attention_q = None
    transpose_115 = view_94.transpose(1, 2);  view_94 = None
    decoder_block_7_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "7").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_95 = decoder_block_7_layer_1_enc_dec_attention_k.view(getitem_111, -1, 6, 64);  decoder_block_7_layer_1_enc_dec_attention_k = None
    transpose_116 = view_95.transpose(1, 2);  view_95 = None
    decoder_block_7_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "7").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_96 = decoder_block_7_layer_1_enc_dec_attention_v.view(getitem_111, -1, 6, 64);  decoder_block_7_layer_1_enc_dec_attention_v = None
    transpose_117 = view_96.transpose(1, 2);  view_96 = None
    transpose_118 = transpose_116.transpose(3, 2)
    matmul_46 = torch.matmul(transpose_115, transpose_118);  transpose_115 = transpose_118 = None
    add_140 = matmul_46 + add_69;  matmul_46 = add_69 = None
    float_26 = add_140.float()
    softmax_23 = torch.nn.functional.softmax(float_26, dim = -1, _stacklevel = 3, dtype = None);  float_26 = None
    type_as_23 = softmax_23.type_as(add_140);  softmax_23 = add_140 = None
    dropout_23 = torch.nn.functional.dropout(type_as_23, p = 0.1, training = False, inplace = False);  type_as_23 = None
    matmul_47 = torch.matmul(dropout_23, transpose_117);  dropout_23 = None
    transpose_119 = matmul_47.transpose(1, 2);  matmul_47 = None
    contiguous_23 = transpose_119.contiguous();  transpose_119 = None
    view_97 = contiguous_23.view(getitem_111, -1, 384);  contiguous_23 = getitem_111 = None
    decoder_block_7_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "7").layer, "1").EncDecAttention.o(view_97);  view_97 = None
    decoder_block_7_layer_1_dropout = getattr(getattr(self.decoder.block, "7").layer, "1").dropout(decoder_block_7_layer_1_enc_dec_attention_o);  decoder_block_7_layer_1_enc_dec_attention_o = None
    add_141 = add_138 + decoder_block_7_layer_1_dropout;  add_138 = decoder_block_7_layer_1_dropout = None
    getattr_128 = add_141.dtype
    eq_87 = getattr_128 == torch.float16;  getattr_128 = None
    to_87 = add_141.to(torch.float32)
    pow_56 = to_87.pow(2);  to_87 = None
    mean_40 = pow_56.mean(-1, keepdim = True);  pow_56 = None
    add_142 = mean_40 + 1e-06;  mean_40 = None
    rsqrt_40 = torch.rsqrt(add_142);  add_142 = None
    mul_162 = add_141 * rsqrt_40;  rsqrt_40 = None
    decoder_block_7_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "7").layer, "2").layer_norm.weight
    getattr_129 = decoder_block_7_layer_2_layer_norm_weight.dtype
    eq_88 = getattr_129 == torch.float16;  getattr_129 = None
    getattr_130 = decoder_block_7_layer_2_layer_norm_weight.dtype
    to_88 = mul_162.to(getattr_130);  mul_162 = getattr_130 = None
    mul_163 = decoder_block_7_layer_2_layer_norm_weight * to_88;  decoder_block_7_layer_2_layer_norm_weight = to_88 = None
    decoder_block_7_layer_2_dense_relu_dense_wi_0 = getattr(getattr(self.decoder.block, "7").layer, "2").DenseReluDense.wi_0(mul_163)
    mul_164 = 0.5 * decoder_block_7_layer_2_dense_relu_dense_wi_0
    pow_57 = torch.pow(decoder_block_7_layer_2_dense_relu_dense_wi_0, 3.0)
    mul_165 = 0.044715 * pow_57;  pow_57 = None
    add_143 = decoder_block_7_layer_2_dense_relu_dense_wi_0 + mul_165;  decoder_block_7_layer_2_dense_relu_dense_wi_0 = mul_165 = None
    mul_166 = 0.7978845608028654 * add_143;  add_143 = None
    tanh_15 = torch.tanh(mul_166);  mul_166 = None
    add_144 = 1.0 + tanh_15;  tanh_15 = None
    mul_167 = mul_164 * add_144;  mul_164 = add_144 = None
    decoder_block_7_layer_2_dense_relu_dense_wi_1 = getattr(getattr(self.decoder.block, "7").layer, "2").DenseReluDense.wi_1(mul_163);  mul_163 = None
    mul_168 = mul_167 * decoder_block_7_layer_2_dense_relu_dense_wi_1;  mul_167 = decoder_block_7_layer_2_dense_relu_dense_wi_1 = None
    decoder_block_7_layer_2_dense_relu_dense_dropout = getattr(getattr(self.decoder.block, "7").layer, "2").DenseReluDense.dropout(mul_168);  mul_168 = None
    decoder_block_7_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "7").layer, "2").DenseReluDense.wo.weight
    decoder_block_7_layer_2_dense_relu_dense_wo = getattr(getattr(self.decoder.block, "7").layer, "2").DenseReluDense.wo(decoder_block_7_layer_2_dense_relu_dense_dropout);  decoder_block_7_layer_2_dense_relu_dense_dropout = None
    decoder_block_7_layer_2_dropout = getattr(getattr(self.decoder.block, "7").layer, "2").dropout(decoder_block_7_layer_2_dense_relu_dense_wo);  decoder_block_7_layer_2_dense_relu_dense_wo = None
    add_145 = add_141 + decoder_block_7_layer_2_dropout;  add_141 = decoder_block_7_layer_2_dropout = None
    getattr_131 = add_145.dtype
    eq_89 = getattr_131 == torch.float16;  getattr_131 = None
    to_89 = add_145.to(torch.float32)
    pow_58 = to_89.pow(2);  to_89 = None
    mean_41 = pow_58.mean(-1, keepdim = True);  pow_58 = None
    add_146 = mean_41 + 1e-06;  mean_41 = None
    rsqrt_41 = torch.rsqrt(add_146);  add_146 = None
    mul_169 = add_145 * rsqrt_41;  add_145 = rsqrt_41 = None
    decoder_final_layer_norm_weight = self.decoder.final_layer_norm.weight
    getattr_132 = decoder_final_layer_norm_weight.dtype
    eq_90 = getattr_132 == torch.float16;  getattr_132 = None
    getattr_133 = decoder_final_layer_norm_weight.dtype
    to_90 = mul_169.to(getattr_133);  mul_169 = getattr_133 = None
    mul_170 = decoder_final_layer_norm_weight * to_90;  decoder_final_layer_norm_weight = to_90 = None
    decoder_dropout_1 = self.decoder.dropout(mul_170);  mul_170 = None
    lm_head = self.lm_head(decoder_dropout_1);  decoder_dropout_1 = None
    getattr_134 = lm_head.device
    to_91 = labels.to(getattr_134);  labels = getattr_134 = None
    size_47 = lm_head.size(-1)
    view_98 = lm_head.view(-1, size_47);  size_47 = None
    view_99 = to_91.view(-1);  to_91 = None
    crossentropyloss_0 = self.crossentropyloss_0(view_98, view_99);  view_98 = view_99 = None
    return {'loss': crossentropyloss_0, 'logits': lm_head, 'past_key_values': ((transpose_41, transpose_42, transpose_46, transpose_47), (transpose_51, transpose_52, transpose_56, transpose_57), (transpose_61, transpose_62, transpose_66, transpose_67), (transpose_71, transpose_72, transpose_76, transpose_77), (transpose_81, transpose_82, transpose_86, transpose_87), (transpose_91, transpose_92, transpose_96, transpose_97), (transpose_101, transpose_102, transpose_106, transpose_107), (transpose_111, transpose_112, transpose_116, transpose_117)), 'encoder_last_hidden_state': encoder_dropout_1}
    
********************************************************************************************************************************************************************************************************

torch.fx._symbolic_trace.wrap("src_patch_linear_layer_linear_layer_triton_wrapper")

def forward(self, input_ids : torch.Tensor, labels : torch.Tensor):
    size = input_ids.size()
    getitem = size[-1]
    view = input_ids.view(-1, getitem);  input_ids = getitem = None
    shared = self.shared(view);  view = None
    getitem_1 = size[0]
    getitem_2 = size[1];  size = None
    getattr_1 = shared.device
    ones = torch.ones(getitem_1, getitem_2, device = getattr_1);  getitem_1 = getitem_2 = getattr_1 = None
    dim = ones.dim()
    eq = dim == 2;  dim = None
    dim_1 = ones.dim()
    eq_1 = dim_1 == 3;  dim_1 = None
    dim_2 = ones.dim()
    eq_2 = dim_2 == 2;  dim_2 = None
    getitem_3 = ones[(slice(None, None, None), None, None, slice(None, None, None))];  ones = None
    to = getitem_3.to(dtype = torch.float16);  getitem_3 = None
    sub = 1.0 - to;  to = None
    mul = sub * -65504.0;  sub = None
    encoder_dropout = self.encoder.dropout(shared);  shared = None
    to_1 = encoder_dropout.to(torch.float32)
    pow_1 = to_1.pow(2);  to_1 = None
    mean = pow_1.mean(-1, keepdim = True);  pow_1 = None
    add = mean + 1e-06;  mean = None
    rsqrt = torch.rsqrt(add);  add = None
    mul_1 = encoder_dropout * rsqrt;  rsqrt = None
    encoder_block_0_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "0").layer, "0").layer_norm.weight
    getattr_2 = encoder_block_0_layer_0_layer_norm_weight.dtype
    eq_3 = getattr_2 == torch.float16;  getattr_2 = None
    getattr_3 = encoder_block_0_layer_0_layer_norm_weight.dtype
    to_2 = mul_1.to(getattr_3);  mul_1 = getattr_3 = None
    mul_2 = encoder_block_0_layer_0_layer_norm_weight * to_2;  encoder_block_0_layer_0_layer_norm_weight = to_2 = None
    size_1 = mul_2.size()
    getitem_4 = size_1[slice(None, 2, None)];  size_1 = None
    getitem_5 = getitem_4[0]
    getitem_6 = getitem_4[1];  getitem_4 = None
    encoder_block_0_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.q(mul_2)
    view_1 = encoder_block_0_layer_0_self_attention_q.view(getitem_5, -1, 6, 64);  encoder_block_0_layer_0_self_attention_q = None
    transpose = view_1.transpose(1, 2);  view_1 = None
    encoder_block_0_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.k(mul_2)
    view_2 = encoder_block_0_layer_0_self_attention_k.view(getitem_5, -1, 6, 64);  encoder_block_0_layer_0_self_attention_k = None
    transpose_1 = view_2.transpose(1, 2);  view_2 = None
    encoder_block_0_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.v(mul_2);  mul_2 = None
    view_3 = encoder_block_0_layer_0_self_attention_v.view(getitem_5, -1, 6, 64);  encoder_block_0_layer_0_self_attention_v = None
    transpose_2 = view_3.transpose(1, 2);  view_3 = None
    transpose_3 = transpose_1.transpose(3, 2);  transpose_1 = None
    matmul = torch.matmul(transpose, transpose_3);  transpose = transpose_3 = None
    getattr_4 = matmul.device
    arange = torch.arange(getitem_6, dtype = torch.int64, device = getattr_4)
    getitem_7 = arange[(slice(None, None, None), None)];  arange = None
    arange_1 = torch.arange(getitem_6, dtype = torch.int64, device = getattr_4);  getitem_6 = getattr_4 = None
    getitem_8 = arange_1[(None, slice(None, None, None))];  arange_1 = None
    sub_1 = getitem_8 - getitem_7;  getitem_8 = getitem_7 = None
    gt = sub_1 > 0
    to_3 = gt.to(torch.int64);  gt = None
    mul_3 = to_3 * 16;  to_3 = None
    add_1 = 0 + mul_3;  mul_3 = None
    abs_1 = torch.abs(sub_1);  sub_1 = None
    lt = abs_1 < 8
    float_1 = abs_1.float()
    truediv = float_1 / 8;  float_1 = None
    log = torch.log(truediv);  truediv = None
    truediv_1 = log / 2.772588722239781;  log = None
    mul_4 = truediv_1 * 8;  truediv_1 = None
    to_4 = mul_4.to(torch.int64);  mul_4 = None
    add_2 = 8 + to_4;  to_4 = None
    full_like = torch.full_like(add_2, 15)
    min_1 = torch.min(add_2, full_like);  add_2 = full_like = None
    where = torch.where(lt, abs_1, min_1);  lt = abs_1 = min_1 = None
    add_3 = add_1 + where;  add_1 = where = None
    encoder_block_0_layer_0_self_attention_relative_attention_bias = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.relative_attention_bias(add_3);  add_3 = None
    permute = encoder_block_0_layer_0_self_attention_relative_attention_bias.permute([2, 0, 1]);  encoder_block_0_layer_0_self_attention_relative_attention_bias = None
    unsqueeze = permute.unsqueeze(0);  permute = None
    add_4 = unsqueeze + mul;  unsqueeze = mul = None
    add_5 = matmul + add_4;  matmul = None
    float_2 = add_5.float()
    softmax = torch.nn.functional.softmax(float_2, dim = -1, _stacklevel = 3, dtype = None);  float_2 = None
    type_as = softmax.type_as(add_5);  softmax = add_5 = None
    dropout = torch.nn.functional.dropout(type_as, p = 0.1, training = False, inplace = False);  type_as = None
    matmul_1 = torch.matmul(dropout, transpose_2);  dropout = transpose_2 = None
    transpose_4 = matmul_1.transpose(1, 2);  matmul_1 = None
    contiguous = transpose_4.contiguous();  transpose_4 = None
    view_4 = contiguous.view(getitem_5, -1, 384);  contiguous = getitem_5 = None
    encoder_block_0_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.o(view_4);  view_4 = None
    encoder_block_0_layer_0_dropout = getattr(getattr(self.encoder.block, "0").layer, "0").dropout(encoder_block_0_layer_0_self_attention_o);  encoder_block_0_layer_0_self_attention_o = None
    add_6 = encoder_dropout + encoder_block_0_layer_0_dropout;  encoder_dropout = encoder_block_0_layer_0_dropout = None
    getattr_5 = add_6.dtype
    eq_4 = getattr_5 == torch.float16;  getattr_5 = None
    to_5 = add_6.to(torch.float32)
    pow_2 = to_5.pow(2);  to_5 = None
    mean_1 = pow_2.mean(-1, keepdim = True);  pow_2 = None
    add_7 = mean_1 + 1e-06;  mean_1 = None
    rsqrt_1 = torch.rsqrt(add_7);  add_7 = None
    mul_5 = add_6 * rsqrt_1;  rsqrt_1 = None
    encoder_block_0_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "0").layer, "1").layer_norm.weight
    getattr_6 = encoder_block_0_layer_1_layer_norm_weight.dtype
    eq_5 = getattr_6 == torch.float16;  getattr_6 = None
    getattr_7 = encoder_block_0_layer_1_layer_norm_weight.dtype
    to_6 = mul_5.to(getattr_7);  mul_5 = getattr_7 = None
    mul_6 = encoder_block_0_layer_1_layer_norm_weight * to_6;  encoder_block_0_layer_1_layer_norm_weight = to_6 = None
    encoder_block_0_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.wo.weight
    linear1 = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.wi_0
    linear_layer_triton_wrapper = src_patch_linear_layer_linear_layer_triton_wrapper(mul_6, linear1, activation = 'fast_gelu');  linear1 = None
    linear2 = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.wi_1(mul_6);  mul_6 = None
    mul_171 = linear_layer_triton_wrapper * linear2;  linear_layer_triton_wrapper = linear2 = None
    dropout_24 = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.dropout(mul_171);  mul_171 = None
    linear3 = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.wo(dropout_24);  dropout_24 = None
    encoder_block_0_layer_1_dropout = getattr(getattr(self.encoder.block, "0").layer, "1").dropout(linear3);  linear3 = None
    add_10 = add_6 + encoder_block_0_layer_1_dropout;  add_6 = encoder_block_0_layer_1_dropout = None
    getattr_8 = add_10.dtype
    eq_6 = getattr_8 == torch.float16;  getattr_8 = None
    to_7 = add_10.to(torch.float32)
    pow_4 = to_7.pow(2);  to_7 = None
    mean_2 = pow_4.mean(-1, keepdim = True);  pow_4 = None
    add_11 = mean_2 + 1e-06;  mean_2 = None
    rsqrt_2 = torch.rsqrt(add_11);  add_11 = None
    mul_12 = add_10 * rsqrt_2;  rsqrt_2 = None
    encoder_block_1_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "1").layer, "0").layer_norm.weight
    getattr_9 = encoder_block_1_layer_0_layer_norm_weight.dtype
    eq_7 = getattr_9 == torch.float16;  getattr_9 = None
    getattr_10 = encoder_block_1_layer_0_layer_norm_weight.dtype
    to_8 = mul_12.to(getattr_10);  mul_12 = getattr_10 = None
    mul_13 = encoder_block_1_layer_0_layer_norm_weight * to_8;  encoder_block_1_layer_0_layer_norm_weight = to_8 = None
    size_2 = mul_13.size()
    getitem_9 = size_2[slice(None, 2, None)];  size_2 = None
    getitem_10 = getitem_9[0]
    getitem_11 = getitem_9[1];  getitem_9 = None
    encoder_block_1_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.q(mul_13)
    view_5 = encoder_block_1_layer_0_self_attention_q.view(getitem_10, -1, 6, 64);  encoder_block_1_layer_0_self_attention_q = None
    transpose_5 = view_5.transpose(1, 2);  view_5 = None
    encoder_block_1_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.k(mul_13)
    view_6 = encoder_block_1_layer_0_self_attention_k.view(getitem_10, -1, 6, 64);  encoder_block_1_layer_0_self_attention_k = None
    transpose_6 = view_6.transpose(1, 2);  view_6 = None
    encoder_block_1_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.v(mul_13);  mul_13 = None
    view_7 = encoder_block_1_layer_0_self_attention_v.view(getitem_10, -1, 6, 64);  encoder_block_1_layer_0_self_attention_v = None
    transpose_7 = view_7.transpose(1, 2);  view_7 = None
    transpose_8 = transpose_6.transpose(3, 2);  transpose_6 = None
    matmul_2 = torch.matmul(transpose_5, transpose_8);  transpose_5 = transpose_8 = None
    add_12 = matmul_2 + add_4;  matmul_2 = None
    float_3 = add_12.float()
    softmax_1 = torch.nn.functional.softmax(float_3, dim = -1, _stacklevel = 3, dtype = None);  float_3 = None
    type_as_1 = softmax_1.type_as(add_12);  softmax_1 = add_12 = None
    dropout_1 = torch.nn.functional.dropout(type_as_1, p = 0.1, training = False, inplace = False);  type_as_1 = None
    matmul_3 = torch.matmul(dropout_1, transpose_7);  dropout_1 = transpose_7 = None
    transpose_9 = matmul_3.transpose(1, 2);  matmul_3 = None
    contiguous_1 = transpose_9.contiguous();  transpose_9 = None
    view_8 = contiguous_1.view(getitem_10, -1, 384);  contiguous_1 = getitem_10 = None
    encoder_block_1_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.o(view_8);  view_8 = None
    encoder_block_1_layer_0_dropout = getattr(getattr(self.encoder.block, "1").layer, "0").dropout(encoder_block_1_layer_0_self_attention_o);  encoder_block_1_layer_0_self_attention_o = None
    add_13 = add_10 + encoder_block_1_layer_0_dropout;  add_10 = encoder_block_1_layer_0_dropout = None
    getattr_11 = add_13.dtype
    eq_8 = getattr_11 == torch.float16;  getattr_11 = None
    to_9 = add_13.to(torch.float32)
    pow_5 = to_9.pow(2);  to_9 = None
    mean_3 = pow_5.mean(-1, keepdim = True);  pow_5 = None
    add_14 = mean_3 + 1e-06;  mean_3 = None
    rsqrt_3 = torch.rsqrt(add_14);  add_14 = None
    mul_14 = add_13 * rsqrt_3;  rsqrt_3 = None
    encoder_block_1_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "1").layer, "1").layer_norm.weight
    getattr_12 = encoder_block_1_layer_1_layer_norm_weight.dtype
    eq_9 = getattr_12 == torch.float16;  getattr_12 = None
    getattr_13 = encoder_block_1_layer_1_layer_norm_weight.dtype
    to_10 = mul_14.to(getattr_13);  mul_14 = getattr_13 = None
    mul_15 = encoder_block_1_layer_1_layer_norm_weight * to_10;  encoder_block_1_layer_1_layer_norm_weight = to_10 = None
    encoder_block_1_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.wo.weight
    linear1_1 = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.wi_0
    linear_layer_triton_wrapper_1 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_15, linear1_1, activation = 'fast_gelu');  linear1_1 = None
    linear2_1 = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.wi_1(mul_15);  mul_15 = None
    mul_172 = linear_layer_triton_wrapper_1 * linear2_1;  linear_layer_triton_wrapper_1 = linear2_1 = None
    dropout_25 = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.dropout(mul_172);  mul_172 = None
    linear3_1 = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.wo(dropout_25);  dropout_25 = None
    encoder_block_1_layer_1_dropout = getattr(getattr(self.encoder.block, "1").layer, "1").dropout(linear3_1);  linear3_1 = None
    add_17 = add_13 + encoder_block_1_layer_1_dropout;  add_13 = encoder_block_1_layer_1_dropout = None
    getattr_14 = add_17.dtype
    eq_10 = getattr_14 == torch.float16;  getattr_14 = None
    to_11 = add_17.to(torch.float32)
    pow_7 = to_11.pow(2);  to_11 = None
    mean_4 = pow_7.mean(-1, keepdim = True);  pow_7 = None
    add_18 = mean_4 + 1e-06;  mean_4 = None
    rsqrt_4 = torch.rsqrt(add_18);  add_18 = None
    mul_21 = add_17 * rsqrt_4;  rsqrt_4 = None
    encoder_block_2_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "2").layer, "0").layer_norm.weight
    getattr_15 = encoder_block_2_layer_0_layer_norm_weight.dtype
    eq_11 = getattr_15 == torch.float16;  getattr_15 = None
    getattr_16 = encoder_block_2_layer_0_layer_norm_weight.dtype
    to_12 = mul_21.to(getattr_16);  mul_21 = getattr_16 = None
    mul_22 = encoder_block_2_layer_0_layer_norm_weight * to_12;  encoder_block_2_layer_0_layer_norm_weight = to_12 = None
    size_3 = mul_22.size()
    getitem_12 = size_3[slice(None, 2, None)];  size_3 = None
    getitem_13 = getitem_12[0]
    getitem_14 = getitem_12[1];  getitem_12 = None
    encoder_block_2_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.q(mul_22)
    view_9 = encoder_block_2_layer_0_self_attention_q.view(getitem_13, -1, 6, 64);  encoder_block_2_layer_0_self_attention_q = None
    transpose_10 = view_9.transpose(1, 2);  view_9 = None
    encoder_block_2_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.k(mul_22)
    view_10 = encoder_block_2_layer_0_self_attention_k.view(getitem_13, -1, 6, 64);  encoder_block_2_layer_0_self_attention_k = None
    transpose_11 = view_10.transpose(1, 2);  view_10 = None
    encoder_block_2_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.v(mul_22);  mul_22 = None
    view_11 = encoder_block_2_layer_0_self_attention_v.view(getitem_13, -1, 6, 64);  encoder_block_2_layer_0_self_attention_v = None
    transpose_12 = view_11.transpose(1, 2);  view_11 = None
    transpose_13 = transpose_11.transpose(3, 2);  transpose_11 = None
    matmul_4 = torch.matmul(transpose_10, transpose_13);  transpose_10 = transpose_13 = None
    add_19 = matmul_4 + add_4;  matmul_4 = None
    float_4 = add_19.float()
    softmax_2 = torch.nn.functional.softmax(float_4, dim = -1, _stacklevel = 3, dtype = None);  float_4 = None
    type_as_2 = softmax_2.type_as(add_19);  softmax_2 = add_19 = None
    dropout_2 = torch.nn.functional.dropout(type_as_2, p = 0.1, training = False, inplace = False);  type_as_2 = None
    matmul_5 = torch.matmul(dropout_2, transpose_12);  dropout_2 = transpose_12 = None
    transpose_14 = matmul_5.transpose(1, 2);  matmul_5 = None
    contiguous_2 = transpose_14.contiguous();  transpose_14 = None
    view_12 = contiguous_2.view(getitem_13, -1, 384);  contiguous_2 = getitem_13 = None
    encoder_block_2_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.o(view_12);  view_12 = None
    encoder_block_2_layer_0_dropout = getattr(getattr(self.encoder.block, "2").layer, "0").dropout(encoder_block_2_layer_0_self_attention_o);  encoder_block_2_layer_0_self_attention_o = None
    add_20 = add_17 + encoder_block_2_layer_0_dropout;  add_17 = encoder_block_2_layer_0_dropout = None
    getattr_17 = add_20.dtype
    eq_12 = getattr_17 == torch.float16;  getattr_17 = None
    to_13 = add_20.to(torch.float32)
    pow_8 = to_13.pow(2);  to_13 = None
    mean_5 = pow_8.mean(-1, keepdim = True);  pow_8 = None
    add_21 = mean_5 + 1e-06;  mean_5 = None
    rsqrt_5 = torch.rsqrt(add_21);  add_21 = None
    mul_23 = add_20 * rsqrt_5;  rsqrt_5 = None
    encoder_block_2_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "2").layer, "1").layer_norm.weight
    getattr_18 = encoder_block_2_layer_1_layer_norm_weight.dtype
    eq_13 = getattr_18 == torch.float16;  getattr_18 = None
    getattr_19 = encoder_block_2_layer_1_layer_norm_weight.dtype
    to_14 = mul_23.to(getattr_19);  mul_23 = getattr_19 = None
    mul_24 = encoder_block_2_layer_1_layer_norm_weight * to_14;  encoder_block_2_layer_1_layer_norm_weight = to_14 = None
    encoder_block_2_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.wo.weight
    linear1_2 = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.wi_0
    linear_layer_triton_wrapper_2 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_24, linear1_2, activation = 'fast_gelu');  linear1_2 = None
    linear2_2 = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.wi_1(mul_24);  mul_24 = None
    mul_173 = linear_layer_triton_wrapper_2 * linear2_2;  linear_layer_triton_wrapper_2 = linear2_2 = None
    dropout_26 = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.dropout(mul_173);  mul_173 = None
    linear3_2 = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.wo(dropout_26);  dropout_26 = None
    encoder_block_2_layer_1_dropout = getattr(getattr(self.encoder.block, "2").layer, "1").dropout(linear3_2);  linear3_2 = None
    add_24 = add_20 + encoder_block_2_layer_1_dropout;  add_20 = encoder_block_2_layer_1_dropout = None
    getattr_20 = add_24.dtype
    eq_14 = getattr_20 == torch.float16;  getattr_20 = None
    to_15 = add_24.to(torch.float32)
    pow_10 = to_15.pow(2);  to_15 = None
    mean_6 = pow_10.mean(-1, keepdim = True);  pow_10 = None
    add_25 = mean_6 + 1e-06;  mean_6 = None
    rsqrt_6 = torch.rsqrt(add_25);  add_25 = None
    mul_30 = add_24 * rsqrt_6;  rsqrt_6 = None
    encoder_block_3_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "3").layer, "0").layer_norm.weight
    getattr_21 = encoder_block_3_layer_0_layer_norm_weight.dtype
    eq_15 = getattr_21 == torch.float16;  getattr_21 = None
    getattr_22 = encoder_block_3_layer_0_layer_norm_weight.dtype
    to_16 = mul_30.to(getattr_22);  mul_30 = getattr_22 = None
    mul_31 = encoder_block_3_layer_0_layer_norm_weight * to_16;  encoder_block_3_layer_0_layer_norm_weight = to_16 = None
    size_4 = mul_31.size()
    getitem_15 = size_4[slice(None, 2, None)];  size_4 = None
    getitem_16 = getitem_15[0]
    getitem_17 = getitem_15[1];  getitem_15 = None
    encoder_block_3_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.q(mul_31)
    view_13 = encoder_block_3_layer_0_self_attention_q.view(getitem_16, -1, 6, 64);  encoder_block_3_layer_0_self_attention_q = None
    transpose_15 = view_13.transpose(1, 2);  view_13 = None
    encoder_block_3_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.k(mul_31)
    view_14 = encoder_block_3_layer_0_self_attention_k.view(getitem_16, -1, 6, 64);  encoder_block_3_layer_0_self_attention_k = None
    transpose_16 = view_14.transpose(1, 2);  view_14 = None
    encoder_block_3_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.v(mul_31);  mul_31 = None
    view_15 = encoder_block_3_layer_0_self_attention_v.view(getitem_16, -1, 6, 64);  encoder_block_3_layer_0_self_attention_v = None
    transpose_17 = view_15.transpose(1, 2);  view_15 = None
    transpose_18 = transpose_16.transpose(3, 2);  transpose_16 = None
    matmul_6 = torch.matmul(transpose_15, transpose_18);  transpose_15 = transpose_18 = None
    add_26 = matmul_6 + add_4;  matmul_6 = None
    float_5 = add_26.float()
    softmax_3 = torch.nn.functional.softmax(float_5, dim = -1, _stacklevel = 3, dtype = None);  float_5 = None
    type_as_3 = softmax_3.type_as(add_26);  softmax_3 = add_26 = None
    dropout_3 = torch.nn.functional.dropout(type_as_3, p = 0.1, training = False, inplace = False);  type_as_3 = None
    matmul_7 = torch.matmul(dropout_3, transpose_17);  dropout_3 = transpose_17 = None
    transpose_19 = matmul_7.transpose(1, 2);  matmul_7 = None
    contiguous_3 = transpose_19.contiguous();  transpose_19 = None
    view_16 = contiguous_3.view(getitem_16, -1, 384);  contiguous_3 = getitem_16 = None
    encoder_block_3_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.o(view_16);  view_16 = None
    encoder_block_3_layer_0_dropout = getattr(getattr(self.encoder.block, "3").layer, "0").dropout(encoder_block_3_layer_0_self_attention_o);  encoder_block_3_layer_0_self_attention_o = None
    add_27 = add_24 + encoder_block_3_layer_0_dropout;  add_24 = encoder_block_3_layer_0_dropout = None
    getattr_23 = add_27.dtype
    eq_16 = getattr_23 == torch.float16;  getattr_23 = None
    to_17 = add_27.to(torch.float32)
    pow_11 = to_17.pow(2);  to_17 = None
    mean_7 = pow_11.mean(-1, keepdim = True);  pow_11 = None
    add_28 = mean_7 + 1e-06;  mean_7 = None
    rsqrt_7 = torch.rsqrt(add_28);  add_28 = None
    mul_32 = add_27 * rsqrt_7;  rsqrt_7 = None
    encoder_block_3_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "3").layer, "1").layer_norm.weight
    getattr_24 = encoder_block_3_layer_1_layer_norm_weight.dtype
    eq_17 = getattr_24 == torch.float16;  getattr_24 = None
    getattr_25 = encoder_block_3_layer_1_layer_norm_weight.dtype
    to_18 = mul_32.to(getattr_25);  mul_32 = getattr_25 = None
    mul_33 = encoder_block_3_layer_1_layer_norm_weight * to_18;  encoder_block_3_layer_1_layer_norm_weight = to_18 = None
    encoder_block_3_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.wo.weight
    linear1_3 = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.wi_0
    linear_layer_triton_wrapper_3 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_33, linear1_3, activation = 'fast_gelu');  linear1_3 = None
    linear2_3 = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.wi_1(mul_33);  mul_33 = None
    mul_174 = linear_layer_triton_wrapper_3 * linear2_3;  linear_layer_triton_wrapper_3 = linear2_3 = None
    dropout_27 = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.dropout(mul_174);  mul_174 = None
    linear3_3 = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.wo(dropout_27);  dropout_27 = None
    encoder_block_3_layer_1_dropout = getattr(getattr(self.encoder.block, "3").layer, "1").dropout(linear3_3);  linear3_3 = None
    add_31 = add_27 + encoder_block_3_layer_1_dropout;  add_27 = encoder_block_3_layer_1_dropout = None
    getattr_26 = add_31.dtype
    eq_18 = getattr_26 == torch.float16;  getattr_26 = None
    to_19 = add_31.to(torch.float32)
    pow_13 = to_19.pow(2);  to_19 = None
    mean_8 = pow_13.mean(-1, keepdim = True);  pow_13 = None
    add_32 = mean_8 + 1e-06;  mean_8 = None
    rsqrt_8 = torch.rsqrt(add_32);  add_32 = None
    mul_39 = add_31 * rsqrt_8;  rsqrt_8 = None
    encoder_block_4_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "4").layer, "0").layer_norm.weight
    getattr_27 = encoder_block_4_layer_0_layer_norm_weight.dtype
    eq_19 = getattr_27 == torch.float16;  getattr_27 = None
    getattr_28 = encoder_block_4_layer_0_layer_norm_weight.dtype
    to_20 = mul_39.to(getattr_28);  mul_39 = getattr_28 = None
    mul_40 = encoder_block_4_layer_0_layer_norm_weight * to_20;  encoder_block_4_layer_0_layer_norm_weight = to_20 = None
    size_5 = mul_40.size()
    getitem_18 = size_5[slice(None, 2, None)];  size_5 = None
    getitem_19 = getitem_18[0]
    getitem_20 = getitem_18[1];  getitem_18 = None
    encoder_block_4_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.q(mul_40)
    view_17 = encoder_block_4_layer_0_self_attention_q.view(getitem_19, -1, 6, 64);  encoder_block_4_layer_0_self_attention_q = None
    transpose_20 = view_17.transpose(1, 2);  view_17 = None
    encoder_block_4_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.k(mul_40)
    view_18 = encoder_block_4_layer_0_self_attention_k.view(getitem_19, -1, 6, 64);  encoder_block_4_layer_0_self_attention_k = None
    transpose_21 = view_18.transpose(1, 2);  view_18 = None
    encoder_block_4_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.v(mul_40);  mul_40 = None
    view_19 = encoder_block_4_layer_0_self_attention_v.view(getitem_19, -1, 6, 64);  encoder_block_4_layer_0_self_attention_v = None
    transpose_22 = view_19.transpose(1, 2);  view_19 = None
    transpose_23 = transpose_21.transpose(3, 2);  transpose_21 = None
    matmul_8 = torch.matmul(transpose_20, transpose_23);  transpose_20 = transpose_23 = None
    add_33 = matmul_8 + add_4;  matmul_8 = None
    float_6 = add_33.float()
    softmax_4 = torch.nn.functional.softmax(float_6, dim = -1, _stacklevel = 3, dtype = None);  float_6 = None
    type_as_4 = softmax_4.type_as(add_33);  softmax_4 = add_33 = None
    dropout_4 = torch.nn.functional.dropout(type_as_4, p = 0.1, training = False, inplace = False);  type_as_4 = None
    matmul_9 = torch.matmul(dropout_4, transpose_22);  dropout_4 = transpose_22 = None
    transpose_24 = matmul_9.transpose(1, 2);  matmul_9 = None
    contiguous_4 = transpose_24.contiguous();  transpose_24 = None
    view_20 = contiguous_4.view(getitem_19, -1, 384);  contiguous_4 = getitem_19 = None
    encoder_block_4_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.o(view_20);  view_20 = None
    encoder_block_4_layer_0_dropout = getattr(getattr(self.encoder.block, "4").layer, "0").dropout(encoder_block_4_layer_0_self_attention_o);  encoder_block_4_layer_0_self_attention_o = None
    add_34 = add_31 + encoder_block_4_layer_0_dropout;  add_31 = encoder_block_4_layer_0_dropout = None
    getattr_29 = add_34.dtype
    eq_20 = getattr_29 == torch.float16;  getattr_29 = None
    to_21 = add_34.to(torch.float32)
    pow_14 = to_21.pow(2);  to_21 = None
    mean_9 = pow_14.mean(-1, keepdim = True);  pow_14 = None
    add_35 = mean_9 + 1e-06;  mean_9 = None
    rsqrt_9 = torch.rsqrt(add_35);  add_35 = None
    mul_41 = add_34 * rsqrt_9;  rsqrt_9 = None
    encoder_block_4_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "4").layer, "1").layer_norm.weight
    getattr_30 = encoder_block_4_layer_1_layer_norm_weight.dtype
    eq_21 = getattr_30 == torch.float16;  getattr_30 = None
    getattr_31 = encoder_block_4_layer_1_layer_norm_weight.dtype
    to_22 = mul_41.to(getattr_31);  mul_41 = getattr_31 = None
    mul_42 = encoder_block_4_layer_1_layer_norm_weight * to_22;  encoder_block_4_layer_1_layer_norm_weight = to_22 = None
    encoder_block_4_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.wo.weight
    linear1_4 = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.wi_0
    linear_layer_triton_wrapper_4 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_42, linear1_4, activation = 'fast_gelu');  linear1_4 = None
    linear2_4 = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.wi_1(mul_42);  mul_42 = None
    mul_175 = linear_layer_triton_wrapper_4 * linear2_4;  linear_layer_triton_wrapper_4 = linear2_4 = None
    dropout_28 = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.dropout(mul_175);  mul_175 = None
    linear3_4 = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.wo(dropout_28);  dropout_28 = None
    encoder_block_4_layer_1_dropout = getattr(getattr(self.encoder.block, "4").layer, "1").dropout(linear3_4);  linear3_4 = None
    add_38 = add_34 + encoder_block_4_layer_1_dropout;  add_34 = encoder_block_4_layer_1_dropout = None
    getattr_32 = add_38.dtype
    eq_22 = getattr_32 == torch.float16;  getattr_32 = None
    to_23 = add_38.to(torch.float32)
    pow_16 = to_23.pow(2);  to_23 = None
    mean_10 = pow_16.mean(-1, keepdim = True);  pow_16 = None
    add_39 = mean_10 + 1e-06;  mean_10 = None
    rsqrt_10 = torch.rsqrt(add_39);  add_39 = None
    mul_48 = add_38 * rsqrt_10;  rsqrt_10 = None
    encoder_block_5_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "5").layer, "0").layer_norm.weight
    getattr_33 = encoder_block_5_layer_0_layer_norm_weight.dtype
    eq_23 = getattr_33 == torch.float16;  getattr_33 = None
    getattr_34 = encoder_block_5_layer_0_layer_norm_weight.dtype
    to_24 = mul_48.to(getattr_34);  mul_48 = getattr_34 = None
    mul_49 = encoder_block_5_layer_0_layer_norm_weight * to_24;  encoder_block_5_layer_0_layer_norm_weight = to_24 = None
    size_6 = mul_49.size()
    getitem_21 = size_6[slice(None, 2, None)];  size_6 = None
    getitem_22 = getitem_21[0]
    getitem_23 = getitem_21[1];  getitem_21 = None
    encoder_block_5_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.q(mul_49)
    view_21 = encoder_block_5_layer_0_self_attention_q.view(getitem_22, -1, 6, 64);  encoder_block_5_layer_0_self_attention_q = None
    transpose_25 = view_21.transpose(1, 2);  view_21 = None
    encoder_block_5_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.k(mul_49)
    view_22 = encoder_block_5_layer_0_self_attention_k.view(getitem_22, -1, 6, 64);  encoder_block_5_layer_0_self_attention_k = None
    transpose_26 = view_22.transpose(1, 2);  view_22 = None
    encoder_block_5_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.v(mul_49);  mul_49 = None
    view_23 = encoder_block_5_layer_0_self_attention_v.view(getitem_22, -1, 6, 64);  encoder_block_5_layer_0_self_attention_v = None
    transpose_27 = view_23.transpose(1, 2);  view_23 = None
    transpose_28 = transpose_26.transpose(3, 2);  transpose_26 = None
    matmul_10 = torch.matmul(transpose_25, transpose_28);  transpose_25 = transpose_28 = None
    add_40 = matmul_10 + add_4;  matmul_10 = None
    float_7 = add_40.float()
    softmax_5 = torch.nn.functional.softmax(float_7, dim = -1, _stacklevel = 3, dtype = None);  float_7 = None
    type_as_5 = softmax_5.type_as(add_40);  softmax_5 = add_40 = None
    dropout_5 = torch.nn.functional.dropout(type_as_5, p = 0.1, training = False, inplace = False);  type_as_5 = None
    matmul_11 = torch.matmul(dropout_5, transpose_27);  dropout_5 = transpose_27 = None
    transpose_29 = matmul_11.transpose(1, 2);  matmul_11 = None
    contiguous_5 = transpose_29.contiguous();  transpose_29 = None
    view_24 = contiguous_5.view(getitem_22, -1, 384);  contiguous_5 = getitem_22 = None
    encoder_block_5_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.o(view_24);  view_24 = None
    encoder_block_5_layer_0_dropout = getattr(getattr(self.encoder.block, "5").layer, "0").dropout(encoder_block_5_layer_0_self_attention_o);  encoder_block_5_layer_0_self_attention_o = None
    add_41 = add_38 + encoder_block_5_layer_0_dropout;  add_38 = encoder_block_5_layer_0_dropout = None
    getattr_35 = add_41.dtype
    eq_24 = getattr_35 == torch.float16;  getattr_35 = None
    to_25 = add_41.to(torch.float32)
    pow_17 = to_25.pow(2);  to_25 = None
    mean_11 = pow_17.mean(-1, keepdim = True);  pow_17 = None
    add_42 = mean_11 + 1e-06;  mean_11 = None
    rsqrt_11 = torch.rsqrt(add_42);  add_42 = None
    mul_50 = add_41 * rsqrt_11;  rsqrt_11 = None
    encoder_block_5_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "5").layer, "1").layer_norm.weight
    getattr_36 = encoder_block_5_layer_1_layer_norm_weight.dtype
    eq_25 = getattr_36 == torch.float16;  getattr_36 = None
    getattr_37 = encoder_block_5_layer_1_layer_norm_weight.dtype
    to_26 = mul_50.to(getattr_37);  mul_50 = getattr_37 = None
    mul_51 = encoder_block_5_layer_1_layer_norm_weight * to_26;  encoder_block_5_layer_1_layer_norm_weight = to_26 = None
    encoder_block_5_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.wo.weight
    linear1_5 = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.wi_0
    linear_layer_triton_wrapper_5 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_51, linear1_5, activation = 'fast_gelu');  linear1_5 = None
    linear2_5 = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.wi_1(mul_51);  mul_51 = None
    mul_176 = linear_layer_triton_wrapper_5 * linear2_5;  linear_layer_triton_wrapper_5 = linear2_5 = None
    dropout_29 = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.dropout(mul_176);  mul_176 = None
    linear3_5 = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.wo(dropout_29);  dropout_29 = None
    encoder_block_5_layer_1_dropout = getattr(getattr(self.encoder.block, "5").layer, "1").dropout(linear3_5);  linear3_5 = None
    add_45 = add_41 + encoder_block_5_layer_1_dropout;  add_41 = encoder_block_5_layer_1_dropout = None
    getattr_38 = add_45.dtype
    eq_26 = getattr_38 == torch.float16;  getattr_38 = None
    to_27 = add_45.to(torch.float32)
    pow_19 = to_27.pow(2);  to_27 = None
    mean_12 = pow_19.mean(-1, keepdim = True);  pow_19 = None
    add_46 = mean_12 + 1e-06;  mean_12 = None
    rsqrt_12 = torch.rsqrt(add_46);  add_46 = None
    mul_57 = add_45 * rsqrt_12;  rsqrt_12 = None
    encoder_block_6_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "6").layer, "0").layer_norm.weight
    getattr_39 = encoder_block_6_layer_0_layer_norm_weight.dtype
    eq_27 = getattr_39 == torch.float16;  getattr_39 = None
    getattr_40 = encoder_block_6_layer_0_layer_norm_weight.dtype
    to_28 = mul_57.to(getattr_40);  mul_57 = getattr_40 = None
    mul_58 = encoder_block_6_layer_0_layer_norm_weight * to_28;  encoder_block_6_layer_0_layer_norm_weight = to_28 = None
    size_7 = mul_58.size()
    getitem_24 = size_7[slice(None, 2, None)];  size_7 = None
    getitem_25 = getitem_24[0]
    getitem_26 = getitem_24[1];  getitem_24 = None
    encoder_block_6_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "6").layer, "0").SelfAttention.q(mul_58)
    view_25 = encoder_block_6_layer_0_self_attention_q.view(getitem_25, -1, 6, 64);  encoder_block_6_layer_0_self_attention_q = None
    transpose_30 = view_25.transpose(1, 2);  view_25 = None
    encoder_block_6_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "6").layer, "0").SelfAttention.k(mul_58)
    view_26 = encoder_block_6_layer_0_self_attention_k.view(getitem_25, -1, 6, 64);  encoder_block_6_layer_0_self_attention_k = None
    transpose_31 = view_26.transpose(1, 2);  view_26 = None
    encoder_block_6_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "6").layer, "0").SelfAttention.v(mul_58);  mul_58 = None
    view_27 = encoder_block_6_layer_0_self_attention_v.view(getitem_25, -1, 6, 64);  encoder_block_6_layer_0_self_attention_v = None
    transpose_32 = view_27.transpose(1, 2);  view_27 = None
    transpose_33 = transpose_31.transpose(3, 2);  transpose_31 = None
    matmul_12 = torch.matmul(transpose_30, transpose_33);  transpose_30 = transpose_33 = None
    add_47 = matmul_12 + add_4;  matmul_12 = None
    float_8 = add_47.float()
    softmax_6 = torch.nn.functional.softmax(float_8, dim = -1, _stacklevel = 3, dtype = None);  float_8 = None
    type_as_6 = softmax_6.type_as(add_47);  softmax_6 = add_47 = None
    dropout_6 = torch.nn.functional.dropout(type_as_6, p = 0.1, training = False, inplace = False);  type_as_6 = None
    matmul_13 = torch.matmul(dropout_6, transpose_32);  dropout_6 = transpose_32 = None
    transpose_34 = matmul_13.transpose(1, 2);  matmul_13 = None
    contiguous_6 = transpose_34.contiguous();  transpose_34 = None
    view_28 = contiguous_6.view(getitem_25, -1, 384);  contiguous_6 = getitem_25 = None
    encoder_block_6_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "6").layer, "0").SelfAttention.o(view_28);  view_28 = None
    encoder_block_6_layer_0_dropout = getattr(getattr(self.encoder.block, "6").layer, "0").dropout(encoder_block_6_layer_0_self_attention_o);  encoder_block_6_layer_0_self_attention_o = None
    add_48 = add_45 + encoder_block_6_layer_0_dropout;  add_45 = encoder_block_6_layer_0_dropout = None
    getattr_41 = add_48.dtype
    eq_28 = getattr_41 == torch.float16;  getattr_41 = None
    to_29 = add_48.to(torch.float32)
    pow_20 = to_29.pow(2);  to_29 = None
    mean_13 = pow_20.mean(-1, keepdim = True);  pow_20 = None
    add_49 = mean_13 + 1e-06;  mean_13 = None
    rsqrt_13 = torch.rsqrt(add_49);  add_49 = None
    mul_59 = add_48 * rsqrt_13;  rsqrt_13 = None
    encoder_block_6_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "6").layer, "1").layer_norm.weight
    getattr_42 = encoder_block_6_layer_1_layer_norm_weight.dtype
    eq_29 = getattr_42 == torch.float16;  getattr_42 = None
    getattr_43 = encoder_block_6_layer_1_layer_norm_weight.dtype
    to_30 = mul_59.to(getattr_43);  mul_59 = getattr_43 = None
    mul_60 = encoder_block_6_layer_1_layer_norm_weight * to_30;  encoder_block_6_layer_1_layer_norm_weight = to_30 = None
    encoder_block_6_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "6").layer, "1").DenseReluDense.wo.weight
    linear1_6 = getattr(getattr(self.encoder.block, "6").layer, "1").DenseReluDense.wi_0
    linear_layer_triton_wrapper_6 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_60, linear1_6, activation = 'fast_gelu');  linear1_6 = None
    linear2_6 = getattr(getattr(self.encoder.block, "6").layer, "1").DenseReluDense.wi_1(mul_60);  mul_60 = None
    mul_177 = linear_layer_triton_wrapper_6 * linear2_6;  linear_layer_triton_wrapper_6 = linear2_6 = None
    dropout_30 = getattr(getattr(self.encoder.block, "6").layer, "1").DenseReluDense.dropout(mul_177);  mul_177 = None
    linear3_6 = getattr(getattr(self.encoder.block, "6").layer, "1").DenseReluDense.wo(dropout_30);  dropout_30 = None
    encoder_block_6_layer_1_dropout = getattr(getattr(self.encoder.block, "6").layer, "1").dropout(linear3_6);  linear3_6 = None
    add_52 = add_48 + encoder_block_6_layer_1_dropout;  add_48 = encoder_block_6_layer_1_dropout = None
    getattr_44 = add_52.dtype
    eq_30 = getattr_44 == torch.float16;  getattr_44 = None
    to_31 = add_52.to(torch.float32)
    pow_22 = to_31.pow(2);  to_31 = None
    mean_14 = pow_22.mean(-1, keepdim = True);  pow_22 = None
    add_53 = mean_14 + 1e-06;  mean_14 = None
    rsqrt_14 = torch.rsqrt(add_53);  add_53 = None
    mul_66 = add_52 * rsqrt_14;  rsqrt_14 = None
    encoder_block_7_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "7").layer, "0").layer_norm.weight
    getattr_45 = encoder_block_7_layer_0_layer_norm_weight.dtype
    eq_31 = getattr_45 == torch.float16;  getattr_45 = None
    getattr_46 = encoder_block_7_layer_0_layer_norm_weight.dtype
    to_32 = mul_66.to(getattr_46);  mul_66 = getattr_46 = None
    mul_67 = encoder_block_7_layer_0_layer_norm_weight * to_32;  encoder_block_7_layer_0_layer_norm_weight = to_32 = None
    size_8 = mul_67.size()
    getitem_27 = size_8[slice(None, 2, None)];  size_8 = None
    getitem_28 = getitem_27[0]
    getitem_29 = getitem_27[1];  getitem_27 = None
    encoder_block_7_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "7").layer, "0").SelfAttention.q(mul_67)
    view_29 = encoder_block_7_layer_0_self_attention_q.view(getitem_28, -1, 6, 64);  encoder_block_7_layer_0_self_attention_q = None
    transpose_35 = view_29.transpose(1, 2);  view_29 = None
    encoder_block_7_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "7").layer, "0").SelfAttention.k(mul_67)
    view_30 = encoder_block_7_layer_0_self_attention_k.view(getitem_28, -1, 6, 64);  encoder_block_7_layer_0_self_attention_k = None
    transpose_36 = view_30.transpose(1, 2);  view_30 = None
    encoder_block_7_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "7").layer, "0").SelfAttention.v(mul_67);  mul_67 = None
    view_31 = encoder_block_7_layer_0_self_attention_v.view(getitem_28, -1, 6, 64);  encoder_block_7_layer_0_self_attention_v = None
    transpose_37 = view_31.transpose(1, 2);  view_31 = None
    transpose_38 = transpose_36.transpose(3, 2);  transpose_36 = None
    matmul_14 = torch.matmul(transpose_35, transpose_38);  transpose_35 = transpose_38 = None
    add_54 = matmul_14 + add_4;  matmul_14 = add_4 = None
    float_9 = add_54.float()
    softmax_7 = torch.nn.functional.softmax(float_9, dim = -1, _stacklevel = 3, dtype = None);  float_9 = None
    type_as_7 = softmax_7.type_as(add_54);  softmax_7 = add_54 = None
    dropout_7 = torch.nn.functional.dropout(type_as_7, p = 0.1, training = False, inplace = False);  type_as_7 = None
    matmul_15 = torch.matmul(dropout_7, transpose_37);  dropout_7 = transpose_37 = None
    transpose_39 = matmul_15.transpose(1, 2);  matmul_15 = None
    contiguous_7 = transpose_39.contiguous();  transpose_39 = None
    view_32 = contiguous_7.view(getitem_28, -1, 384);  contiguous_7 = getitem_28 = None
    encoder_block_7_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "7").layer, "0").SelfAttention.o(view_32);  view_32 = None
    encoder_block_7_layer_0_dropout = getattr(getattr(self.encoder.block, "7").layer, "0").dropout(encoder_block_7_layer_0_self_attention_o);  encoder_block_7_layer_0_self_attention_o = None
    add_55 = add_52 + encoder_block_7_layer_0_dropout;  add_52 = encoder_block_7_layer_0_dropout = None
    getattr_47 = add_55.dtype
    eq_32 = getattr_47 == torch.float16;  getattr_47 = None
    to_33 = add_55.to(torch.float32)
    pow_23 = to_33.pow(2);  to_33 = None
    mean_15 = pow_23.mean(-1, keepdim = True);  pow_23 = None
    add_56 = mean_15 + 1e-06;  mean_15 = None
    rsqrt_15 = torch.rsqrt(add_56);  add_56 = None
    mul_68 = add_55 * rsqrt_15;  rsqrt_15 = None
    encoder_block_7_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "7").layer, "1").layer_norm.weight
    getattr_48 = encoder_block_7_layer_1_layer_norm_weight.dtype
    eq_33 = getattr_48 == torch.float16;  getattr_48 = None
    getattr_49 = encoder_block_7_layer_1_layer_norm_weight.dtype
    to_34 = mul_68.to(getattr_49);  mul_68 = getattr_49 = None
    mul_69 = encoder_block_7_layer_1_layer_norm_weight * to_34;  encoder_block_7_layer_1_layer_norm_weight = to_34 = None
    encoder_block_7_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "7").layer, "1").DenseReluDense.wo.weight
    linear1_7 = getattr(getattr(self.encoder.block, "7").layer, "1").DenseReluDense.wi_0
    linear_layer_triton_wrapper_7 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_69, linear1_7, activation = 'fast_gelu');  linear1_7 = None
    linear2_7 = getattr(getattr(self.encoder.block, "7").layer, "1").DenseReluDense.wi_1(mul_69);  mul_69 = None
    mul_178 = linear_layer_triton_wrapper_7 * linear2_7;  linear_layer_triton_wrapper_7 = linear2_7 = None
    dropout_31 = getattr(getattr(self.encoder.block, "7").layer, "1").DenseReluDense.dropout(mul_178);  mul_178 = None
    linear3_7 = getattr(getattr(self.encoder.block, "7").layer, "1").DenseReluDense.wo(dropout_31);  dropout_31 = None
    encoder_block_7_layer_1_dropout = getattr(getattr(self.encoder.block, "7").layer, "1").dropout(linear3_7);  linear3_7 = None
    add_59 = add_55 + encoder_block_7_layer_1_dropout;  add_55 = encoder_block_7_layer_1_dropout = None
    getattr_50 = add_59.dtype
    eq_34 = getattr_50 == torch.float16;  getattr_50 = None
    to_35 = add_59.to(torch.float32)
    pow_25 = to_35.pow(2);  to_35 = None
    mean_16 = pow_25.mean(-1, keepdim = True);  pow_25 = None
    add_60 = mean_16 + 1e-06;  mean_16 = None
    rsqrt_16 = torch.rsqrt(add_60);  add_60 = None
    mul_75 = add_59 * rsqrt_16;  add_59 = rsqrt_16 = None
    encoder_final_layer_norm_weight = self.encoder.final_layer_norm.weight
    getattr_51 = encoder_final_layer_norm_weight.dtype
    eq_35 = getattr_51 == torch.float16;  getattr_51 = None
    getattr_52 = encoder_final_layer_norm_weight.dtype
    to_36 = mul_75.to(getattr_52);  mul_75 = getattr_52 = None
    mul_76 = encoder_final_layer_norm_weight * to_36;  encoder_final_layer_norm_weight = to_36 = None
    encoder_dropout_1 = self.encoder.dropout(mul_76);  mul_76 = None
    size_9 = labels.size()
    getitem_30 = size_9[slice(None, -1, None)];  size_9 = None
    add_61 = getitem_30 + (1,);  getitem_30 = None
    full = torch.full(add_61, 0);  add_61 = None
    getitem_31 = labels[(Ellipsis, slice(None, -1, None))]
    cat = torch.cat([full, getitem_31], dim = -1);  full = getitem_31 = None
    eq_36 = cat == -100
    masked_fill_ = cat.masked_fill_(eq_36, 0);  eq_36 = None
    size_10 = cat.size()
    getitem_32 = size_10[-1]
    view_33 = cat.view(-1, getitem_32);  cat = getitem_32 = None
    shared_1 = self.shared(view_33);  view_33 = None
    getitem_33 = size_10[0]
    getitem_34 = size_10[1]
    getattr_53 = shared_1.device
    ones_1 = torch.ones(getitem_33, getitem_34, device = getattr_53);  getitem_34 = getattr_53 = None
    size_11 = encoder_dropout_1.size()
    getitem_35 = size_11[1];  size_11 = None
    getattr_54 = shared_1.device
    ones_2 = torch.ones(getitem_33, getitem_35, device = getattr_54, dtype = torch.int64);  getitem_33 = getitem_35 = getattr_54 = None
    dim_3 = ones_1.dim()
    eq_37 = dim_3 == 2;  dim_3 = None
    dim_4 = ones_1.dim()
    eq_38 = dim_4 == 3;  dim_4 = None
    dim_5 = ones_1.dim()
    eq_39 = dim_5 == 2;  dim_5 = None
    getitem_36 = size_10[0]
    getitem_37 = size_10[1];  size_10 = None
    getattr_55 = ones_1.device
    arange_2 = torch.arange(getitem_37, device = getattr_55);  getattr_55 = None
    getitem_38 = arange_2[(None, None, slice(None, None, None))]
    repeat = getitem_38.repeat(getitem_36, getitem_37, 1);  getitem_38 = getitem_36 = getitem_37 = None
    getitem_39 = arange_2[(None, slice(None, None, None), None)];  arange_2 = None
    le = repeat <= getitem_39;  repeat = getitem_39 = None
    getattr_56 = ones_1.dtype
    to_37 = le.to(getattr_56);  le = getattr_56 = None
    size_12 = to_37.size()
    getitem_40 = size_12[1];  size_12 = None
    size_13 = ones_1.size()
    getitem_41 = size_13[1];  size_13 = None
    lt_1 = getitem_40 < getitem_41;  getitem_40 = getitem_41 = None
    getitem_42 = to_37[(slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  to_37 = None
    getitem_43 = ones_1[(slice(None, None, None), None, None, slice(None, None, None))];  ones_1 = None
    mul_77 = getitem_42 * getitem_43;  getitem_42 = getitem_43 = None
    to_38 = mul_77.to(dtype = torch.float16);  mul_77 = None
    sub_2 = 1.0 - to_38;  to_38 = None
    mul_78 = sub_2 * -65504.0;  sub_2 = None
    size_14 = encoder_dropout_1.size()
    getitem_44 = size_14[0]
    getitem_45 = size_14[1]
    getitem_46 = size_14[2];  size_14 = None
    dim_6 = ones_2.dim()
    eq_40 = dim_6 == 3;  dim_6 = None
    dim_7 = ones_2.dim()
    eq_41 = dim_7 == 2;  dim_7 = None
    getitem_47 = ones_2[(slice(None, None, None), None, None, slice(None, None, None))];  ones_2 = None
    to_39 = getitem_47.to(dtype = torch.float16);  getitem_47 = None
    sub_3 = 1.0 - to_39;  to_39 = None
    mul_79 = sub_3 * -65504.0;  sub_3 = None
    decoder_dropout = self.decoder.dropout(shared_1);  shared_1 = None
    to_40 = decoder_dropout.to(torch.float32)
    pow_26 = to_40.pow(2);  to_40 = None
    mean_17 = pow_26.mean(-1, keepdim = True);  pow_26 = None
    add_62 = mean_17 + 1e-06;  mean_17 = None
    rsqrt_17 = torch.rsqrt(add_62);  add_62 = None
    mul_80 = decoder_dropout * rsqrt_17;  rsqrt_17 = None
    decoder_block_0_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "0").layer, "0").layer_norm.weight
    getattr_57 = decoder_block_0_layer_0_layer_norm_weight.dtype
    eq_42 = getattr_57 == torch.float16;  getattr_57 = None
    getattr_58 = decoder_block_0_layer_0_layer_norm_weight.dtype
    to_41 = mul_80.to(getattr_58);  mul_80 = getattr_58 = None
    mul_81 = decoder_block_0_layer_0_layer_norm_weight * to_41;  decoder_block_0_layer_0_layer_norm_weight = to_41 = None
    size_15 = mul_81.size()
    getitem_48 = size_15[slice(None, 2, None)];  size_15 = None
    getitem_49 = getitem_48[0]
    getitem_50 = getitem_48[1];  getitem_48 = None
    decoder_block_0_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.q(mul_81)
    view_34 = decoder_block_0_layer_0_self_attention_q.view(getitem_49, -1, 6, 64);  decoder_block_0_layer_0_self_attention_q = None
    transpose_40 = view_34.transpose(1, 2);  view_34 = None
    decoder_block_0_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.k(mul_81)
    view_35 = decoder_block_0_layer_0_self_attention_k.view(getitem_49, -1, 6, 64);  decoder_block_0_layer_0_self_attention_k = None
    transpose_41 = view_35.transpose(1, 2);  view_35 = None
    decoder_block_0_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.v(mul_81);  mul_81 = None
    view_36 = decoder_block_0_layer_0_self_attention_v.view(getitem_49, -1, 6, 64);  decoder_block_0_layer_0_self_attention_v = None
    transpose_42 = view_36.transpose(1, 2);  view_36 = None
    transpose_43 = transpose_41.transpose(3, 2)
    matmul_16 = torch.matmul(transpose_40, transpose_43);  transpose_40 = transpose_43 = None
    getattr_59 = matmul_16.device
    arange_3 = torch.arange(getitem_50, dtype = torch.int64, device = getattr_59)
    getitem_51 = arange_3[(slice(None, None, None), None)];  arange_3 = None
    arange_4 = torch.arange(getitem_50, dtype = torch.int64, device = getattr_59);  getitem_50 = getattr_59 = None
    getitem_52 = arange_4[(None, slice(None, None, None))];  arange_4 = None
    sub_4 = getitem_52 - getitem_51;  getitem_52 = getitem_51 = None
    zeros_like = torch.zeros_like(sub_4)
    min_2 = torch.min(sub_4, zeros_like);  sub_4 = zeros_like = None
    neg = -min_2;  min_2 = None
    lt_2 = neg < 16
    float_10 = neg.float()
    truediv_2 = float_10 / 16;  float_10 = None
    log_1 = torch.log(truediv_2);  truediv_2 = None
    truediv_3 = log_1 / 2.0794415416798357;  log_1 = None
    mul_82 = truediv_3 * 16;  truediv_3 = None
    to_42 = mul_82.to(torch.int64);  mul_82 = None
    add_63 = 16 + to_42;  to_42 = None
    full_like_1 = torch.full_like(add_63, 31)
    min_3 = torch.min(add_63, full_like_1);  add_63 = full_like_1 = None
    where_1 = torch.where(lt_2, neg, min_3);  lt_2 = neg = min_3 = None
    add_64 = 0 + where_1;  where_1 = None
    decoder_block_0_layer_0_self_attention_relative_attention_bias = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.relative_attention_bias(add_64);  add_64 = None
    permute_1 = decoder_block_0_layer_0_self_attention_relative_attention_bias.permute([2, 0, 1]);  decoder_block_0_layer_0_self_attention_relative_attention_bias = None
    unsqueeze_1 = permute_1.unsqueeze(0);  permute_1 = None
    add_65 = unsqueeze_1 + mul_78;  unsqueeze_1 = mul_78 = None
    add_66 = matmul_16 + add_65;  matmul_16 = None
    float_11 = add_66.float()
    softmax_8 = torch.nn.functional.softmax(float_11, dim = -1, _stacklevel = 3, dtype = None);  float_11 = None
    type_as_8 = softmax_8.type_as(add_66);  softmax_8 = add_66 = None
    dropout_8 = torch.nn.functional.dropout(type_as_8, p = 0.1, training = False, inplace = False);  type_as_8 = None
    matmul_17 = torch.matmul(dropout_8, transpose_42);  dropout_8 = None
    transpose_44 = matmul_17.transpose(1, 2);  matmul_17 = None
    contiguous_8 = transpose_44.contiguous();  transpose_44 = None
    view_37 = contiguous_8.view(getitem_49, -1, 384);  contiguous_8 = getitem_49 = None
    decoder_block_0_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.o(view_37);  view_37 = None
    decoder_block_0_layer_0_dropout = getattr(getattr(self.decoder.block, "0").layer, "0").dropout(decoder_block_0_layer_0_self_attention_o);  decoder_block_0_layer_0_self_attention_o = None
    add_67 = decoder_dropout + decoder_block_0_layer_0_dropout;  decoder_dropout = decoder_block_0_layer_0_dropout = None
    getattr_60 = add_67.dtype
    eq_43 = getattr_60 == torch.float16;  getattr_60 = None
    size_16 = transpose_41.size()
    getitem_53 = size_16[2];  size_16 = None
    to_43 = add_67.to(torch.float32)
    pow_27 = to_43.pow(2);  to_43 = None
    mean_18 = pow_27.mean(-1, keepdim = True);  pow_27 = None
    add_68 = mean_18 + 1e-06;  mean_18 = None
    rsqrt_18 = torch.rsqrt(add_68);  add_68 = None
    mul_83 = add_67 * rsqrt_18;  rsqrt_18 = None
    decoder_block_0_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "0").layer, "1").layer_norm.weight
    getattr_61 = decoder_block_0_layer_1_layer_norm_weight.dtype
    eq_44 = getattr_61 == torch.float16;  getattr_61 = None
    getattr_62 = decoder_block_0_layer_1_layer_norm_weight.dtype
    to_44 = mul_83.to(getattr_62);  mul_83 = getattr_62 = None
    mul_84 = decoder_block_0_layer_1_layer_norm_weight * to_44;  decoder_block_0_layer_1_layer_norm_weight = to_44 = None
    size_17 = mul_84.size()
    getitem_54 = size_17[slice(None, 2, None)];  size_17 = None
    getitem_55 = getitem_54[0]
    getitem_56 = getitem_54[1];  getitem_54 = None
    size_18 = encoder_dropout_1.size()
    getitem_57 = size_18[1];  size_18 = None
    decoder_block_0_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.q(mul_84);  mul_84 = None
    view_38 = decoder_block_0_layer_1_enc_dec_attention_q.view(getitem_55, -1, 6, 64);  decoder_block_0_layer_1_enc_dec_attention_q = None
    transpose_45 = view_38.transpose(1, 2);  view_38 = None
    decoder_block_0_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_39 = decoder_block_0_layer_1_enc_dec_attention_k.view(getitem_55, -1, 6, 64);  decoder_block_0_layer_1_enc_dec_attention_k = None
    transpose_46 = view_39.transpose(1, 2);  view_39 = None
    decoder_block_0_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_40 = decoder_block_0_layer_1_enc_dec_attention_v.view(getitem_55, -1, 6, 64);  decoder_block_0_layer_1_enc_dec_attention_v = None
    transpose_47 = view_40.transpose(1, 2);  view_40 = None
    transpose_48 = transpose_46.transpose(3, 2)
    matmul_18 = torch.matmul(transpose_45, transpose_48);  transpose_45 = transpose_48 = None
    getattr_63 = matmul_18.device
    getattr_64 = matmul_18.dtype
    zeros = torch.zeros((1, 6, getitem_56, getitem_57), device = getattr_63, dtype = getattr_64);  getitem_56 = getitem_57 = getattr_63 = getattr_64 = None
    add_69 = zeros + mul_79;  zeros = mul_79 = None
    add_70 = matmul_18 + add_69;  matmul_18 = None
    float_12 = add_70.float()
    softmax_9 = torch.nn.functional.softmax(float_12, dim = -1, _stacklevel = 3, dtype = None);  float_12 = None
    type_as_9 = softmax_9.type_as(add_70);  softmax_9 = add_70 = None
    dropout_9 = torch.nn.functional.dropout(type_as_9, p = 0.1, training = False, inplace = False);  type_as_9 = None
    matmul_19 = torch.matmul(dropout_9, transpose_47);  dropout_9 = None
    transpose_49 = matmul_19.transpose(1, 2);  matmul_19 = None
    contiguous_9 = transpose_49.contiguous();  transpose_49 = None
    view_41 = contiguous_9.view(getitem_55, -1, 384);  contiguous_9 = getitem_55 = None
    decoder_block_0_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.o(view_41);  view_41 = None
    decoder_block_0_layer_1_dropout = getattr(getattr(self.decoder.block, "0").layer, "1").dropout(decoder_block_0_layer_1_enc_dec_attention_o);  decoder_block_0_layer_1_enc_dec_attention_o = None
    add_71 = add_67 + decoder_block_0_layer_1_dropout;  add_67 = decoder_block_0_layer_1_dropout = None
    getattr_65 = add_71.dtype
    eq_45 = getattr_65 == torch.float16;  getattr_65 = None
    to_45 = add_71.to(torch.float32)
    pow_28 = to_45.pow(2);  to_45 = None
    mean_19 = pow_28.mean(-1, keepdim = True);  pow_28 = None
    add_72 = mean_19 + 1e-06;  mean_19 = None
    rsqrt_19 = torch.rsqrt(add_72);  add_72 = None
    mul_85 = add_71 * rsqrt_19;  rsqrt_19 = None
    decoder_block_0_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "0").layer, "2").layer_norm.weight
    getattr_66 = decoder_block_0_layer_2_layer_norm_weight.dtype
    eq_46 = getattr_66 == torch.float16;  getattr_66 = None
    getattr_67 = decoder_block_0_layer_2_layer_norm_weight.dtype
    to_46 = mul_85.to(getattr_67);  mul_85 = getattr_67 = None
    mul_86 = decoder_block_0_layer_2_layer_norm_weight * to_46;  decoder_block_0_layer_2_layer_norm_weight = to_46 = None
    decoder_block_0_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.wo.weight
    linear1_8 = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.wi_0
    linear_layer_triton_wrapper_8 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_86, linear1_8, activation = 'fast_gelu');  linear1_8 = None
    linear2_8 = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.wi_1(mul_86);  mul_86 = None
    mul_179 = linear_layer_triton_wrapper_8 * linear2_8;  linear_layer_triton_wrapper_8 = linear2_8 = None
    dropout_32 = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.dropout(mul_179);  mul_179 = None
    linear3_8 = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.wo(dropout_32);  dropout_32 = None
    decoder_block_0_layer_2_dropout = getattr(getattr(self.decoder.block, "0").layer, "2").dropout(linear3_8);  linear3_8 = None
    add_75 = add_71 + decoder_block_0_layer_2_dropout;  add_71 = decoder_block_0_layer_2_dropout = None
    getattr_68 = add_75.dtype
    eq_47 = getattr_68 == torch.float16;  getattr_68 = None
    to_47 = add_75.to(torch.float32)
    pow_30 = to_47.pow(2);  to_47 = None
    mean_20 = pow_30.mean(-1, keepdim = True);  pow_30 = None
    add_76 = mean_20 + 1e-06;  mean_20 = None
    rsqrt_20 = torch.rsqrt(add_76);  add_76 = None
    mul_92 = add_75 * rsqrt_20;  rsqrt_20 = None
    decoder_block_1_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "1").layer, "0").layer_norm.weight
    getattr_69 = decoder_block_1_layer_0_layer_norm_weight.dtype
    eq_48 = getattr_69 == torch.float16;  getattr_69 = None
    getattr_70 = decoder_block_1_layer_0_layer_norm_weight.dtype
    to_48 = mul_92.to(getattr_70);  mul_92 = getattr_70 = None
    mul_93 = decoder_block_1_layer_0_layer_norm_weight * to_48;  decoder_block_1_layer_0_layer_norm_weight = to_48 = None
    size_19 = mul_93.size()
    getitem_58 = size_19[slice(None, 2, None)];  size_19 = None
    getitem_59 = getitem_58[0]
    getitem_60 = getitem_58[1];  getitem_58 = None
    decoder_block_1_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.q(mul_93)
    view_42 = decoder_block_1_layer_0_self_attention_q.view(getitem_59, -1, 6, 64);  decoder_block_1_layer_0_self_attention_q = None
    transpose_50 = view_42.transpose(1, 2);  view_42 = None
    decoder_block_1_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.k(mul_93)
    view_43 = decoder_block_1_layer_0_self_attention_k.view(getitem_59, -1, 6, 64);  decoder_block_1_layer_0_self_attention_k = None
    transpose_51 = view_43.transpose(1, 2);  view_43 = None
    decoder_block_1_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.v(mul_93);  mul_93 = None
    view_44 = decoder_block_1_layer_0_self_attention_v.view(getitem_59, -1, 6, 64);  decoder_block_1_layer_0_self_attention_v = None
    transpose_52 = view_44.transpose(1, 2);  view_44 = None
    transpose_53 = transpose_51.transpose(3, 2)
    matmul_20 = torch.matmul(transpose_50, transpose_53);  transpose_50 = transpose_53 = None
    add_77 = matmul_20 + add_65;  matmul_20 = None
    float_13 = add_77.float()
    softmax_10 = torch.nn.functional.softmax(float_13, dim = -1, _stacklevel = 3, dtype = None);  float_13 = None
    type_as_10 = softmax_10.type_as(add_77);  softmax_10 = add_77 = None
    dropout_10 = torch.nn.functional.dropout(type_as_10, p = 0.1, training = False, inplace = False);  type_as_10 = None
    matmul_21 = torch.matmul(dropout_10, transpose_52);  dropout_10 = None
    transpose_54 = matmul_21.transpose(1, 2);  matmul_21 = None
    contiguous_10 = transpose_54.contiguous();  transpose_54 = None
    view_45 = contiguous_10.view(getitem_59, -1, 384);  contiguous_10 = getitem_59 = None
    decoder_block_1_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.o(view_45);  view_45 = None
    decoder_block_1_layer_0_dropout = getattr(getattr(self.decoder.block, "1").layer, "0").dropout(decoder_block_1_layer_0_self_attention_o);  decoder_block_1_layer_0_self_attention_o = None
    add_78 = add_75 + decoder_block_1_layer_0_dropout;  add_75 = decoder_block_1_layer_0_dropout = None
    getattr_71 = add_78.dtype
    eq_49 = getattr_71 == torch.float16;  getattr_71 = None
    size_20 = transpose_51.size()
    getitem_61 = size_20[2];  size_20 = None
    to_49 = add_78.to(torch.float32)
    pow_31 = to_49.pow(2);  to_49 = None
    mean_21 = pow_31.mean(-1, keepdim = True);  pow_31 = None
    add_79 = mean_21 + 1e-06;  mean_21 = None
    rsqrt_21 = torch.rsqrt(add_79);  add_79 = None
    mul_94 = add_78 * rsqrt_21;  rsqrt_21 = None
    decoder_block_1_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "1").layer, "1").layer_norm.weight
    getattr_72 = decoder_block_1_layer_1_layer_norm_weight.dtype
    eq_50 = getattr_72 == torch.float16;  getattr_72 = None
    getattr_73 = decoder_block_1_layer_1_layer_norm_weight.dtype
    to_50 = mul_94.to(getattr_73);  mul_94 = getattr_73 = None
    mul_95 = decoder_block_1_layer_1_layer_norm_weight * to_50;  decoder_block_1_layer_1_layer_norm_weight = to_50 = None
    size_21 = mul_95.size()
    getitem_62 = size_21[slice(None, 2, None)];  size_21 = None
    getitem_63 = getitem_62[0]
    getitem_64 = getitem_62[1];  getitem_62 = None
    size_22 = encoder_dropout_1.size()
    getitem_65 = size_22[1];  size_22 = None
    decoder_block_1_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.q(mul_95);  mul_95 = None
    view_46 = decoder_block_1_layer_1_enc_dec_attention_q.view(getitem_63, -1, 6, 64);  decoder_block_1_layer_1_enc_dec_attention_q = None
    transpose_55 = view_46.transpose(1, 2);  view_46 = None
    decoder_block_1_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_47 = decoder_block_1_layer_1_enc_dec_attention_k.view(getitem_63, -1, 6, 64);  decoder_block_1_layer_1_enc_dec_attention_k = None
    transpose_56 = view_47.transpose(1, 2);  view_47 = None
    decoder_block_1_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_48 = decoder_block_1_layer_1_enc_dec_attention_v.view(getitem_63, -1, 6, 64);  decoder_block_1_layer_1_enc_dec_attention_v = None
    transpose_57 = view_48.transpose(1, 2);  view_48 = None
    transpose_58 = transpose_56.transpose(3, 2)
    matmul_22 = torch.matmul(transpose_55, transpose_58);  transpose_55 = transpose_58 = None
    add_80 = matmul_22 + add_69;  matmul_22 = None
    float_14 = add_80.float()
    softmax_11 = torch.nn.functional.softmax(float_14, dim = -1, _stacklevel = 3, dtype = None);  float_14 = None
    type_as_11 = softmax_11.type_as(add_80);  softmax_11 = add_80 = None
    dropout_11 = torch.nn.functional.dropout(type_as_11, p = 0.1, training = False, inplace = False);  type_as_11 = None
    matmul_23 = torch.matmul(dropout_11, transpose_57);  dropout_11 = None
    transpose_59 = matmul_23.transpose(1, 2);  matmul_23 = None
    contiguous_11 = transpose_59.contiguous();  transpose_59 = None
    view_49 = contiguous_11.view(getitem_63, -1, 384);  contiguous_11 = getitem_63 = None
    decoder_block_1_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.o(view_49);  view_49 = None
    decoder_block_1_layer_1_dropout = getattr(getattr(self.decoder.block, "1").layer, "1").dropout(decoder_block_1_layer_1_enc_dec_attention_o);  decoder_block_1_layer_1_enc_dec_attention_o = None
    add_81 = add_78 + decoder_block_1_layer_1_dropout;  add_78 = decoder_block_1_layer_1_dropout = None
    getattr_74 = add_81.dtype
    eq_51 = getattr_74 == torch.float16;  getattr_74 = None
    to_51 = add_81.to(torch.float32)
    pow_32 = to_51.pow(2);  to_51 = None
    mean_22 = pow_32.mean(-1, keepdim = True);  pow_32 = None
    add_82 = mean_22 + 1e-06;  mean_22 = None
    rsqrt_22 = torch.rsqrt(add_82);  add_82 = None
    mul_96 = add_81 * rsqrt_22;  rsqrt_22 = None
    decoder_block_1_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "1").layer, "2").layer_norm.weight
    getattr_75 = decoder_block_1_layer_2_layer_norm_weight.dtype
    eq_52 = getattr_75 == torch.float16;  getattr_75 = None
    getattr_76 = decoder_block_1_layer_2_layer_norm_weight.dtype
    to_52 = mul_96.to(getattr_76);  mul_96 = getattr_76 = None
    mul_97 = decoder_block_1_layer_2_layer_norm_weight * to_52;  decoder_block_1_layer_2_layer_norm_weight = to_52 = None
    decoder_block_1_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.wo.weight
    linear1_9 = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.wi_0
    linear_layer_triton_wrapper_9 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_97, linear1_9, activation = 'fast_gelu');  linear1_9 = None
    linear2_9 = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.wi_1(mul_97);  mul_97 = None
    mul_180 = linear_layer_triton_wrapper_9 * linear2_9;  linear_layer_triton_wrapper_9 = linear2_9 = None
    dropout_33 = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.dropout(mul_180);  mul_180 = None
    linear3_9 = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.wo(dropout_33);  dropout_33 = None
    decoder_block_1_layer_2_dropout = getattr(getattr(self.decoder.block, "1").layer, "2").dropout(linear3_9);  linear3_9 = None
    add_85 = add_81 + decoder_block_1_layer_2_dropout;  add_81 = decoder_block_1_layer_2_dropout = None
    getattr_77 = add_85.dtype
    eq_53 = getattr_77 == torch.float16;  getattr_77 = None
    to_53 = add_85.to(torch.float32)
    pow_34 = to_53.pow(2);  to_53 = None
    mean_23 = pow_34.mean(-1, keepdim = True);  pow_34 = None
    add_86 = mean_23 + 1e-06;  mean_23 = None
    rsqrt_23 = torch.rsqrt(add_86);  add_86 = None
    mul_103 = add_85 * rsqrt_23;  rsqrt_23 = None
    decoder_block_2_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "2").layer, "0").layer_norm.weight
    getattr_78 = decoder_block_2_layer_0_layer_norm_weight.dtype
    eq_54 = getattr_78 == torch.float16;  getattr_78 = None
    getattr_79 = decoder_block_2_layer_0_layer_norm_weight.dtype
    to_54 = mul_103.to(getattr_79);  mul_103 = getattr_79 = None
    mul_104 = decoder_block_2_layer_0_layer_norm_weight * to_54;  decoder_block_2_layer_0_layer_norm_weight = to_54 = None
    size_23 = mul_104.size()
    getitem_66 = size_23[slice(None, 2, None)];  size_23 = None
    getitem_67 = getitem_66[0]
    getitem_68 = getitem_66[1];  getitem_66 = None
    decoder_block_2_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.q(mul_104)
    view_50 = decoder_block_2_layer_0_self_attention_q.view(getitem_67, -1, 6, 64);  decoder_block_2_layer_0_self_attention_q = None
    transpose_60 = view_50.transpose(1, 2);  view_50 = None
    decoder_block_2_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.k(mul_104)
    view_51 = decoder_block_2_layer_0_self_attention_k.view(getitem_67, -1, 6, 64);  decoder_block_2_layer_0_self_attention_k = None
    transpose_61 = view_51.transpose(1, 2);  view_51 = None
    decoder_block_2_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.v(mul_104);  mul_104 = None
    view_52 = decoder_block_2_layer_0_self_attention_v.view(getitem_67, -1, 6, 64);  decoder_block_2_layer_0_self_attention_v = None
    transpose_62 = view_52.transpose(1, 2);  view_52 = None
    transpose_63 = transpose_61.transpose(3, 2)
    matmul_24 = torch.matmul(transpose_60, transpose_63);  transpose_60 = transpose_63 = None
    add_87 = matmul_24 + add_65;  matmul_24 = None
    float_15 = add_87.float()
    softmax_12 = torch.nn.functional.softmax(float_15, dim = -1, _stacklevel = 3, dtype = None);  float_15 = None
    type_as_12 = softmax_12.type_as(add_87);  softmax_12 = add_87 = None
    dropout_12 = torch.nn.functional.dropout(type_as_12, p = 0.1, training = False, inplace = False);  type_as_12 = None
    matmul_25 = torch.matmul(dropout_12, transpose_62);  dropout_12 = None
    transpose_64 = matmul_25.transpose(1, 2);  matmul_25 = None
    contiguous_12 = transpose_64.contiguous();  transpose_64 = None
    view_53 = contiguous_12.view(getitem_67, -1, 384);  contiguous_12 = getitem_67 = None
    decoder_block_2_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.o(view_53);  view_53 = None
    decoder_block_2_layer_0_dropout = getattr(getattr(self.decoder.block, "2").layer, "0").dropout(decoder_block_2_layer_0_self_attention_o);  decoder_block_2_layer_0_self_attention_o = None
    add_88 = add_85 + decoder_block_2_layer_0_dropout;  add_85 = decoder_block_2_layer_0_dropout = None
    getattr_80 = add_88.dtype
    eq_55 = getattr_80 == torch.float16;  getattr_80 = None
    size_24 = transpose_61.size()
    getitem_69 = size_24[2];  size_24 = None
    to_55 = add_88.to(torch.float32)
    pow_35 = to_55.pow(2);  to_55 = None
    mean_24 = pow_35.mean(-1, keepdim = True);  pow_35 = None
    add_89 = mean_24 + 1e-06;  mean_24 = None
    rsqrt_24 = torch.rsqrt(add_89);  add_89 = None
    mul_105 = add_88 * rsqrt_24;  rsqrt_24 = None
    decoder_block_2_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "2").layer, "1").layer_norm.weight
    getattr_81 = decoder_block_2_layer_1_layer_norm_weight.dtype
    eq_56 = getattr_81 == torch.float16;  getattr_81 = None
    getattr_82 = decoder_block_2_layer_1_layer_norm_weight.dtype
    to_56 = mul_105.to(getattr_82);  mul_105 = getattr_82 = None
    mul_106 = decoder_block_2_layer_1_layer_norm_weight * to_56;  decoder_block_2_layer_1_layer_norm_weight = to_56 = None
    size_25 = mul_106.size()
    getitem_70 = size_25[slice(None, 2, None)];  size_25 = None
    getitem_71 = getitem_70[0]
    getitem_72 = getitem_70[1];  getitem_70 = None
    size_26 = encoder_dropout_1.size()
    getitem_73 = size_26[1];  size_26 = None
    decoder_block_2_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.q(mul_106);  mul_106 = None
    view_54 = decoder_block_2_layer_1_enc_dec_attention_q.view(getitem_71, -1, 6, 64);  decoder_block_2_layer_1_enc_dec_attention_q = None
    transpose_65 = view_54.transpose(1, 2);  view_54 = None
    decoder_block_2_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_55 = decoder_block_2_layer_1_enc_dec_attention_k.view(getitem_71, -1, 6, 64);  decoder_block_2_layer_1_enc_dec_attention_k = None
    transpose_66 = view_55.transpose(1, 2);  view_55 = None
    decoder_block_2_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_56 = decoder_block_2_layer_1_enc_dec_attention_v.view(getitem_71, -1, 6, 64);  decoder_block_2_layer_1_enc_dec_attention_v = None
    transpose_67 = view_56.transpose(1, 2);  view_56 = None
    transpose_68 = transpose_66.transpose(3, 2)
    matmul_26 = torch.matmul(transpose_65, transpose_68);  transpose_65 = transpose_68 = None
    add_90 = matmul_26 + add_69;  matmul_26 = None
    float_16 = add_90.float()
    softmax_13 = torch.nn.functional.softmax(float_16, dim = -1, _stacklevel = 3, dtype = None);  float_16 = None
    type_as_13 = softmax_13.type_as(add_90);  softmax_13 = add_90 = None
    dropout_13 = torch.nn.functional.dropout(type_as_13, p = 0.1, training = False, inplace = False);  type_as_13 = None
    matmul_27 = torch.matmul(dropout_13, transpose_67);  dropout_13 = None
    transpose_69 = matmul_27.transpose(1, 2);  matmul_27 = None
    contiguous_13 = transpose_69.contiguous();  transpose_69 = None
    view_57 = contiguous_13.view(getitem_71, -1, 384);  contiguous_13 = getitem_71 = None
    decoder_block_2_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.o(view_57);  view_57 = None
    decoder_block_2_layer_1_dropout = getattr(getattr(self.decoder.block, "2").layer, "1").dropout(decoder_block_2_layer_1_enc_dec_attention_o);  decoder_block_2_layer_1_enc_dec_attention_o = None
    add_91 = add_88 + decoder_block_2_layer_1_dropout;  add_88 = decoder_block_2_layer_1_dropout = None
    getattr_83 = add_91.dtype
    eq_57 = getattr_83 == torch.float16;  getattr_83 = None
    to_57 = add_91.to(torch.float32)
    pow_36 = to_57.pow(2);  to_57 = None
    mean_25 = pow_36.mean(-1, keepdim = True);  pow_36 = None
    add_92 = mean_25 + 1e-06;  mean_25 = None
    rsqrt_25 = torch.rsqrt(add_92);  add_92 = None
    mul_107 = add_91 * rsqrt_25;  rsqrt_25 = None
    decoder_block_2_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "2").layer, "2").layer_norm.weight
    getattr_84 = decoder_block_2_layer_2_layer_norm_weight.dtype
    eq_58 = getattr_84 == torch.float16;  getattr_84 = None
    getattr_85 = decoder_block_2_layer_2_layer_norm_weight.dtype
    to_58 = mul_107.to(getattr_85);  mul_107 = getattr_85 = None
    mul_108 = decoder_block_2_layer_2_layer_norm_weight * to_58;  decoder_block_2_layer_2_layer_norm_weight = to_58 = None
    decoder_block_2_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.wo.weight
    linear1_10 = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.wi_0
    linear_layer_triton_wrapper_10 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_108, linear1_10, activation = 'fast_gelu');  linear1_10 = None
    linear2_10 = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.wi_1(mul_108);  mul_108 = None
    mul_181 = linear_layer_triton_wrapper_10 * linear2_10;  linear_layer_triton_wrapper_10 = linear2_10 = None
    dropout_34 = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.dropout(mul_181);  mul_181 = None
    linear3_10 = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.wo(dropout_34);  dropout_34 = None
    decoder_block_2_layer_2_dropout = getattr(getattr(self.decoder.block, "2").layer, "2").dropout(linear3_10);  linear3_10 = None
    add_95 = add_91 + decoder_block_2_layer_2_dropout;  add_91 = decoder_block_2_layer_2_dropout = None
    getattr_86 = add_95.dtype
    eq_59 = getattr_86 == torch.float16;  getattr_86 = None
    to_59 = add_95.to(torch.float32)
    pow_38 = to_59.pow(2);  to_59 = None
    mean_26 = pow_38.mean(-1, keepdim = True);  pow_38 = None
    add_96 = mean_26 + 1e-06;  mean_26 = None
    rsqrt_26 = torch.rsqrt(add_96);  add_96 = None
    mul_114 = add_95 * rsqrt_26;  rsqrt_26 = None
    decoder_block_3_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "3").layer, "0").layer_norm.weight
    getattr_87 = decoder_block_3_layer_0_layer_norm_weight.dtype
    eq_60 = getattr_87 == torch.float16;  getattr_87 = None
    getattr_88 = decoder_block_3_layer_0_layer_norm_weight.dtype
    to_60 = mul_114.to(getattr_88);  mul_114 = getattr_88 = None
    mul_115 = decoder_block_3_layer_0_layer_norm_weight * to_60;  decoder_block_3_layer_0_layer_norm_weight = to_60 = None
    size_27 = mul_115.size()
    getitem_74 = size_27[slice(None, 2, None)];  size_27 = None
    getitem_75 = getitem_74[0]
    getitem_76 = getitem_74[1];  getitem_74 = None
    decoder_block_3_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.q(mul_115)
    view_58 = decoder_block_3_layer_0_self_attention_q.view(getitem_75, -1, 6, 64);  decoder_block_3_layer_0_self_attention_q = None
    transpose_70 = view_58.transpose(1, 2);  view_58 = None
    decoder_block_3_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.k(mul_115)
    view_59 = decoder_block_3_layer_0_self_attention_k.view(getitem_75, -1, 6, 64);  decoder_block_3_layer_0_self_attention_k = None
    transpose_71 = view_59.transpose(1, 2);  view_59 = None
    decoder_block_3_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.v(mul_115);  mul_115 = None
    view_60 = decoder_block_3_layer_0_self_attention_v.view(getitem_75, -1, 6, 64);  decoder_block_3_layer_0_self_attention_v = None
    transpose_72 = view_60.transpose(1, 2);  view_60 = None
    transpose_73 = transpose_71.transpose(3, 2)
    matmul_28 = torch.matmul(transpose_70, transpose_73);  transpose_70 = transpose_73 = None
    add_97 = matmul_28 + add_65;  matmul_28 = None
    float_17 = add_97.float()
    softmax_14 = torch.nn.functional.softmax(float_17, dim = -1, _stacklevel = 3, dtype = None);  float_17 = None
    type_as_14 = softmax_14.type_as(add_97);  softmax_14 = add_97 = None
    dropout_14 = torch.nn.functional.dropout(type_as_14, p = 0.1, training = False, inplace = False);  type_as_14 = None
    matmul_29 = torch.matmul(dropout_14, transpose_72);  dropout_14 = None
    transpose_74 = matmul_29.transpose(1, 2);  matmul_29 = None
    contiguous_14 = transpose_74.contiguous();  transpose_74 = None
    view_61 = contiguous_14.view(getitem_75, -1, 384);  contiguous_14 = getitem_75 = None
    decoder_block_3_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.o(view_61);  view_61 = None
    decoder_block_3_layer_0_dropout = getattr(getattr(self.decoder.block, "3").layer, "0").dropout(decoder_block_3_layer_0_self_attention_o);  decoder_block_3_layer_0_self_attention_o = None
    add_98 = add_95 + decoder_block_3_layer_0_dropout;  add_95 = decoder_block_3_layer_0_dropout = None
    getattr_89 = add_98.dtype
    eq_61 = getattr_89 == torch.float16;  getattr_89 = None
    size_28 = transpose_71.size()
    getitem_77 = size_28[2];  size_28 = None
    to_61 = add_98.to(torch.float32)
    pow_39 = to_61.pow(2);  to_61 = None
    mean_27 = pow_39.mean(-1, keepdim = True);  pow_39 = None
    add_99 = mean_27 + 1e-06;  mean_27 = None
    rsqrt_27 = torch.rsqrt(add_99);  add_99 = None
    mul_116 = add_98 * rsqrt_27;  rsqrt_27 = None
    decoder_block_3_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "3").layer, "1").layer_norm.weight
    getattr_90 = decoder_block_3_layer_1_layer_norm_weight.dtype
    eq_62 = getattr_90 == torch.float16;  getattr_90 = None
    getattr_91 = decoder_block_3_layer_1_layer_norm_weight.dtype
    to_62 = mul_116.to(getattr_91);  mul_116 = getattr_91 = None
    mul_117 = decoder_block_3_layer_1_layer_norm_weight * to_62;  decoder_block_3_layer_1_layer_norm_weight = to_62 = None
    size_29 = mul_117.size()
    getitem_78 = size_29[slice(None, 2, None)];  size_29 = None
    getitem_79 = getitem_78[0]
    getitem_80 = getitem_78[1];  getitem_78 = None
    size_30 = encoder_dropout_1.size()
    getitem_81 = size_30[1];  size_30 = None
    decoder_block_3_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.q(mul_117);  mul_117 = None
    view_62 = decoder_block_3_layer_1_enc_dec_attention_q.view(getitem_79, -1, 6, 64);  decoder_block_3_layer_1_enc_dec_attention_q = None
    transpose_75 = view_62.transpose(1, 2);  view_62 = None
    decoder_block_3_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_63 = decoder_block_3_layer_1_enc_dec_attention_k.view(getitem_79, -1, 6, 64);  decoder_block_3_layer_1_enc_dec_attention_k = None
    transpose_76 = view_63.transpose(1, 2);  view_63 = None
    decoder_block_3_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_64 = decoder_block_3_layer_1_enc_dec_attention_v.view(getitem_79, -1, 6, 64);  decoder_block_3_layer_1_enc_dec_attention_v = None
    transpose_77 = view_64.transpose(1, 2);  view_64 = None
    transpose_78 = transpose_76.transpose(3, 2)
    matmul_30 = torch.matmul(transpose_75, transpose_78);  transpose_75 = transpose_78 = None
    add_100 = matmul_30 + add_69;  matmul_30 = None
    float_18 = add_100.float()
    softmax_15 = torch.nn.functional.softmax(float_18, dim = -1, _stacklevel = 3, dtype = None);  float_18 = None
    type_as_15 = softmax_15.type_as(add_100);  softmax_15 = add_100 = None
    dropout_15 = torch.nn.functional.dropout(type_as_15, p = 0.1, training = False, inplace = False);  type_as_15 = None
    matmul_31 = torch.matmul(dropout_15, transpose_77);  dropout_15 = None
    transpose_79 = matmul_31.transpose(1, 2);  matmul_31 = None
    contiguous_15 = transpose_79.contiguous();  transpose_79 = None
    view_65 = contiguous_15.view(getitem_79, -1, 384);  contiguous_15 = getitem_79 = None
    decoder_block_3_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.o(view_65);  view_65 = None
    decoder_block_3_layer_1_dropout = getattr(getattr(self.decoder.block, "3").layer, "1").dropout(decoder_block_3_layer_1_enc_dec_attention_o);  decoder_block_3_layer_1_enc_dec_attention_o = None
    add_101 = add_98 + decoder_block_3_layer_1_dropout;  add_98 = decoder_block_3_layer_1_dropout = None
    getattr_92 = add_101.dtype
    eq_63 = getattr_92 == torch.float16;  getattr_92 = None
    to_63 = add_101.to(torch.float32)
    pow_40 = to_63.pow(2);  to_63 = None
    mean_28 = pow_40.mean(-1, keepdim = True);  pow_40 = None
    add_102 = mean_28 + 1e-06;  mean_28 = None
    rsqrt_28 = torch.rsqrt(add_102);  add_102 = None
    mul_118 = add_101 * rsqrt_28;  rsqrt_28 = None
    decoder_block_3_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "3").layer, "2").layer_norm.weight
    getattr_93 = decoder_block_3_layer_2_layer_norm_weight.dtype
    eq_64 = getattr_93 == torch.float16;  getattr_93 = None
    getattr_94 = decoder_block_3_layer_2_layer_norm_weight.dtype
    to_64 = mul_118.to(getattr_94);  mul_118 = getattr_94 = None
    mul_119 = decoder_block_3_layer_2_layer_norm_weight * to_64;  decoder_block_3_layer_2_layer_norm_weight = to_64 = None
    decoder_block_3_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.wo.weight
    linear1_11 = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.wi_0
    linear_layer_triton_wrapper_11 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_119, linear1_11, activation = 'fast_gelu');  linear1_11 = None
    linear2_11 = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.wi_1(mul_119);  mul_119 = None
    mul_182 = linear_layer_triton_wrapper_11 * linear2_11;  linear_layer_triton_wrapper_11 = linear2_11 = None
    dropout_35 = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.dropout(mul_182);  mul_182 = None
    linear3_11 = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.wo(dropout_35);  dropout_35 = None
    decoder_block_3_layer_2_dropout = getattr(getattr(self.decoder.block, "3").layer, "2").dropout(linear3_11);  linear3_11 = None
    add_105 = add_101 + decoder_block_3_layer_2_dropout;  add_101 = decoder_block_3_layer_2_dropout = None
    getattr_95 = add_105.dtype
    eq_65 = getattr_95 == torch.float16;  getattr_95 = None
    to_65 = add_105.to(torch.float32)
    pow_42 = to_65.pow(2);  to_65 = None
    mean_29 = pow_42.mean(-1, keepdim = True);  pow_42 = None
    add_106 = mean_29 + 1e-06;  mean_29 = None
    rsqrt_29 = torch.rsqrt(add_106);  add_106 = None
    mul_125 = add_105 * rsqrt_29;  rsqrt_29 = None
    decoder_block_4_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "4").layer, "0").layer_norm.weight
    getattr_96 = decoder_block_4_layer_0_layer_norm_weight.dtype
    eq_66 = getattr_96 == torch.float16;  getattr_96 = None
    getattr_97 = decoder_block_4_layer_0_layer_norm_weight.dtype
    to_66 = mul_125.to(getattr_97);  mul_125 = getattr_97 = None
    mul_126 = decoder_block_4_layer_0_layer_norm_weight * to_66;  decoder_block_4_layer_0_layer_norm_weight = to_66 = None
    size_31 = mul_126.size()
    getitem_82 = size_31[slice(None, 2, None)];  size_31 = None
    getitem_83 = getitem_82[0]
    getitem_84 = getitem_82[1];  getitem_82 = None
    decoder_block_4_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.q(mul_126)
    view_66 = decoder_block_4_layer_0_self_attention_q.view(getitem_83, -1, 6, 64);  decoder_block_4_layer_0_self_attention_q = None
    transpose_80 = view_66.transpose(1, 2);  view_66 = None
    decoder_block_4_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.k(mul_126)
    view_67 = decoder_block_4_layer_0_self_attention_k.view(getitem_83, -1, 6, 64);  decoder_block_4_layer_0_self_attention_k = None
    transpose_81 = view_67.transpose(1, 2);  view_67 = None
    decoder_block_4_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.v(mul_126);  mul_126 = None
    view_68 = decoder_block_4_layer_0_self_attention_v.view(getitem_83, -1, 6, 64);  decoder_block_4_layer_0_self_attention_v = None
    transpose_82 = view_68.transpose(1, 2);  view_68 = None
    transpose_83 = transpose_81.transpose(3, 2)
    matmul_32 = torch.matmul(transpose_80, transpose_83);  transpose_80 = transpose_83 = None
    add_107 = matmul_32 + add_65;  matmul_32 = None
    float_19 = add_107.float()
    softmax_16 = torch.nn.functional.softmax(float_19, dim = -1, _stacklevel = 3, dtype = None);  float_19 = None
    type_as_16 = softmax_16.type_as(add_107);  softmax_16 = add_107 = None
    dropout_16 = torch.nn.functional.dropout(type_as_16, p = 0.1, training = False, inplace = False);  type_as_16 = None
    matmul_33 = torch.matmul(dropout_16, transpose_82);  dropout_16 = None
    transpose_84 = matmul_33.transpose(1, 2);  matmul_33 = None
    contiguous_16 = transpose_84.contiguous();  transpose_84 = None
    view_69 = contiguous_16.view(getitem_83, -1, 384);  contiguous_16 = getitem_83 = None
    decoder_block_4_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.o(view_69);  view_69 = None
    decoder_block_4_layer_0_dropout = getattr(getattr(self.decoder.block, "4").layer, "0").dropout(decoder_block_4_layer_0_self_attention_o);  decoder_block_4_layer_0_self_attention_o = None
    add_108 = add_105 + decoder_block_4_layer_0_dropout;  add_105 = decoder_block_4_layer_0_dropout = None
    getattr_98 = add_108.dtype
    eq_67 = getattr_98 == torch.float16;  getattr_98 = None
    size_32 = transpose_81.size()
    getitem_85 = size_32[2];  size_32 = None
    to_67 = add_108.to(torch.float32)
    pow_43 = to_67.pow(2);  to_67 = None
    mean_30 = pow_43.mean(-1, keepdim = True);  pow_43 = None
    add_109 = mean_30 + 1e-06;  mean_30 = None
    rsqrt_30 = torch.rsqrt(add_109);  add_109 = None
    mul_127 = add_108 * rsqrt_30;  rsqrt_30 = None
    decoder_block_4_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "4").layer, "1").layer_norm.weight
    getattr_99 = decoder_block_4_layer_1_layer_norm_weight.dtype
    eq_68 = getattr_99 == torch.float16;  getattr_99 = None
    getattr_100 = decoder_block_4_layer_1_layer_norm_weight.dtype
    to_68 = mul_127.to(getattr_100);  mul_127 = getattr_100 = None
    mul_128 = decoder_block_4_layer_1_layer_norm_weight * to_68;  decoder_block_4_layer_1_layer_norm_weight = to_68 = None
    size_33 = mul_128.size()
    getitem_86 = size_33[slice(None, 2, None)];  size_33 = None
    getitem_87 = getitem_86[0]
    getitem_88 = getitem_86[1];  getitem_86 = None
    size_34 = encoder_dropout_1.size()
    getitem_89 = size_34[1];  size_34 = None
    decoder_block_4_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.q(mul_128);  mul_128 = None
    view_70 = decoder_block_4_layer_1_enc_dec_attention_q.view(getitem_87, -1, 6, 64);  decoder_block_4_layer_1_enc_dec_attention_q = None
    transpose_85 = view_70.transpose(1, 2);  view_70 = None
    decoder_block_4_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_71 = decoder_block_4_layer_1_enc_dec_attention_k.view(getitem_87, -1, 6, 64);  decoder_block_4_layer_1_enc_dec_attention_k = None
    transpose_86 = view_71.transpose(1, 2);  view_71 = None
    decoder_block_4_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_72 = decoder_block_4_layer_1_enc_dec_attention_v.view(getitem_87, -1, 6, 64);  decoder_block_4_layer_1_enc_dec_attention_v = None
    transpose_87 = view_72.transpose(1, 2);  view_72 = None
    transpose_88 = transpose_86.transpose(3, 2)
    matmul_34 = torch.matmul(transpose_85, transpose_88);  transpose_85 = transpose_88 = None
    add_110 = matmul_34 + add_69;  matmul_34 = None
    float_20 = add_110.float()
    softmax_17 = torch.nn.functional.softmax(float_20, dim = -1, _stacklevel = 3, dtype = None);  float_20 = None
    type_as_17 = softmax_17.type_as(add_110);  softmax_17 = add_110 = None
    dropout_17 = torch.nn.functional.dropout(type_as_17, p = 0.1, training = False, inplace = False);  type_as_17 = None
    matmul_35 = torch.matmul(dropout_17, transpose_87);  dropout_17 = None
    transpose_89 = matmul_35.transpose(1, 2);  matmul_35 = None
    contiguous_17 = transpose_89.contiguous();  transpose_89 = None
    view_73 = contiguous_17.view(getitem_87, -1, 384);  contiguous_17 = getitem_87 = None
    decoder_block_4_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.o(view_73);  view_73 = None
    decoder_block_4_layer_1_dropout = getattr(getattr(self.decoder.block, "4").layer, "1").dropout(decoder_block_4_layer_1_enc_dec_attention_o);  decoder_block_4_layer_1_enc_dec_attention_o = None
    add_111 = add_108 + decoder_block_4_layer_1_dropout;  add_108 = decoder_block_4_layer_1_dropout = None
    getattr_101 = add_111.dtype
    eq_69 = getattr_101 == torch.float16;  getattr_101 = None
    to_69 = add_111.to(torch.float32)
    pow_44 = to_69.pow(2);  to_69 = None
    mean_31 = pow_44.mean(-1, keepdim = True);  pow_44 = None
    add_112 = mean_31 + 1e-06;  mean_31 = None
    rsqrt_31 = torch.rsqrt(add_112);  add_112 = None
    mul_129 = add_111 * rsqrt_31;  rsqrt_31 = None
    decoder_block_4_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "4").layer, "2").layer_norm.weight
    getattr_102 = decoder_block_4_layer_2_layer_norm_weight.dtype
    eq_70 = getattr_102 == torch.float16;  getattr_102 = None
    getattr_103 = decoder_block_4_layer_2_layer_norm_weight.dtype
    to_70 = mul_129.to(getattr_103);  mul_129 = getattr_103 = None
    mul_130 = decoder_block_4_layer_2_layer_norm_weight * to_70;  decoder_block_4_layer_2_layer_norm_weight = to_70 = None
    decoder_block_4_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.wo.weight
    linear1_12 = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.wi_0
    linear_layer_triton_wrapper_12 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_130, linear1_12, activation = 'fast_gelu');  linear1_12 = None
    linear2_12 = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.wi_1(mul_130);  mul_130 = None
    mul_183 = linear_layer_triton_wrapper_12 * linear2_12;  linear_layer_triton_wrapper_12 = linear2_12 = None
    dropout_36 = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.dropout(mul_183);  mul_183 = None
    linear3_12 = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.wo(dropout_36);  dropout_36 = None
    decoder_block_4_layer_2_dropout = getattr(getattr(self.decoder.block, "4").layer, "2").dropout(linear3_12);  linear3_12 = None
    add_115 = add_111 + decoder_block_4_layer_2_dropout;  add_111 = decoder_block_4_layer_2_dropout = None
    getattr_104 = add_115.dtype
    eq_71 = getattr_104 == torch.float16;  getattr_104 = None
    to_71 = add_115.to(torch.float32)
    pow_46 = to_71.pow(2);  to_71 = None
    mean_32 = pow_46.mean(-1, keepdim = True);  pow_46 = None
    add_116 = mean_32 + 1e-06;  mean_32 = None
    rsqrt_32 = torch.rsqrt(add_116);  add_116 = None
    mul_136 = add_115 * rsqrt_32;  rsqrt_32 = None
    decoder_block_5_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "5").layer, "0").layer_norm.weight
    getattr_105 = decoder_block_5_layer_0_layer_norm_weight.dtype
    eq_72 = getattr_105 == torch.float16;  getattr_105 = None
    getattr_106 = decoder_block_5_layer_0_layer_norm_weight.dtype
    to_72 = mul_136.to(getattr_106);  mul_136 = getattr_106 = None
    mul_137 = decoder_block_5_layer_0_layer_norm_weight * to_72;  decoder_block_5_layer_0_layer_norm_weight = to_72 = None
    size_35 = mul_137.size()
    getitem_90 = size_35[slice(None, 2, None)];  size_35 = None
    getitem_91 = getitem_90[0]
    getitem_92 = getitem_90[1];  getitem_90 = None
    decoder_block_5_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.q(mul_137)
    view_74 = decoder_block_5_layer_0_self_attention_q.view(getitem_91, -1, 6, 64);  decoder_block_5_layer_0_self_attention_q = None
    transpose_90 = view_74.transpose(1, 2);  view_74 = None
    decoder_block_5_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.k(mul_137)
    view_75 = decoder_block_5_layer_0_self_attention_k.view(getitem_91, -1, 6, 64);  decoder_block_5_layer_0_self_attention_k = None
    transpose_91 = view_75.transpose(1, 2);  view_75 = None
    decoder_block_5_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.v(mul_137);  mul_137 = None
    view_76 = decoder_block_5_layer_0_self_attention_v.view(getitem_91, -1, 6, 64);  decoder_block_5_layer_0_self_attention_v = None
    transpose_92 = view_76.transpose(1, 2);  view_76 = None
    transpose_93 = transpose_91.transpose(3, 2)
    matmul_36 = torch.matmul(transpose_90, transpose_93);  transpose_90 = transpose_93 = None
    add_117 = matmul_36 + add_65;  matmul_36 = None
    float_21 = add_117.float()
    softmax_18 = torch.nn.functional.softmax(float_21, dim = -1, _stacklevel = 3, dtype = None);  float_21 = None
    type_as_18 = softmax_18.type_as(add_117);  softmax_18 = add_117 = None
    dropout_18 = torch.nn.functional.dropout(type_as_18, p = 0.1, training = False, inplace = False);  type_as_18 = None
    matmul_37 = torch.matmul(dropout_18, transpose_92);  dropout_18 = None
    transpose_94 = matmul_37.transpose(1, 2);  matmul_37 = None
    contiguous_18 = transpose_94.contiguous();  transpose_94 = None
    view_77 = contiguous_18.view(getitem_91, -1, 384);  contiguous_18 = getitem_91 = None
    decoder_block_5_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.o(view_77);  view_77 = None
    decoder_block_5_layer_0_dropout = getattr(getattr(self.decoder.block, "5").layer, "0").dropout(decoder_block_5_layer_0_self_attention_o);  decoder_block_5_layer_0_self_attention_o = None
    add_118 = add_115 + decoder_block_5_layer_0_dropout;  add_115 = decoder_block_5_layer_0_dropout = None
    getattr_107 = add_118.dtype
    eq_73 = getattr_107 == torch.float16;  getattr_107 = None
    size_36 = transpose_91.size()
    getitem_93 = size_36[2];  size_36 = None
    to_73 = add_118.to(torch.float32)
    pow_47 = to_73.pow(2);  to_73 = None
    mean_33 = pow_47.mean(-1, keepdim = True);  pow_47 = None
    add_119 = mean_33 + 1e-06;  mean_33 = None
    rsqrt_33 = torch.rsqrt(add_119);  add_119 = None
    mul_138 = add_118 * rsqrt_33;  rsqrt_33 = None
    decoder_block_5_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "5").layer, "1").layer_norm.weight
    getattr_108 = decoder_block_5_layer_1_layer_norm_weight.dtype
    eq_74 = getattr_108 == torch.float16;  getattr_108 = None
    getattr_109 = decoder_block_5_layer_1_layer_norm_weight.dtype
    to_74 = mul_138.to(getattr_109);  mul_138 = getattr_109 = None
    mul_139 = decoder_block_5_layer_1_layer_norm_weight * to_74;  decoder_block_5_layer_1_layer_norm_weight = to_74 = None
    size_37 = mul_139.size()
    getitem_94 = size_37[slice(None, 2, None)];  size_37 = None
    getitem_95 = getitem_94[0]
    getitem_96 = getitem_94[1];  getitem_94 = None
    size_38 = encoder_dropout_1.size()
    getitem_97 = size_38[1];  size_38 = None
    decoder_block_5_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.q(mul_139);  mul_139 = None
    view_78 = decoder_block_5_layer_1_enc_dec_attention_q.view(getitem_95, -1, 6, 64);  decoder_block_5_layer_1_enc_dec_attention_q = None
    transpose_95 = view_78.transpose(1, 2);  view_78 = None
    decoder_block_5_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_79 = decoder_block_5_layer_1_enc_dec_attention_k.view(getitem_95, -1, 6, 64);  decoder_block_5_layer_1_enc_dec_attention_k = None
    transpose_96 = view_79.transpose(1, 2);  view_79 = None
    decoder_block_5_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_80 = decoder_block_5_layer_1_enc_dec_attention_v.view(getitem_95, -1, 6, 64);  decoder_block_5_layer_1_enc_dec_attention_v = None
    transpose_97 = view_80.transpose(1, 2);  view_80 = None
    transpose_98 = transpose_96.transpose(3, 2)
    matmul_38 = torch.matmul(transpose_95, transpose_98);  transpose_95 = transpose_98 = None
    add_120 = matmul_38 + add_69;  matmul_38 = None
    float_22 = add_120.float()
    softmax_19 = torch.nn.functional.softmax(float_22, dim = -1, _stacklevel = 3, dtype = None);  float_22 = None
    type_as_19 = softmax_19.type_as(add_120);  softmax_19 = add_120 = None
    dropout_19 = torch.nn.functional.dropout(type_as_19, p = 0.1, training = False, inplace = False);  type_as_19 = None
    matmul_39 = torch.matmul(dropout_19, transpose_97);  dropout_19 = None
    transpose_99 = matmul_39.transpose(1, 2);  matmul_39 = None
    contiguous_19 = transpose_99.contiguous();  transpose_99 = None
    view_81 = contiguous_19.view(getitem_95, -1, 384);  contiguous_19 = getitem_95 = None
    decoder_block_5_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.o(view_81);  view_81 = None
    decoder_block_5_layer_1_dropout = getattr(getattr(self.decoder.block, "5").layer, "1").dropout(decoder_block_5_layer_1_enc_dec_attention_o);  decoder_block_5_layer_1_enc_dec_attention_o = None
    add_121 = add_118 + decoder_block_5_layer_1_dropout;  add_118 = decoder_block_5_layer_1_dropout = None
    getattr_110 = add_121.dtype
    eq_75 = getattr_110 == torch.float16;  getattr_110 = None
    to_75 = add_121.to(torch.float32)
    pow_48 = to_75.pow(2);  to_75 = None
    mean_34 = pow_48.mean(-1, keepdim = True);  pow_48 = None
    add_122 = mean_34 + 1e-06;  mean_34 = None
    rsqrt_34 = torch.rsqrt(add_122);  add_122 = None
    mul_140 = add_121 * rsqrt_34;  rsqrt_34 = None
    decoder_block_5_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "5").layer, "2").layer_norm.weight
    getattr_111 = decoder_block_5_layer_2_layer_norm_weight.dtype
    eq_76 = getattr_111 == torch.float16;  getattr_111 = None
    getattr_112 = decoder_block_5_layer_2_layer_norm_weight.dtype
    to_76 = mul_140.to(getattr_112);  mul_140 = getattr_112 = None
    mul_141 = decoder_block_5_layer_2_layer_norm_weight * to_76;  decoder_block_5_layer_2_layer_norm_weight = to_76 = None
    decoder_block_5_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.wo.weight
    linear1_13 = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.wi_0
    linear_layer_triton_wrapper_13 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_141, linear1_13, activation = 'fast_gelu');  linear1_13 = None
    linear2_13 = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.wi_1(mul_141);  mul_141 = None
    mul_184 = linear_layer_triton_wrapper_13 * linear2_13;  linear_layer_triton_wrapper_13 = linear2_13 = None
    dropout_37 = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.dropout(mul_184);  mul_184 = None
    linear3_13 = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.wo(dropout_37);  dropout_37 = None
    decoder_block_5_layer_2_dropout = getattr(getattr(self.decoder.block, "5").layer, "2").dropout(linear3_13);  linear3_13 = None
    add_125 = add_121 + decoder_block_5_layer_2_dropout;  add_121 = decoder_block_5_layer_2_dropout = None
    getattr_113 = add_125.dtype
    eq_77 = getattr_113 == torch.float16;  getattr_113 = None
    to_77 = add_125.to(torch.float32)
    pow_50 = to_77.pow(2);  to_77 = None
    mean_35 = pow_50.mean(-1, keepdim = True);  pow_50 = None
    add_126 = mean_35 + 1e-06;  mean_35 = None
    rsqrt_35 = torch.rsqrt(add_126);  add_126 = None
    mul_147 = add_125 * rsqrt_35;  rsqrt_35 = None
    decoder_block_6_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "6").layer, "0").layer_norm.weight
    getattr_114 = decoder_block_6_layer_0_layer_norm_weight.dtype
    eq_78 = getattr_114 == torch.float16;  getattr_114 = None
    getattr_115 = decoder_block_6_layer_0_layer_norm_weight.dtype
    to_78 = mul_147.to(getattr_115);  mul_147 = getattr_115 = None
    mul_148 = decoder_block_6_layer_0_layer_norm_weight * to_78;  decoder_block_6_layer_0_layer_norm_weight = to_78 = None
    size_39 = mul_148.size()
    getitem_98 = size_39[slice(None, 2, None)];  size_39 = None
    getitem_99 = getitem_98[0]
    getitem_100 = getitem_98[1];  getitem_98 = None
    decoder_block_6_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "6").layer, "0").SelfAttention.q(mul_148)
    view_82 = decoder_block_6_layer_0_self_attention_q.view(getitem_99, -1, 6, 64);  decoder_block_6_layer_0_self_attention_q = None
    transpose_100 = view_82.transpose(1, 2);  view_82 = None
    decoder_block_6_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "6").layer, "0").SelfAttention.k(mul_148)
    view_83 = decoder_block_6_layer_0_self_attention_k.view(getitem_99, -1, 6, 64);  decoder_block_6_layer_0_self_attention_k = None
    transpose_101 = view_83.transpose(1, 2);  view_83 = None
    decoder_block_6_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "6").layer, "0").SelfAttention.v(mul_148);  mul_148 = None
    view_84 = decoder_block_6_layer_0_self_attention_v.view(getitem_99, -1, 6, 64);  decoder_block_6_layer_0_self_attention_v = None
    transpose_102 = view_84.transpose(1, 2);  view_84 = None
    transpose_103 = transpose_101.transpose(3, 2)
    matmul_40 = torch.matmul(transpose_100, transpose_103);  transpose_100 = transpose_103 = None
    add_127 = matmul_40 + add_65;  matmul_40 = None
    float_23 = add_127.float()
    softmax_20 = torch.nn.functional.softmax(float_23, dim = -1, _stacklevel = 3, dtype = None);  float_23 = None
    type_as_20 = softmax_20.type_as(add_127);  softmax_20 = add_127 = None
    dropout_20 = torch.nn.functional.dropout(type_as_20, p = 0.1, training = False, inplace = False);  type_as_20 = None
    matmul_41 = torch.matmul(dropout_20, transpose_102);  dropout_20 = None
    transpose_104 = matmul_41.transpose(1, 2);  matmul_41 = None
    contiguous_20 = transpose_104.contiguous();  transpose_104 = None
    view_85 = contiguous_20.view(getitem_99, -1, 384);  contiguous_20 = getitem_99 = None
    decoder_block_6_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "6").layer, "0").SelfAttention.o(view_85);  view_85 = None
    decoder_block_6_layer_0_dropout = getattr(getattr(self.decoder.block, "6").layer, "0").dropout(decoder_block_6_layer_0_self_attention_o);  decoder_block_6_layer_0_self_attention_o = None
    add_128 = add_125 + decoder_block_6_layer_0_dropout;  add_125 = decoder_block_6_layer_0_dropout = None
    getattr_116 = add_128.dtype
    eq_79 = getattr_116 == torch.float16;  getattr_116 = None
    size_40 = transpose_101.size()
    getitem_101 = size_40[2];  size_40 = None
    to_79 = add_128.to(torch.float32)
    pow_51 = to_79.pow(2);  to_79 = None
    mean_36 = pow_51.mean(-1, keepdim = True);  pow_51 = None
    add_129 = mean_36 + 1e-06;  mean_36 = None
    rsqrt_36 = torch.rsqrt(add_129);  add_129 = None
    mul_149 = add_128 * rsqrt_36;  rsqrt_36 = None
    decoder_block_6_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "6").layer, "1").layer_norm.weight
    getattr_117 = decoder_block_6_layer_1_layer_norm_weight.dtype
    eq_80 = getattr_117 == torch.float16;  getattr_117 = None
    getattr_118 = decoder_block_6_layer_1_layer_norm_weight.dtype
    to_80 = mul_149.to(getattr_118);  mul_149 = getattr_118 = None
    mul_150 = decoder_block_6_layer_1_layer_norm_weight * to_80;  decoder_block_6_layer_1_layer_norm_weight = to_80 = None
    size_41 = mul_150.size()
    getitem_102 = size_41[slice(None, 2, None)];  size_41 = None
    getitem_103 = getitem_102[0]
    getitem_104 = getitem_102[1];  getitem_102 = None
    size_42 = encoder_dropout_1.size()
    getitem_105 = size_42[1];  size_42 = None
    decoder_block_6_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "6").layer, "1").EncDecAttention.q(mul_150);  mul_150 = None
    view_86 = decoder_block_6_layer_1_enc_dec_attention_q.view(getitem_103, -1, 6, 64);  decoder_block_6_layer_1_enc_dec_attention_q = None
    transpose_105 = view_86.transpose(1, 2);  view_86 = None
    decoder_block_6_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "6").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_87 = decoder_block_6_layer_1_enc_dec_attention_k.view(getitem_103, -1, 6, 64);  decoder_block_6_layer_1_enc_dec_attention_k = None
    transpose_106 = view_87.transpose(1, 2);  view_87 = None
    decoder_block_6_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "6").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_88 = decoder_block_6_layer_1_enc_dec_attention_v.view(getitem_103, -1, 6, 64);  decoder_block_6_layer_1_enc_dec_attention_v = None
    transpose_107 = view_88.transpose(1, 2);  view_88 = None
    transpose_108 = transpose_106.transpose(3, 2)
    matmul_42 = torch.matmul(transpose_105, transpose_108);  transpose_105 = transpose_108 = None
    add_130 = matmul_42 + add_69;  matmul_42 = None
    float_24 = add_130.float()
    softmax_21 = torch.nn.functional.softmax(float_24, dim = -1, _stacklevel = 3, dtype = None);  float_24 = None
    type_as_21 = softmax_21.type_as(add_130);  softmax_21 = add_130 = None
    dropout_21 = torch.nn.functional.dropout(type_as_21, p = 0.1, training = False, inplace = False);  type_as_21 = None
    matmul_43 = torch.matmul(dropout_21, transpose_107);  dropout_21 = None
    transpose_109 = matmul_43.transpose(1, 2);  matmul_43 = None
    contiguous_21 = transpose_109.contiguous();  transpose_109 = None
    view_89 = contiguous_21.view(getitem_103, -1, 384);  contiguous_21 = getitem_103 = None
    decoder_block_6_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "6").layer, "1").EncDecAttention.o(view_89);  view_89 = None
    decoder_block_6_layer_1_dropout = getattr(getattr(self.decoder.block, "6").layer, "1").dropout(decoder_block_6_layer_1_enc_dec_attention_o);  decoder_block_6_layer_1_enc_dec_attention_o = None
    add_131 = add_128 + decoder_block_6_layer_1_dropout;  add_128 = decoder_block_6_layer_1_dropout = None
    getattr_119 = add_131.dtype
    eq_81 = getattr_119 == torch.float16;  getattr_119 = None
    to_81 = add_131.to(torch.float32)
    pow_52 = to_81.pow(2);  to_81 = None
    mean_37 = pow_52.mean(-1, keepdim = True);  pow_52 = None
    add_132 = mean_37 + 1e-06;  mean_37 = None
    rsqrt_37 = torch.rsqrt(add_132);  add_132 = None
    mul_151 = add_131 * rsqrt_37;  rsqrt_37 = None
    decoder_block_6_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "6").layer, "2").layer_norm.weight
    getattr_120 = decoder_block_6_layer_2_layer_norm_weight.dtype
    eq_82 = getattr_120 == torch.float16;  getattr_120 = None
    getattr_121 = decoder_block_6_layer_2_layer_norm_weight.dtype
    to_82 = mul_151.to(getattr_121);  mul_151 = getattr_121 = None
    mul_152 = decoder_block_6_layer_2_layer_norm_weight * to_82;  decoder_block_6_layer_2_layer_norm_weight = to_82 = None
    decoder_block_6_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "6").layer, "2").DenseReluDense.wo.weight
    linear1_14 = getattr(getattr(self.decoder.block, "6").layer, "2").DenseReluDense.wi_0
    linear_layer_triton_wrapper_14 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_152, linear1_14, activation = 'fast_gelu');  linear1_14 = None
    linear2_14 = getattr(getattr(self.decoder.block, "6").layer, "2").DenseReluDense.wi_1(mul_152);  mul_152 = None
    mul_185 = linear_layer_triton_wrapper_14 * linear2_14;  linear_layer_triton_wrapper_14 = linear2_14 = None
    dropout_38 = getattr(getattr(self.decoder.block, "6").layer, "2").DenseReluDense.dropout(mul_185);  mul_185 = None
    linear3_14 = getattr(getattr(self.decoder.block, "6").layer, "2").DenseReluDense.wo(dropout_38);  dropout_38 = None
    decoder_block_6_layer_2_dropout = getattr(getattr(self.decoder.block, "6").layer, "2").dropout(linear3_14);  linear3_14 = None
    add_135 = add_131 + decoder_block_6_layer_2_dropout;  add_131 = decoder_block_6_layer_2_dropout = None
    getattr_122 = add_135.dtype
    eq_83 = getattr_122 == torch.float16;  getattr_122 = None
    to_83 = add_135.to(torch.float32)
    pow_54 = to_83.pow(2);  to_83 = None
    mean_38 = pow_54.mean(-1, keepdim = True);  pow_54 = None
    add_136 = mean_38 + 1e-06;  mean_38 = None
    rsqrt_38 = torch.rsqrt(add_136);  add_136 = None
    mul_158 = add_135 * rsqrt_38;  rsqrt_38 = None
    decoder_block_7_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "7").layer, "0").layer_norm.weight
    getattr_123 = decoder_block_7_layer_0_layer_norm_weight.dtype
    eq_84 = getattr_123 == torch.float16;  getattr_123 = None
    getattr_124 = decoder_block_7_layer_0_layer_norm_weight.dtype
    to_84 = mul_158.to(getattr_124);  mul_158 = getattr_124 = None
    mul_159 = decoder_block_7_layer_0_layer_norm_weight * to_84;  decoder_block_7_layer_0_layer_norm_weight = to_84 = None
    size_43 = mul_159.size()
    getitem_106 = size_43[slice(None, 2, None)];  size_43 = None
    getitem_107 = getitem_106[0]
    getitem_108 = getitem_106[1];  getitem_106 = None
    decoder_block_7_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "7").layer, "0").SelfAttention.q(mul_159)
    view_90 = decoder_block_7_layer_0_self_attention_q.view(getitem_107, -1, 6, 64);  decoder_block_7_layer_0_self_attention_q = None
    transpose_110 = view_90.transpose(1, 2);  view_90 = None
    decoder_block_7_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "7").layer, "0").SelfAttention.k(mul_159)
    view_91 = decoder_block_7_layer_0_self_attention_k.view(getitem_107, -1, 6, 64);  decoder_block_7_layer_0_self_attention_k = None
    transpose_111 = view_91.transpose(1, 2);  view_91 = None
    decoder_block_7_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "7").layer, "0").SelfAttention.v(mul_159);  mul_159 = None
    view_92 = decoder_block_7_layer_0_self_attention_v.view(getitem_107, -1, 6, 64);  decoder_block_7_layer_0_self_attention_v = None
    transpose_112 = view_92.transpose(1, 2);  view_92 = None
    transpose_113 = transpose_111.transpose(3, 2)
    matmul_44 = torch.matmul(transpose_110, transpose_113);  transpose_110 = transpose_113 = None
    add_137 = matmul_44 + add_65;  matmul_44 = add_65 = None
    float_25 = add_137.float()
    softmax_22 = torch.nn.functional.softmax(float_25, dim = -1, _stacklevel = 3, dtype = None);  float_25 = None
    type_as_22 = softmax_22.type_as(add_137);  softmax_22 = add_137 = None
    dropout_22 = torch.nn.functional.dropout(type_as_22, p = 0.1, training = False, inplace = False);  type_as_22 = None
    matmul_45 = torch.matmul(dropout_22, transpose_112);  dropout_22 = None
    transpose_114 = matmul_45.transpose(1, 2);  matmul_45 = None
    contiguous_22 = transpose_114.contiguous();  transpose_114 = None
    view_93 = contiguous_22.view(getitem_107, -1, 384);  contiguous_22 = getitem_107 = None
    decoder_block_7_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "7").layer, "0").SelfAttention.o(view_93);  view_93 = None
    decoder_block_7_layer_0_dropout = getattr(getattr(self.decoder.block, "7").layer, "0").dropout(decoder_block_7_layer_0_self_attention_o);  decoder_block_7_layer_0_self_attention_o = None
    add_138 = add_135 + decoder_block_7_layer_0_dropout;  add_135 = decoder_block_7_layer_0_dropout = None
    getattr_125 = add_138.dtype
    eq_85 = getattr_125 == torch.float16;  getattr_125 = None
    size_44 = transpose_111.size()
    getitem_109 = size_44[2];  size_44 = None
    to_85 = add_138.to(torch.float32)
    pow_55 = to_85.pow(2);  to_85 = None
    mean_39 = pow_55.mean(-1, keepdim = True);  pow_55 = None
    add_139 = mean_39 + 1e-06;  mean_39 = None
    rsqrt_39 = torch.rsqrt(add_139);  add_139 = None
    mul_160 = add_138 * rsqrt_39;  rsqrt_39 = None
    decoder_block_7_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "7").layer, "1").layer_norm.weight
    getattr_126 = decoder_block_7_layer_1_layer_norm_weight.dtype
    eq_86 = getattr_126 == torch.float16;  getattr_126 = None
    getattr_127 = decoder_block_7_layer_1_layer_norm_weight.dtype
    to_86 = mul_160.to(getattr_127);  mul_160 = getattr_127 = None
    mul_161 = decoder_block_7_layer_1_layer_norm_weight * to_86;  decoder_block_7_layer_1_layer_norm_weight = to_86 = None
    size_45 = mul_161.size()
    getitem_110 = size_45[slice(None, 2, None)];  size_45 = None
    getitem_111 = getitem_110[0]
    getitem_112 = getitem_110[1];  getitem_110 = None
    size_46 = encoder_dropout_1.size()
    getitem_113 = size_46[1];  size_46 = None
    decoder_block_7_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "7").layer, "1").EncDecAttention.q(mul_161);  mul_161 = None
    view_94 = decoder_block_7_layer_1_enc_dec_attention_q.view(getitem_111, -1, 6, 64);  decoder_block_7_layer_1_enc_dec_attention_q = None
    transpose_115 = view_94.transpose(1, 2);  view_94 = None
    decoder_block_7_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "7").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_95 = decoder_block_7_layer_1_enc_dec_attention_k.view(getitem_111, -1, 6, 64);  decoder_block_7_layer_1_enc_dec_attention_k = None
    transpose_116 = view_95.transpose(1, 2);  view_95 = None
    decoder_block_7_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "7").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_96 = decoder_block_7_layer_1_enc_dec_attention_v.view(getitem_111, -1, 6, 64);  decoder_block_7_layer_1_enc_dec_attention_v = None
    transpose_117 = view_96.transpose(1, 2);  view_96 = None
    transpose_118 = transpose_116.transpose(3, 2)
    matmul_46 = torch.matmul(transpose_115, transpose_118);  transpose_115 = transpose_118 = None
    add_140 = matmul_46 + add_69;  matmul_46 = add_69 = None
    float_26 = add_140.float()
    softmax_23 = torch.nn.functional.softmax(float_26, dim = -1, _stacklevel = 3, dtype = None);  float_26 = None
    type_as_23 = softmax_23.type_as(add_140);  softmax_23 = add_140 = None
    dropout_23 = torch.nn.functional.dropout(type_as_23, p = 0.1, training = False, inplace = False);  type_as_23 = None
    matmul_47 = torch.matmul(dropout_23, transpose_117);  dropout_23 = None
    transpose_119 = matmul_47.transpose(1, 2);  matmul_47 = None
    contiguous_23 = transpose_119.contiguous();  transpose_119 = None
    view_97 = contiguous_23.view(getitem_111, -1, 384);  contiguous_23 = getitem_111 = None
    decoder_block_7_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "7").layer, "1").EncDecAttention.o(view_97);  view_97 = None
    decoder_block_7_layer_1_dropout = getattr(getattr(self.decoder.block, "7").layer, "1").dropout(decoder_block_7_layer_1_enc_dec_attention_o);  decoder_block_7_layer_1_enc_dec_attention_o = None
    add_141 = add_138 + decoder_block_7_layer_1_dropout;  add_138 = decoder_block_7_layer_1_dropout = None
    getattr_128 = add_141.dtype
    eq_87 = getattr_128 == torch.float16;  getattr_128 = None
    to_87 = add_141.to(torch.float32)
    pow_56 = to_87.pow(2);  to_87 = None
    mean_40 = pow_56.mean(-1, keepdim = True);  pow_56 = None
    add_142 = mean_40 + 1e-06;  mean_40 = None
    rsqrt_40 = torch.rsqrt(add_142);  add_142 = None
    mul_162 = add_141 * rsqrt_40;  rsqrt_40 = None
    decoder_block_7_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "7").layer, "2").layer_norm.weight
    getattr_129 = decoder_block_7_layer_2_layer_norm_weight.dtype
    eq_88 = getattr_129 == torch.float16;  getattr_129 = None
    getattr_130 = decoder_block_7_layer_2_layer_norm_weight.dtype
    to_88 = mul_162.to(getattr_130);  mul_162 = getattr_130 = None
    mul_163 = decoder_block_7_layer_2_layer_norm_weight * to_88;  decoder_block_7_layer_2_layer_norm_weight = to_88 = None
    decoder_block_7_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "7").layer, "2").DenseReluDense.wo.weight
    linear1_15 = getattr(getattr(self.decoder.block, "7").layer, "2").DenseReluDense.wi_0
    linear_layer_triton_wrapper_15 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_163, linear1_15, activation = 'fast_gelu');  linear1_15 = None
    linear2_15 = getattr(getattr(self.decoder.block, "7").layer, "2").DenseReluDense.wi_1(mul_163);  mul_163 = None
    mul_186 = linear_layer_triton_wrapper_15 * linear2_15;  linear_layer_triton_wrapper_15 = linear2_15 = None
    dropout_39 = getattr(getattr(self.decoder.block, "7").layer, "2").DenseReluDense.dropout(mul_186);  mul_186 = None
    linear3_15 = getattr(getattr(self.decoder.block, "7").layer, "2").DenseReluDense.wo(dropout_39);  dropout_39 = None
    decoder_block_7_layer_2_dropout = getattr(getattr(self.decoder.block, "7").layer, "2").dropout(linear3_15);  linear3_15 = None
    add_145 = add_141 + decoder_block_7_layer_2_dropout;  add_141 = decoder_block_7_layer_2_dropout = None
    getattr_131 = add_145.dtype
    eq_89 = getattr_131 == torch.float16;  getattr_131 = None
    to_89 = add_145.to(torch.float32)
    pow_58 = to_89.pow(2);  to_89 = None
    mean_41 = pow_58.mean(-1, keepdim = True);  pow_58 = None
    add_146 = mean_41 + 1e-06;  mean_41 = None
    rsqrt_41 = torch.rsqrt(add_146);  add_146 = None
    mul_169 = add_145 * rsqrt_41;  add_145 = rsqrt_41 = None
    decoder_final_layer_norm_weight = self.decoder.final_layer_norm.weight
    getattr_132 = decoder_final_layer_norm_weight.dtype
    eq_90 = getattr_132 == torch.float16;  getattr_132 = None
    getattr_133 = decoder_final_layer_norm_weight.dtype
    to_90 = mul_169.to(getattr_133);  mul_169 = getattr_133 = None
    mul_170 = decoder_final_layer_norm_weight * to_90;  decoder_final_layer_norm_weight = to_90 = None
    decoder_dropout_1 = self.decoder.dropout(mul_170);  mul_170 = None
    lm_head = self.lm_head(decoder_dropout_1);  decoder_dropout_1 = None
    getattr_134 = lm_head.device
    to_91 = labels.to(getattr_134);  labels = getattr_134 = None
    size_47 = lm_head.size(-1)
    view_98 = lm_head.view(-1, size_47);  size_47 = None
    view_99 = to_91.view(-1);  to_91 = None
    crossentropyloss_0 = self.crossentropyloss_0(view_98, view_99);  view_98 = view_99 = None
    return {'loss': crossentropyloss_0, 'logits': lm_head, 'past_key_values': ((transpose_41, transpose_42, transpose_46, transpose_47), (transpose_51, transpose_52, transpose_56, transpose_57), (transpose_61, transpose_62, transpose_66, transpose_67), (transpose_71, transpose_72, transpose_76, transpose_77), (transpose_81, transpose_82, transpose_86, transpose_87), (transpose_91, transpose_92, transpose_96, transpose_97), (transpose_101, transpose_102, transpose_106, transpose_107), (transpose_111, transpose_112, transpose_116, transpose_117)), 'encoder_last_hidden_state': encoder_dropout_1}
    
