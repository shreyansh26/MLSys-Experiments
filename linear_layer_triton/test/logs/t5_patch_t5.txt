[2024-01-06 07:01:46,509] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)



def forward(self, input_ids : torch.Tensor, labels : torch.Tensor):
    size = input_ids.size()
    getitem = size[-1]
    view = input_ids.view(-1, getitem);  input_ids = getitem = None
    shared = self.shared(view);  view = None
    getitem_1 = size[0]
    getitem_2 = size[1];  size = None
    getattr_1 = shared.device
    ones = torch.ones(getitem_1, getitem_2, device = getattr_1);  getitem_1 = getitem_2 = getattr_1 = None
    dim = ones.dim()
    eq = dim == 2;  dim = None
    dim_1 = ones.dim()
    eq_1 = dim_1 == 3;  dim_1 = None
    dim_2 = ones.dim()
    eq_2 = dim_2 == 2;  dim_2 = None
    getitem_3 = ones[(slice(None, None, None), None, None, slice(None, None, None))];  ones = None
    to = getitem_3.to(dtype = torch.float16);  getitem_3 = None
    sub = 1.0 - to;  to = None
    mul = sub * -65504.0;  sub = None
    encoder_dropout = self.encoder.dropout(shared);  shared = None
    to_1 = encoder_dropout.to(torch.float32)
    pow_1 = to_1.pow(2);  to_1 = None
    mean = pow_1.mean(-1, keepdim = True);  pow_1 = None
    add = mean + 1e-06;  mean = None
    rsqrt = torch.rsqrt(add);  add = None
    mul_1 = encoder_dropout * rsqrt;  rsqrt = None
    encoder_block_0_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "0").layer, "0").layer_norm.weight
    getattr_2 = encoder_block_0_layer_0_layer_norm_weight.dtype
    eq_3 = getattr_2 == torch.float16;  getattr_2 = None
    getattr_3 = encoder_block_0_layer_0_layer_norm_weight.dtype
    to_2 = mul_1.to(getattr_3);  mul_1 = getattr_3 = None
    mul_2 = encoder_block_0_layer_0_layer_norm_weight * to_2;  encoder_block_0_layer_0_layer_norm_weight = to_2 = None
    size_1 = mul_2.size()
    getitem_4 = size_1[slice(None, 2, None)];  size_1 = None
    getitem_5 = getitem_4[0]
    getitem_6 = getitem_4[1];  getitem_4 = None
    encoder_block_0_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.q(mul_2)
    view_1 = encoder_block_0_layer_0_self_attention_q.view(getitem_5, -1, 8, 64);  encoder_block_0_layer_0_self_attention_q = None
    transpose = view_1.transpose(1, 2);  view_1 = None
    encoder_block_0_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.k(mul_2)
    view_2 = encoder_block_0_layer_0_self_attention_k.view(getitem_5, -1, 8, 64);  encoder_block_0_layer_0_self_attention_k = None
    transpose_1 = view_2.transpose(1, 2);  view_2 = None
    encoder_block_0_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.v(mul_2);  mul_2 = None
    view_3 = encoder_block_0_layer_0_self_attention_v.view(getitem_5, -1, 8, 64);  encoder_block_0_layer_0_self_attention_v = None
    transpose_2 = view_3.transpose(1, 2);  view_3 = None
    transpose_3 = transpose_1.transpose(3, 2);  transpose_1 = None
    matmul = torch.matmul(transpose, transpose_3);  transpose = transpose_3 = None
    getattr_4 = matmul.device
    arange = torch.arange(getitem_6, dtype = torch.int64, device = getattr_4)
    getitem_7 = arange[(slice(None, None, None), None)];  arange = None
    arange_1 = torch.arange(getitem_6, dtype = torch.int64, device = getattr_4);  getitem_6 = getattr_4 = None
    getitem_8 = arange_1[(None, slice(None, None, None))];  arange_1 = None
    sub_1 = getitem_8 - getitem_7;  getitem_8 = getitem_7 = None
    gt = sub_1 > 0
    to_3 = gt.to(torch.int64);  gt = None
    mul_3 = to_3 * 16;  to_3 = None
    add_1 = 0 + mul_3;  mul_3 = None
    abs_1 = torch.abs(sub_1);  sub_1 = None
    lt = abs_1 < 8
    float_1 = abs_1.float()
    truediv = float_1 / 8;  float_1 = None
    log = torch.log(truediv);  truediv = None
    truediv_1 = log / 2.772588722239781;  log = None
    mul_4 = truediv_1 * 8;  truediv_1 = None
    to_4 = mul_4.to(torch.int64);  mul_4 = None
    add_2 = 8 + to_4;  to_4 = None
    full_like = torch.full_like(add_2, 15)
    min_1 = torch.min(add_2, full_like);  add_2 = full_like = None
    where = torch.where(lt, abs_1, min_1);  lt = abs_1 = min_1 = None
    add_3 = add_1 + where;  add_1 = where = None
    encoder_block_0_layer_0_self_attention_relative_attention_bias = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.relative_attention_bias(add_3);  add_3 = None
    permute = encoder_block_0_layer_0_self_attention_relative_attention_bias.permute([2, 0, 1]);  encoder_block_0_layer_0_self_attention_relative_attention_bias = None
    unsqueeze = permute.unsqueeze(0);  permute = None
    add_4 = unsqueeze + mul;  unsqueeze = mul = None
    add_5 = matmul + add_4;  matmul = None
    float_2 = add_5.float()
    softmax = torch.nn.functional.softmax(float_2, dim = -1, _stacklevel = 3, dtype = None);  float_2 = None
    type_as = softmax.type_as(add_5);  softmax = add_5 = None
    dropout = torch.nn.functional.dropout(type_as, p = 0.1, training = False, inplace = False);  type_as = None
    matmul_1 = torch.matmul(dropout, transpose_2);  dropout = transpose_2 = None
    transpose_4 = matmul_1.transpose(1, 2);  matmul_1 = None
    contiguous = transpose_4.contiguous();  transpose_4 = None
    view_4 = contiguous.view(getitem_5, -1, 512);  contiguous = getitem_5 = None
    encoder_block_0_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.o(view_4);  view_4 = None
    encoder_block_0_layer_0_dropout = getattr(getattr(self.encoder.block, "0").layer, "0").dropout(encoder_block_0_layer_0_self_attention_o);  encoder_block_0_layer_0_self_attention_o = None
    add_6 = encoder_dropout + encoder_block_0_layer_0_dropout;  encoder_dropout = encoder_block_0_layer_0_dropout = None
    getattr_5 = add_6.dtype
    eq_4 = getattr_5 == torch.float16;  getattr_5 = None
    to_5 = add_6.to(torch.float32)
    pow_2 = to_5.pow(2);  to_5 = None
    mean_1 = pow_2.mean(-1, keepdim = True);  pow_2 = None
    add_7 = mean_1 + 1e-06;  mean_1 = None
    rsqrt_1 = torch.rsqrt(add_7);  add_7 = None
    mul_5 = add_6 * rsqrt_1;  rsqrt_1 = None
    encoder_block_0_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "0").layer, "1").layer_norm.weight
    getattr_6 = encoder_block_0_layer_1_layer_norm_weight.dtype
    eq_5 = getattr_6 == torch.float16;  getattr_6 = None
    getattr_7 = encoder_block_0_layer_1_layer_norm_weight.dtype
    to_6 = mul_5.to(getattr_7);  mul_5 = getattr_7 = None
    mul_6 = encoder_block_0_layer_1_layer_norm_weight * to_6;  encoder_block_0_layer_1_layer_norm_weight = to_6 = None
    encoder_block_0_layer_1_dense_relu_dense_wi = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.wi(mul_6);  mul_6 = None
    encoder_block_0_layer_1_dense_relu_dense_act = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.act(encoder_block_0_layer_1_dense_relu_dense_wi);  encoder_block_0_layer_1_dense_relu_dense_wi = None
    encoder_block_0_layer_1_dense_relu_dense_dropout = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.dropout(encoder_block_0_layer_1_dense_relu_dense_act);  encoder_block_0_layer_1_dense_relu_dense_act = None
    encoder_block_0_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.wo.weight
    encoder_block_0_layer_1_dense_relu_dense_wo = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.wo(encoder_block_0_layer_1_dense_relu_dense_dropout);  encoder_block_0_layer_1_dense_relu_dense_dropout = None
    encoder_block_0_layer_1_dropout = getattr(getattr(self.encoder.block, "0").layer, "1").dropout(encoder_block_0_layer_1_dense_relu_dense_wo);  encoder_block_0_layer_1_dense_relu_dense_wo = None
    add_8 = add_6 + encoder_block_0_layer_1_dropout;  add_6 = encoder_block_0_layer_1_dropout = None
    getattr_8 = add_8.dtype
    eq_6 = getattr_8 == torch.float16;  getattr_8 = None
    to_7 = add_8.to(torch.float32)
    pow_3 = to_7.pow(2);  to_7 = None
    mean_2 = pow_3.mean(-1, keepdim = True);  pow_3 = None
    add_9 = mean_2 + 1e-06;  mean_2 = None
    rsqrt_2 = torch.rsqrt(add_9);  add_9 = None
    mul_7 = add_8 * rsqrt_2;  rsqrt_2 = None
    encoder_block_1_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "1").layer, "0").layer_norm.weight
    getattr_9 = encoder_block_1_layer_0_layer_norm_weight.dtype
    eq_7 = getattr_9 == torch.float16;  getattr_9 = None
    getattr_10 = encoder_block_1_layer_0_layer_norm_weight.dtype
    to_8 = mul_7.to(getattr_10);  mul_7 = getattr_10 = None
    mul_8 = encoder_block_1_layer_0_layer_norm_weight * to_8;  encoder_block_1_layer_0_layer_norm_weight = to_8 = None
    size_2 = mul_8.size()
    getitem_9 = size_2[slice(None, 2, None)];  size_2 = None
    getitem_10 = getitem_9[0]
    getitem_11 = getitem_9[1];  getitem_9 = None
    encoder_block_1_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.q(mul_8)
    view_5 = encoder_block_1_layer_0_self_attention_q.view(getitem_10, -1, 8, 64);  encoder_block_1_layer_0_self_attention_q = None
    transpose_5 = view_5.transpose(1, 2);  view_5 = None
    encoder_block_1_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.k(mul_8)
    view_6 = encoder_block_1_layer_0_self_attention_k.view(getitem_10, -1, 8, 64);  encoder_block_1_layer_0_self_attention_k = None
    transpose_6 = view_6.transpose(1, 2);  view_6 = None
    encoder_block_1_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.v(mul_8);  mul_8 = None
    view_7 = encoder_block_1_layer_0_self_attention_v.view(getitem_10, -1, 8, 64);  encoder_block_1_layer_0_self_attention_v = None
    transpose_7 = view_7.transpose(1, 2);  view_7 = None
    transpose_8 = transpose_6.transpose(3, 2);  transpose_6 = None
    matmul_2 = torch.matmul(transpose_5, transpose_8);  transpose_5 = transpose_8 = None
    add_10 = matmul_2 + add_4;  matmul_2 = None
    float_3 = add_10.float()
    softmax_1 = torch.nn.functional.softmax(float_3, dim = -1, _stacklevel = 3, dtype = None);  float_3 = None
    type_as_1 = softmax_1.type_as(add_10);  softmax_1 = add_10 = None
    dropout_1 = torch.nn.functional.dropout(type_as_1, p = 0.1, training = False, inplace = False);  type_as_1 = None
    matmul_3 = torch.matmul(dropout_1, transpose_7);  dropout_1 = transpose_7 = None
    transpose_9 = matmul_3.transpose(1, 2);  matmul_3 = None
    contiguous_1 = transpose_9.contiguous();  transpose_9 = None
    view_8 = contiguous_1.view(getitem_10, -1, 512);  contiguous_1 = getitem_10 = None
    encoder_block_1_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.o(view_8);  view_8 = None
    encoder_block_1_layer_0_dropout = getattr(getattr(self.encoder.block, "1").layer, "0").dropout(encoder_block_1_layer_0_self_attention_o);  encoder_block_1_layer_0_self_attention_o = None
    add_11 = add_8 + encoder_block_1_layer_0_dropout;  add_8 = encoder_block_1_layer_0_dropout = None
    getattr_11 = add_11.dtype
    eq_8 = getattr_11 == torch.float16;  getattr_11 = None
    to_9 = add_11.to(torch.float32)
    pow_4 = to_9.pow(2);  to_9 = None
    mean_3 = pow_4.mean(-1, keepdim = True);  pow_4 = None
    add_12 = mean_3 + 1e-06;  mean_3 = None
    rsqrt_3 = torch.rsqrt(add_12);  add_12 = None
    mul_9 = add_11 * rsqrt_3;  rsqrt_3 = None
    encoder_block_1_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "1").layer, "1").layer_norm.weight
    getattr_12 = encoder_block_1_layer_1_layer_norm_weight.dtype
    eq_9 = getattr_12 == torch.float16;  getattr_12 = None
    getattr_13 = encoder_block_1_layer_1_layer_norm_weight.dtype
    to_10 = mul_9.to(getattr_13);  mul_9 = getattr_13 = None
    mul_10 = encoder_block_1_layer_1_layer_norm_weight * to_10;  encoder_block_1_layer_1_layer_norm_weight = to_10 = None
    encoder_block_1_layer_1_dense_relu_dense_wi = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.wi(mul_10);  mul_10 = None
    encoder_block_1_layer_1_dense_relu_dense_act = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.act(encoder_block_1_layer_1_dense_relu_dense_wi);  encoder_block_1_layer_1_dense_relu_dense_wi = None
    encoder_block_1_layer_1_dense_relu_dense_dropout = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.dropout(encoder_block_1_layer_1_dense_relu_dense_act);  encoder_block_1_layer_1_dense_relu_dense_act = None
    encoder_block_1_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.wo.weight
    encoder_block_1_layer_1_dense_relu_dense_wo = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.wo(encoder_block_1_layer_1_dense_relu_dense_dropout);  encoder_block_1_layer_1_dense_relu_dense_dropout = None
    encoder_block_1_layer_1_dropout = getattr(getattr(self.encoder.block, "1").layer, "1").dropout(encoder_block_1_layer_1_dense_relu_dense_wo);  encoder_block_1_layer_1_dense_relu_dense_wo = None
    add_13 = add_11 + encoder_block_1_layer_1_dropout;  add_11 = encoder_block_1_layer_1_dropout = None
    getattr_14 = add_13.dtype
    eq_10 = getattr_14 == torch.float16;  getattr_14 = None
    to_11 = add_13.to(torch.float32)
    pow_5 = to_11.pow(2);  to_11 = None
    mean_4 = pow_5.mean(-1, keepdim = True);  pow_5 = None
    add_14 = mean_4 + 1e-06;  mean_4 = None
    rsqrt_4 = torch.rsqrt(add_14);  add_14 = None
    mul_11 = add_13 * rsqrt_4;  rsqrt_4 = None
    encoder_block_2_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "2").layer, "0").layer_norm.weight
    getattr_15 = encoder_block_2_layer_0_layer_norm_weight.dtype
    eq_11 = getattr_15 == torch.float16;  getattr_15 = None
    getattr_16 = encoder_block_2_layer_0_layer_norm_weight.dtype
    to_12 = mul_11.to(getattr_16);  mul_11 = getattr_16 = None
    mul_12 = encoder_block_2_layer_0_layer_norm_weight * to_12;  encoder_block_2_layer_0_layer_norm_weight = to_12 = None
    size_3 = mul_12.size()
    getitem_12 = size_3[slice(None, 2, None)];  size_3 = None
    getitem_13 = getitem_12[0]
    getitem_14 = getitem_12[1];  getitem_12 = None
    encoder_block_2_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.q(mul_12)
    view_9 = encoder_block_2_layer_0_self_attention_q.view(getitem_13, -1, 8, 64);  encoder_block_2_layer_0_self_attention_q = None
    transpose_10 = view_9.transpose(1, 2);  view_9 = None
    encoder_block_2_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.k(mul_12)
    view_10 = encoder_block_2_layer_0_self_attention_k.view(getitem_13, -1, 8, 64);  encoder_block_2_layer_0_self_attention_k = None
    transpose_11 = view_10.transpose(1, 2);  view_10 = None
    encoder_block_2_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.v(mul_12);  mul_12 = None
    view_11 = encoder_block_2_layer_0_self_attention_v.view(getitem_13, -1, 8, 64);  encoder_block_2_layer_0_self_attention_v = None
    transpose_12 = view_11.transpose(1, 2);  view_11 = None
    transpose_13 = transpose_11.transpose(3, 2);  transpose_11 = None
    matmul_4 = torch.matmul(transpose_10, transpose_13);  transpose_10 = transpose_13 = None
    add_15 = matmul_4 + add_4;  matmul_4 = None
    float_4 = add_15.float()
    softmax_2 = torch.nn.functional.softmax(float_4, dim = -1, _stacklevel = 3, dtype = None);  float_4 = None
    type_as_2 = softmax_2.type_as(add_15);  softmax_2 = add_15 = None
    dropout_2 = torch.nn.functional.dropout(type_as_2, p = 0.1, training = False, inplace = False);  type_as_2 = None
    matmul_5 = torch.matmul(dropout_2, transpose_12);  dropout_2 = transpose_12 = None
    transpose_14 = matmul_5.transpose(1, 2);  matmul_5 = None
    contiguous_2 = transpose_14.contiguous();  transpose_14 = None
    view_12 = contiguous_2.view(getitem_13, -1, 512);  contiguous_2 = getitem_13 = None
    encoder_block_2_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.o(view_12);  view_12 = None
    encoder_block_2_layer_0_dropout = getattr(getattr(self.encoder.block, "2").layer, "0").dropout(encoder_block_2_layer_0_self_attention_o);  encoder_block_2_layer_0_self_attention_o = None
    add_16 = add_13 + encoder_block_2_layer_0_dropout;  add_13 = encoder_block_2_layer_0_dropout = None
    getattr_17 = add_16.dtype
    eq_12 = getattr_17 == torch.float16;  getattr_17 = None
    to_13 = add_16.to(torch.float32)
    pow_6 = to_13.pow(2);  to_13 = None
    mean_5 = pow_6.mean(-1, keepdim = True);  pow_6 = None
    add_17 = mean_5 + 1e-06;  mean_5 = None
    rsqrt_5 = torch.rsqrt(add_17);  add_17 = None
    mul_13 = add_16 * rsqrt_5;  rsqrt_5 = None
    encoder_block_2_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "2").layer, "1").layer_norm.weight
    getattr_18 = encoder_block_2_layer_1_layer_norm_weight.dtype
    eq_13 = getattr_18 == torch.float16;  getattr_18 = None
    getattr_19 = encoder_block_2_layer_1_layer_norm_weight.dtype
    to_14 = mul_13.to(getattr_19);  mul_13 = getattr_19 = None
    mul_14 = encoder_block_2_layer_1_layer_norm_weight * to_14;  encoder_block_2_layer_1_layer_norm_weight = to_14 = None
    encoder_block_2_layer_1_dense_relu_dense_wi = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.wi(mul_14);  mul_14 = None
    encoder_block_2_layer_1_dense_relu_dense_act = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.act(encoder_block_2_layer_1_dense_relu_dense_wi);  encoder_block_2_layer_1_dense_relu_dense_wi = None
    encoder_block_2_layer_1_dense_relu_dense_dropout = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.dropout(encoder_block_2_layer_1_dense_relu_dense_act);  encoder_block_2_layer_1_dense_relu_dense_act = None
    encoder_block_2_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.wo.weight
    encoder_block_2_layer_1_dense_relu_dense_wo = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.wo(encoder_block_2_layer_1_dense_relu_dense_dropout);  encoder_block_2_layer_1_dense_relu_dense_dropout = None
    encoder_block_2_layer_1_dropout = getattr(getattr(self.encoder.block, "2").layer, "1").dropout(encoder_block_2_layer_1_dense_relu_dense_wo);  encoder_block_2_layer_1_dense_relu_dense_wo = None
    add_18 = add_16 + encoder_block_2_layer_1_dropout;  add_16 = encoder_block_2_layer_1_dropout = None
    getattr_20 = add_18.dtype
    eq_14 = getattr_20 == torch.float16;  getattr_20 = None
    to_15 = add_18.to(torch.float32)
    pow_7 = to_15.pow(2);  to_15 = None
    mean_6 = pow_7.mean(-1, keepdim = True);  pow_7 = None
    add_19 = mean_6 + 1e-06;  mean_6 = None
    rsqrt_6 = torch.rsqrt(add_19);  add_19 = None
    mul_15 = add_18 * rsqrt_6;  rsqrt_6 = None
    encoder_block_3_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "3").layer, "0").layer_norm.weight
    getattr_21 = encoder_block_3_layer_0_layer_norm_weight.dtype
    eq_15 = getattr_21 == torch.float16;  getattr_21 = None
    getattr_22 = encoder_block_3_layer_0_layer_norm_weight.dtype
    to_16 = mul_15.to(getattr_22);  mul_15 = getattr_22 = None
    mul_16 = encoder_block_3_layer_0_layer_norm_weight * to_16;  encoder_block_3_layer_0_layer_norm_weight = to_16 = None
    size_4 = mul_16.size()
    getitem_15 = size_4[slice(None, 2, None)];  size_4 = None
    getitem_16 = getitem_15[0]
    getitem_17 = getitem_15[1];  getitem_15 = None
    encoder_block_3_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.q(mul_16)
    view_13 = encoder_block_3_layer_0_self_attention_q.view(getitem_16, -1, 8, 64);  encoder_block_3_layer_0_self_attention_q = None
    transpose_15 = view_13.transpose(1, 2);  view_13 = None
    encoder_block_3_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.k(mul_16)
    view_14 = encoder_block_3_layer_0_self_attention_k.view(getitem_16, -1, 8, 64);  encoder_block_3_layer_0_self_attention_k = None
    transpose_16 = view_14.transpose(1, 2);  view_14 = None
    encoder_block_3_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.v(mul_16);  mul_16 = None
    view_15 = encoder_block_3_layer_0_self_attention_v.view(getitem_16, -1, 8, 64);  encoder_block_3_layer_0_self_attention_v = None
    transpose_17 = view_15.transpose(1, 2);  view_15 = None
    transpose_18 = transpose_16.transpose(3, 2);  transpose_16 = None
    matmul_6 = torch.matmul(transpose_15, transpose_18);  transpose_15 = transpose_18 = None
    add_20 = matmul_6 + add_4;  matmul_6 = None
    float_5 = add_20.float()
    softmax_3 = torch.nn.functional.softmax(float_5, dim = -1, _stacklevel = 3, dtype = None);  float_5 = None
    type_as_3 = softmax_3.type_as(add_20);  softmax_3 = add_20 = None
    dropout_3 = torch.nn.functional.dropout(type_as_3, p = 0.1, training = False, inplace = False);  type_as_3 = None
    matmul_7 = torch.matmul(dropout_3, transpose_17);  dropout_3 = transpose_17 = None
    transpose_19 = matmul_7.transpose(1, 2);  matmul_7 = None
    contiguous_3 = transpose_19.contiguous();  transpose_19 = None
    view_16 = contiguous_3.view(getitem_16, -1, 512);  contiguous_3 = getitem_16 = None
    encoder_block_3_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.o(view_16);  view_16 = None
    encoder_block_3_layer_0_dropout = getattr(getattr(self.encoder.block, "3").layer, "0").dropout(encoder_block_3_layer_0_self_attention_o);  encoder_block_3_layer_0_self_attention_o = None
    add_21 = add_18 + encoder_block_3_layer_0_dropout;  add_18 = encoder_block_3_layer_0_dropout = None
    getattr_23 = add_21.dtype
    eq_16 = getattr_23 == torch.float16;  getattr_23 = None
    to_17 = add_21.to(torch.float32)
    pow_8 = to_17.pow(2);  to_17 = None
    mean_7 = pow_8.mean(-1, keepdim = True);  pow_8 = None
    add_22 = mean_7 + 1e-06;  mean_7 = None
    rsqrt_7 = torch.rsqrt(add_22);  add_22 = None
    mul_17 = add_21 * rsqrt_7;  rsqrt_7 = None
    encoder_block_3_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "3").layer, "1").layer_norm.weight
    getattr_24 = encoder_block_3_layer_1_layer_norm_weight.dtype
    eq_17 = getattr_24 == torch.float16;  getattr_24 = None
    getattr_25 = encoder_block_3_layer_1_layer_norm_weight.dtype
    to_18 = mul_17.to(getattr_25);  mul_17 = getattr_25 = None
    mul_18 = encoder_block_3_layer_1_layer_norm_weight * to_18;  encoder_block_3_layer_1_layer_norm_weight = to_18 = None
    encoder_block_3_layer_1_dense_relu_dense_wi = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.wi(mul_18);  mul_18 = None
    encoder_block_3_layer_1_dense_relu_dense_act = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.act(encoder_block_3_layer_1_dense_relu_dense_wi);  encoder_block_3_layer_1_dense_relu_dense_wi = None
    encoder_block_3_layer_1_dense_relu_dense_dropout = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.dropout(encoder_block_3_layer_1_dense_relu_dense_act);  encoder_block_3_layer_1_dense_relu_dense_act = None
    encoder_block_3_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.wo.weight
    encoder_block_3_layer_1_dense_relu_dense_wo = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.wo(encoder_block_3_layer_1_dense_relu_dense_dropout);  encoder_block_3_layer_1_dense_relu_dense_dropout = None
    encoder_block_3_layer_1_dropout = getattr(getattr(self.encoder.block, "3").layer, "1").dropout(encoder_block_3_layer_1_dense_relu_dense_wo);  encoder_block_3_layer_1_dense_relu_dense_wo = None
    add_23 = add_21 + encoder_block_3_layer_1_dropout;  add_21 = encoder_block_3_layer_1_dropout = None
    getattr_26 = add_23.dtype
    eq_18 = getattr_26 == torch.float16;  getattr_26 = None
    to_19 = add_23.to(torch.float32)
    pow_9 = to_19.pow(2);  to_19 = None
    mean_8 = pow_9.mean(-1, keepdim = True);  pow_9 = None
    add_24 = mean_8 + 1e-06;  mean_8 = None
    rsqrt_8 = torch.rsqrt(add_24);  add_24 = None
    mul_19 = add_23 * rsqrt_8;  rsqrt_8 = None
    encoder_block_4_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "4").layer, "0").layer_norm.weight
    getattr_27 = encoder_block_4_layer_0_layer_norm_weight.dtype
    eq_19 = getattr_27 == torch.float16;  getattr_27 = None
    getattr_28 = encoder_block_4_layer_0_layer_norm_weight.dtype
    to_20 = mul_19.to(getattr_28);  mul_19 = getattr_28 = None
    mul_20 = encoder_block_4_layer_0_layer_norm_weight * to_20;  encoder_block_4_layer_0_layer_norm_weight = to_20 = None
    size_5 = mul_20.size()
    getitem_18 = size_5[slice(None, 2, None)];  size_5 = None
    getitem_19 = getitem_18[0]
    getitem_20 = getitem_18[1];  getitem_18 = None
    encoder_block_4_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.q(mul_20)
    view_17 = encoder_block_4_layer_0_self_attention_q.view(getitem_19, -1, 8, 64);  encoder_block_4_layer_0_self_attention_q = None
    transpose_20 = view_17.transpose(1, 2);  view_17 = None
    encoder_block_4_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.k(mul_20)
    view_18 = encoder_block_4_layer_0_self_attention_k.view(getitem_19, -1, 8, 64);  encoder_block_4_layer_0_self_attention_k = None
    transpose_21 = view_18.transpose(1, 2);  view_18 = None
    encoder_block_4_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.v(mul_20);  mul_20 = None
    view_19 = encoder_block_4_layer_0_self_attention_v.view(getitem_19, -1, 8, 64);  encoder_block_4_layer_0_self_attention_v = None
    transpose_22 = view_19.transpose(1, 2);  view_19 = None
    transpose_23 = transpose_21.transpose(3, 2);  transpose_21 = None
    matmul_8 = torch.matmul(transpose_20, transpose_23);  transpose_20 = transpose_23 = None
    add_25 = matmul_8 + add_4;  matmul_8 = None
    float_6 = add_25.float()
    softmax_4 = torch.nn.functional.softmax(float_6, dim = -1, _stacklevel = 3, dtype = None);  float_6 = None
    type_as_4 = softmax_4.type_as(add_25);  softmax_4 = add_25 = None
    dropout_4 = torch.nn.functional.dropout(type_as_4, p = 0.1, training = False, inplace = False);  type_as_4 = None
    matmul_9 = torch.matmul(dropout_4, transpose_22);  dropout_4 = transpose_22 = None
    transpose_24 = matmul_9.transpose(1, 2);  matmul_9 = None
    contiguous_4 = transpose_24.contiguous();  transpose_24 = None
    view_20 = contiguous_4.view(getitem_19, -1, 512);  contiguous_4 = getitem_19 = None
    encoder_block_4_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.o(view_20);  view_20 = None
    encoder_block_4_layer_0_dropout = getattr(getattr(self.encoder.block, "4").layer, "0").dropout(encoder_block_4_layer_0_self_attention_o);  encoder_block_4_layer_0_self_attention_o = None
    add_26 = add_23 + encoder_block_4_layer_0_dropout;  add_23 = encoder_block_4_layer_0_dropout = None
    getattr_29 = add_26.dtype
    eq_20 = getattr_29 == torch.float16;  getattr_29 = None
    to_21 = add_26.to(torch.float32)
    pow_10 = to_21.pow(2);  to_21 = None
    mean_9 = pow_10.mean(-1, keepdim = True);  pow_10 = None
    add_27 = mean_9 + 1e-06;  mean_9 = None
    rsqrt_9 = torch.rsqrt(add_27);  add_27 = None
    mul_21 = add_26 * rsqrt_9;  rsqrt_9 = None
    encoder_block_4_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "4").layer, "1").layer_norm.weight
    getattr_30 = encoder_block_4_layer_1_layer_norm_weight.dtype
    eq_21 = getattr_30 == torch.float16;  getattr_30 = None
    getattr_31 = encoder_block_4_layer_1_layer_norm_weight.dtype
    to_22 = mul_21.to(getattr_31);  mul_21 = getattr_31 = None
    mul_22 = encoder_block_4_layer_1_layer_norm_weight * to_22;  encoder_block_4_layer_1_layer_norm_weight = to_22 = None
    encoder_block_4_layer_1_dense_relu_dense_wi = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.wi(mul_22);  mul_22 = None
    encoder_block_4_layer_1_dense_relu_dense_act = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.act(encoder_block_4_layer_1_dense_relu_dense_wi);  encoder_block_4_layer_1_dense_relu_dense_wi = None
    encoder_block_4_layer_1_dense_relu_dense_dropout = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.dropout(encoder_block_4_layer_1_dense_relu_dense_act);  encoder_block_4_layer_1_dense_relu_dense_act = None
    encoder_block_4_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.wo.weight
    encoder_block_4_layer_1_dense_relu_dense_wo = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.wo(encoder_block_4_layer_1_dense_relu_dense_dropout);  encoder_block_4_layer_1_dense_relu_dense_dropout = None
    encoder_block_4_layer_1_dropout = getattr(getattr(self.encoder.block, "4").layer, "1").dropout(encoder_block_4_layer_1_dense_relu_dense_wo);  encoder_block_4_layer_1_dense_relu_dense_wo = None
    add_28 = add_26 + encoder_block_4_layer_1_dropout;  add_26 = encoder_block_4_layer_1_dropout = None
    getattr_32 = add_28.dtype
    eq_22 = getattr_32 == torch.float16;  getattr_32 = None
    to_23 = add_28.to(torch.float32)
    pow_11 = to_23.pow(2);  to_23 = None
    mean_10 = pow_11.mean(-1, keepdim = True);  pow_11 = None
    add_29 = mean_10 + 1e-06;  mean_10 = None
    rsqrt_10 = torch.rsqrt(add_29);  add_29 = None
    mul_23 = add_28 * rsqrt_10;  rsqrt_10 = None
    encoder_block_5_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "5").layer, "0").layer_norm.weight
    getattr_33 = encoder_block_5_layer_0_layer_norm_weight.dtype
    eq_23 = getattr_33 == torch.float16;  getattr_33 = None
    getattr_34 = encoder_block_5_layer_0_layer_norm_weight.dtype
    to_24 = mul_23.to(getattr_34);  mul_23 = getattr_34 = None
    mul_24 = encoder_block_5_layer_0_layer_norm_weight * to_24;  encoder_block_5_layer_0_layer_norm_weight = to_24 = None
    size_6 = mul_24.size()
    getitem_21 = size_6[slice(None, 2, None)];  size_6 = None
    getitem_22 = getitem_21[0]
    getitem_23 = getitem_21[1];  getitem_21 = None
    encoder_block_5_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.q(mul_24)
    view_21 = encoder_block_5_layer_0_self_attention_q.view(getitem_22, -1, 8, 64);  encoder_block_5_layer_0_self_attention_q = None
    transpose_25 = view_21.transpose(1, 2);  view_21 = None
    encoder_block_5_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.k(mul_24)
    view_22 = encoder_block_5_layer_0_self_attention_k.view(getitem_22, -1, 8, 64);  encoder_block_5_layer_0_self_attention_k = None
    transpose_26 = view_22.transpose(1, 2);  view_22 = None
    encoder_block_5_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.v(mul_24);  mul_24 = None
    view_23 = encoder_block_5_layer_0_self_attention_v.view(getitem_22, -1, 8, 64);  encoder_block_5_layer_0_self_attention_v = None
    transpose_27 = view_23.transpose(1, 2);  view_23 = None
    transpose_28 = transpose_26.transpose(3, 2);  transpose_26 = None
    matmul_10 = torch.matmul(transpose_25, transpose_28);  transpose_25 = transpose_28 = None
    add_30 = matmul_10 + add_4;  matmul_10 = add_4 = None
    float_7 = add_30.float()
    softmax_5 = torch.nn.functional.softmax(float_7, dim = -1, _stacklevel = 3, dtype = None);  float_7 = None
    type_as_5 = softmax_5.type_as(add_30);  softmax_5 = add_30 = None
    dropout_5 = torch.nn.functional.dropout(type_as_5, p = 0.1, training = False, inplace = False);  type_as_5 = None
    matmul_11 = torch.matmul(dropout_5, transpose_27);  dropout_5 = transpose_27 = None
    transpose_29 = matmul_11.transpose(1, 2);  matmul_11 = None
    contiguous_5 = transpose_29.contiguous();  transpose_29 = None
    view_24 = contiguous_5.view(getitem_22, -1, 512);  contiguous_5 = getitem_22 = None
    encoder_block_5_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.o(view_24);  view_24 = None
    encoder_block_5_layer_0_dropout = getattr(getattr(self.encoder.block, "5").layer, "0").dropout(encoder_block_5_layer_0_self_attention_o);  encoder_block_5_layer_0_self_attention_o = None
    add_31 = add_28 + encoder_block_5_layer_0_dropout;  add_28 = encoder_block_5_layer_0_dropout = None
    getattr_35 = add_31.dtype
    eq_24 = getattr_35 == torch.float16;  getattr_35 = None
    to_25 = add_31.to(torch.float32)
    pow_12 = to_25.pow(2);  to_25 = None
    mean_11 = pow_12.mean(-1, keepdim = True);  pow_12 = None
    add_32 = mean_11 + 1e-06;  mean_11 = None
    rsqrt_11 = torch.rsqrt(add_32);  add_32 = None
    mul_25 = add_31 * rsqrt_11;  rsqrt_11 = None
    encoder_block_5_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "5").layer, "1").layer_norm.weight
    getattr_36 = encoder_block_5_layer_1_layer_norm_weight.dtype
    eq_25 = getattr_36 == torch.float16;  getattr_36 = None
    getattr_37 = encoder_block_5_layer_1_layer_norm_weight.dtype
    to_26 = mul_25.to(getattr_37);  mul_25 = getattr_37 = None
    mul_26 = encoder_block_5_layer_1_layer_norm_weight * to_26;  encoder_block_5_layer_1_layer_norm_weight = to_26 = None
    encoder_block_5_layer_1_dense_relu_dense_wi = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.wi(mul_26);  mul_26 = None
    encoder_block_5_layer_1_dense_relu_dense_act = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.act(encoder_block_5_layer_1_dense_relu_dense_wi);  encoder_block_5_layer_1_dense_relu_dense_wi = None
    encoder_block_5_layer_1_dense_relu_dense_dropout = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.dropout(encoder_block_5_layer_1_dense_relu_dense_act);  encoder_block_5_layer_1_dense_relu_dense_act = None
    encoder_block_5_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.wo.weight
    encoder_block_5_layer_1_dense_relu_dense_wo = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.wo(encoder_block_5_layer_1_dense_relu_dense_dropout);  encoder_block_5_layer_1_dense_relu_dense_dropout = None
    encoder_block_5_layer_1_dropout = getattr(getattr(self.encoder.block, "5").layer, "1").dropout(encoder_block_5_layer_1_dense_relu_dense_wo);  encoder_block_5_layer_1_dense_relu_dense_wo = None
    add_33 = add_31 + encoder_block_5_layer_1_dropout;  add_31 = encoder_block_5_layer_1_dropout = None
    getattr_38 = add_33.dtype
    eq_26 = getattr_38 == torch.float16;  getattr_38 = None
    to_27 = add_33.to(torch.float32)
    pow_13 = to_27.pow(2);  to_27 = None
    mean_12 = pow_13.mean(-1, keepdim = True);  pow_13 = None
    add_34 = mean_12 + 1e-06;  mean_12 = None
    rsqrt_12 = torch.rsqrt(add_34);  add_34 = None
    mul_27 = add_33 * rsqrt_12;  add_33 = rsqrt_12 = None
    encoder_final_layer_norm_weight = self.encoder.final_layer_norm.weight
    getattr_39 = encoder_final_layer_norm_weight.dtype
    eq_27 = getattr_39 == torch.float16;  getattr_39 = None
    getattr_40 = encoder_final_layer_norm_weight.dtype
    to_28 = mul_27.to(getattr_40);  mul_27 = getattr_40 = None
    mul_28 = encoder_final_layer_norm_weight * to_28;  encoder_final_layer_norm_weight = to_28 = None
    encoder_dropout_1 = self.encoder.dropout(mul_28);  mul_28 = None
    size_7 = labels.size()
    getitem_24 = size_7[slice(None, -1, None)];  size_7 = None
    add_35 = getitem_24 + (1,);  getitem_24 = None
    full = torch.full(add_35, 0);  add_35 = None
    getitem_25 = labels[(Ellipsis, slice(None, -1, None))]
    cat = torch.cat([full, getitem_25], dim = -1);  full = getitem_25 = None
    eq_28 = cat == -100
    masked_fill_ = cat.masked_fill_(eq_28, 0);  eq_28 = None
    size_8 = cat.size()
    getitem_26 = size_8[-1]
    view_25 = cat.view(-1, getitem_26);  cat = getitem_26 = None
    shared_1 = self.shared(view_25);  view_25 = None
    getitem_27 = size_8[0]
    getitem_28 = size_8[1]
    getattr_41 = shared_1.device
    ones_1 = torch.ones(getitem_27, getitem_28, device = getattr_41);  getitem_28 = getattr_41 = None
    size_9 = encoder_dropout_1.size()
    getitem_29 = size_9[1];  size_9 = None
    getattr_42 = shared_1.device
    ones_2 = torch.ones(getitem_27, getitem_29, device = getattr_42, dtype = torch.int64);  getitem_27 = getitem_29 = getattr_42 = None
    dim_3 = ones_1.dim()
    eq_29 = dim_3 == 2;  dim_3 = None
    dim_4 = ones_1.dim()
    eq_30 = dim_4 == 3;  dim_4 = None
    dim_5 = ones_1.dim()
    eq_31 = dim_5 == 2;  dim_5 = None
    getitem_30 = size_8[0]
    getitem_31 = size_8[1];  size_8 = None
    getattr_43 = ones_1.device
    arange_2 = torch.arange(getitem_31, device = getattr_43);  getattr_43 = None
    getitem_32 = arange_2[(None, None, slice(None, None, None))]
    repeat = getitem_32.repeat(getitem_30, getitem_31, 1);  getitem_32 = getitem_30 = getitem_31 = None
    getitem_33 = arange_2[(None, slice(None, None, None), None)];  arange_2 = None
    le = repeat <= getitem_33;  repeat = getitem_33 = None
    getattr_44 = ones_1.dtype
    to_29 = le.to(getattr_44);  le = getattr_44 = None
    size_10 = to_29.size()
    getitem_34 = size_10[1];  size_10 = None
    size_11 = ones_1.size()
    getitem_35 = size_11[1];  size_11 = None
    lt_1 = getitem_34 < getitem_35;  getitem_34 = getitem_35 = None
    getitem_36 = to_29[(slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  to_29 = None
    getitem_37 = ones_1[(slice(None, None, None), None, None, slice(None, None, None))];  ones_1 = None
    mul_29 = getitem_36 * getitem_37;  getitem_36 = getitem_37 = None
    to_30 = mul_29.to(dtype = torch.float16);  mul_29 = None
    sub_2 = 1.0 - to_30;  to_30 = None
    mul_30 = sub_2 * -65504.0;  sub_2 = None
    size_12 = encoder_dropout_1.size()
    getitem_38 = size_12[0]
    getitem_39 = size_12[1]
    getitem_40 = size_12[2];  size_12 = None
    dim_6 = ones_2.dim()
    eq_32 = dim_6 == 3;  dim_6 = None
    dim_7 = ones_2.dim()
    eq_33 = dim_7 == 2;  dim_7 = None
    getitem_41 = ones_2[(slice(None, None, None), None, None, slice(None, None, None))];  ones_2 = None
    to_31 = getitem_41.to(dtype = torch.float16);  getitem_41 = None
    sub_3 = 1.0 - to_31;  to_31 = None
    mul_31 = sub_3 * -65504.0;  sub_3 = None
    decoder_dropout = self.decoder.dropout(shared_1);  shared_1 = None
    to_32 = decoder_dropout.to(torch.float32)
    pow_14 = to_32.pow(2);  to_32 = None
    mean_13 = pow_14.mean(-1, keepdim = True);  pow_14 = None
    add_36 = mean_13 + 1e-06;  mean_13 = None
    rsqrt_13 = torch.rsqrt(add_36);  add_36 = None
    mul_32 = decoder_dropout * rsqrt_13;  rsqrt_13 = None
    decoder_block_0_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "0").layer, "0").layer_norm.weight
    getattr_45 = decoder_block_0_layer_0_layer_norm_weight.dtype
    eq_34 = getattr_45 == torch.float16;  getattr_45 = None
    getattr_46 = decoder_block_0_layer_0_layer_norm_weight.dtype
    to_33 = mul_32.to(getattr_46);  mul_32 = getattr_46 = None
    mul_33 = decoder_block_0_layer_0_layer_norm_weight * to_33;  decoder_block_0_layer_0_layer_norm_weight = to_33 = None
    size_13 = mul_33.size()
    getitem_42 = size_13[slice(None, 2, None)];  size_13 = None
    getitem_43 = getitem_42[0]
    getitem_44 = getitem_42[1];  getitem_42 = None
    decoder_block_0_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.q(mul_33)
    view_26 = decoder_block_0_layer_0_self_attention_q.view(getitem_43, -1, 8, 64);  decoder_block_0_layer_0_self_attention_q = None
    transpose_30 = view_26.transpose(1, 2);  view_26 = None
    decoder_block_0_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.k(mul_33)
    view_27 = decoder_block_0_layer_0_self_attention_k.view(getitem_43, -1, 8, 64);  decoder_block_0_layer_0_self_attention_k = None
    transpose_31 = view_27.transpose(1, 2);  view_27 = None
    decoder_block_0_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.v(mul_33);  mul_33 = None
    view_28 = decoder_block_0_layer_0_self_attention_v.view(getitem_43, -1, 8, 64);  decoder_block_0_layer_0_self_attention_v = None
    transpose_32 = view_28.transpose(1, 2);  view_28 = None
    transpose_33 = transpose_31.transpose(3, 2)
    matmul_12 = torch.matmul(transpose_30, transpose_33);  transpose_30 = transpose_33 = None
    getattr_47 = matmul_12.device
    arange_3 = torch.arange(getitem_44, dtype = torch.int64, device = getattr_47)
    getitem_45 = arange_3[(slice(None, None, None), None)];  arange_3 = None
    arange_4 = torch.arange(getitem_44, dtype = torch.int64, device = getattr_47);  getitem_44 = getattr_47 = None
    getitem_46 = arange_4[(None, slice(None, None, None))];  arange_4 = None
    sub_4 = getitem_46 - getitem_45;  getitem_46 = getitem_45 = None
    zeros_like = torch.zeros_like(sub_4)
    min_2 = torch.min(sub_4, zeros_like);  sub_4 = zeros_like = None
    neg = -min_2;  min_2 = None
    lt_2 = neg < 16
    float_8 = neg.float()
    truediv_2 = float_8 / 16;  float_8 = None
    log_1 = torch.log(truediv_2);  truediv_2 = None
    truediv_3 = log_1 / 2.0794415416798357;  log_1 = None
    mul_34 = truediv_3 * 16;  truediv_3 = None
    to_34 = mul_34.to(torch.int64);  mul_34 = None
    add_37 = 16 + to_34;  to_34 = None
    full_like_1 = torch.full_like(add_37, 31)
    min_3 = torch.min(add_37, full_like_1);  add_37 = full_like_1 = None
    where_1 = torch.where(lt_2, neg, min_3);  lt_2 = neg = min_3 = None
    add_38 = 0 + where_1;  where_1 = None
    decoder_block_0_layer_0_self_attention_relative_attention_bias = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.relative_attention_bias(add_38);  add_38 = None
    permute_1 = decoder_block_0_layer_0_self_attention_relative_attention_bias.permute([2, 0, 1]);  decoder_block_0_layer_0_self_attention_relative_attention_bias = None
    unsqueeze_1 = permute_1.unsqueeze(0);  permute_1 = None
    add_39 = unsqueeze_1 + mul_30;  unsqueeze_1 = mul_30 = None
    add_40 = matmul_12 + add_39;  matmul_12 = None
    float_9 = add_40.float()
    softmax_6 = torch.nn.functional.softmax(float_9, dim = -1, _stacklevel = 3, dtype = None);  float_9 = None
    type_as_6 = softmax_6.type_as(add_40);  softmax_6 = add_40 = None
    dropout_6 = torch.nn.functional.dropout(type_as_6, p = 0.1, training = False, inplace = False);  type_as_6 = None
    matmul_13 = torch.matmul(dropout_6, transpose_32);  dropout_6 = None
    transpose_34 = matmul_13.transpose(1, 2);  matmul_13 = None
    contiguous_6 = transpose_34.contiguous();  transpose_34 = None
    view_29 = contiguous_6.view(getitem_43, -1, 512);  contiguous_6 = getitem_43 = None
    decoder_block_0_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.o(view_29);  view_29 = None
    decoder_block_0_layer_0_dropout = getattr(getattr(self.decoder.block, "0").layer, "0").dropout(decoder_block_0_layer_0_self_attention_o);  decoder_block_0_layer_0_self_attention_o = None
    add_41 = decoder_dropout + decoder_block_0_layer_0_dropout;  decoder_dropout = decoder_block_0_layer_0_dropout = None
    getattr_48 = add_41.dtype
    eq_35 = getattr_48 == torch.float16;  getattr_48 = None
    size_14 = transpose_31.size()
    getitem_47 = size_14[2];  size_14 = None
    to_35 = add_41.to(torch.float32)
    pow_15 = to_35.pow(2);  to_35 = None
    mean_14 = pow_15.mean(-1, keepdim = True);  pow_15 = None
    add_42 = mean_14 + 1e-06;  mean_14 = None
    rsqrt_14 = torch.rsqrt(add_42);  add_42 = None
    mul_35 = add_41 * rsqrt_14;  rsqrt_14 = None
    decoder_block_0_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "0").layer, "1").layer_norm.weight
    getattr_49 = decoder_block_0_layer_1_layer_norm_weight.dtype
    eq_36 = getattr_49 == torch.float16;  getattr_49 = None
    getattr_50 = decoder_block_0_layer_1_layer_norm_weight.dtype
    to_36 = mul_35.to(getattr_50);  mul_35 = getattr_50 = None
    mul_36 = decoder_block_0_layer_1_layer_norm_weight * to_36;  decoder_block_0_layer_1_layer_norm_weight = to_36 = None
    size_15 = mul_36.size()
    getitem_48 = size_15[slice(None, 2, None)];  size_15 = None
    getitem_49 = getitem_48[0]
    getitem_50 = getitem_48[1];  getitem_48 = None
    size_16 = encoder_dropout_1.size()
    getitem_51 = size_16[1];  size_16 = None
    decoder_block_0_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.q(mul_36);  mul_36 = None
    view_30 = decoder_block_0_layer_1_enc_dec_attention_q.view(getitem_49, -1, 8, 64);  decoder_block_0_layer_1_enc_dec_attention_q = None
    transpose_35 = view_30.transpose(1, 2);  view_30 = None
    decoder_block_0_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_31 = decoder_block_0_layer_1_enc_dec_attention_k.view(getitem_49, -1, 8, 64);  decoder_block_0_layer_1_enc_dec_attention_k = None
    transpose_36 = view_31.transpose(1, 2);  view_31 = None
    decoder_block_0_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_32 = decoder_block_0_layer_1_enc_dec_attention_v.view(getitem_49, -1, 8, 64);  decoder_block_0_layer_1_enc_dec_attention_v = None
    transpose_37 = view_32.transpose(1, 2);  view_32 = None
    transpose_38 = transpose_36.transpose(3, 2)
    matmul_14 = torch.matmul(transpose_35, transpose_38);  transpose_35 = transpose_38 = None
    getattr_51 = matmul_14.device
    getattr_52 = matmul_14.dtype
    zeros = torch.zeros((1, 8, getitem_50, getitem_51), device = getattr_51, dtype = getattr_52);  getitem_50 = getitem_51 = getattr_51 = getattr_52 = None
    add_43 = zeros + mul_31;  zeros = mul_31 = None
    add_44 = matmul_14 + add_43;  matmul_14 = None
    float_10 = add_44.float()
    softmax_7 = torch.nn.functional.softmax(float_10, dim = -1, _stacklevel = 3, dtype = None);  float_10 = None
    type_as_7 = softmax_7.type_as(add_44);  softmax_7 = add_44 = None
    dropout_7 = torch.nn.functional.dropout(type_as_7, p = 0.1, training = False, inplace = False);  type_as_7 = None
    matmul_15 = torch.matmul(dropout_7, transpose_37);  dropout_7 = None
    transpose_39 = matmul_15.transpose(1, 2);  matmul_15 = None
    contiguous_7 = transpose_39.contiguous();  transpose_39 = None
    view_33 = contiguous_7.view(getitem_49, -1, 512);  contiguous_7 = getitem_49 = None
    decoder_block_0_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.o(view_33);  view_33 = None
    decoder_block_0_layer_1_dropout = getattr(getattr(self.decoder.block, "0").layer, "1").dropout(decoder_block_0_layer_1_enc_dec_attention_o);  decoder_block_0_layer_1_enc_dec_attention_o = None
    add_45 = add_41 + decoder_block_0_layer_1_dropout;  add_41 = decoder_block_0_layer_1_dropout = None
    getattr_53 = add_45.dtype
    eq_37 = getattr_53 == torch.float16;  getattr_53 = None
    to_37 = add_45.to(torch.float32)
    pow_16 = to_37.pow(2);  to_37 = None
    mean_15 = pow_16.mean(-1, keepdim = True);  pow_16 = None
    add_46 = mean_15 + 1e-06;  mean_15 = None
    rsqrt_15 = torch.rsqrt(add_46);  add_46 = None
    mul_37 = add_45 * rsqrt_15;  rsqrt_15 = None
    decoder_block_0_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "0").layer, "2").layer_norm.weight
    getattr_54 = decoder_block_0_layer_2_layer_norm_weight.dtype
    eq_38 = getattr_54 == torch.float16;  getattr_54 = None
    getattr_55 = decoder_block_0_layer_2_layer_norm_weight.dtype
    to_38 = mul_37.to(getattr_55);  mul_37 = getattr_55 = None
    mul_38 = decoder_block_0_layer_2_layer_norm_weight * to_38;  decoder_block_0_layer_2_layer_norm_weight = to_38 = None
    decoder_block_0_layer_2_dense_relu_dense_wi = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.wi(mul_38);  mul_38 = None
    decoder_block_0_layer_2_dense_relu_dense_act = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.act(decoder_block_0_layer_2_dense_relu_dense_wi);  decoder_block_0_layer_2_dense_relu_dense_wi = None
    decoder_block_0_layer_2_dense_relu_dense_dropout = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.dropout(decoder_block_0_layer_2_dense_relu_dense_act);  decoder_block_0_layer_2_dense_relu_dense_act = None
    decoder_block_0_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.wo.weight
    decoder_block_0_layer_2_dense_relu_dense_wo = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.wo(decoder_block_0_layer_2_dense_relu_dense_dropout);  decoder_block_0_layer_2_dense_relu_dense_dropout = None
    decoder_block_0_layer_2_dropout = getattr(getattr(self.decoder.block, "0").layer, "2").dropout(decoder_block_0_layer_2_dense_relu_dense_wo);  decoder_block_0_layer_2_dense_relu_dense_wo = None
    add_47 = add_45 + decoder_block_0_layer_2_dropout;  add_45 = decoder_block_0_layer_2_dropout = None
    getattr_56 = add_47.dtype
    eq_39 = getattr_56 == torch.float16;  getattr_56 = None
    to_39 = add_47.to(torch.float32)
    pow_17 = to_39.pow(2);  to_39 = None
    mean_16 = pow_17.mean(-1, keepdim = True);  pow_17 = None
    add_48 = mean_16 + 1e-06;  mean_16 = None
    rsqrt_16 = torch.rsqrt(add_48);  add_48 = None
    mul_39 = add_47 * rsqrt_16;  rsqrt_16 = None
    decoder_block_1_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "1").layer, "0").layer_norm.weight
    getattr_57 = decoder_block_1_layer_0_layer_norm_weight.dtype
    eq_40 = getattr_57 == torch.float16;  getattr_57 = None
    getattr_58 = decoder_block_1_layer_0_layer_norm_weight.dtype
    to_40 = mul_39.to(getattr_58);  mul_39 = getattr_58 = None
    mul_40 = decoder_block_1_layer_0_layer_norm_weight * to_40;  decoder_block_1_layer_0_layer_norm_weight = to_40 = None
    size_17 = mul_40.size()
    getitem_52 = size_17[slice(None, 2, None)];  size_17 = None
    getitem_53 = getitem_52[0]
    getitem_54 = getitem_52[1];  getitem_52 = None
    decoder_block_1_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.q(mul_40)
    view_34 = decoder_block_1_layer_0_self_attention_q.view(getitem_53, -1, 8, 64);  decoder_block_1_layer_0_self_attention_q = None
    transpose_40 = view_34.transpose(1, 2);  view_34 = None
    decoder_block_1_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.k(mul_40)
    view_35 = decoder_block_1_layer_0_self_attention_k.view(getitem_53, -1, 8, 64);  decoder_block_1_layer_0_self_attention_k = None
    transpose_41 = view_35.transpose(1, 2);  view_35 = None
    decoder_block_1_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.v(mul_40);  mul_40 = None
    view_36 = decoder_block_1_layer_0_self_attention_v.view(getitem_53, -1, 8, 64);  decoder_block_1_layer_0_self_attention_v = None
    transpose_42 = view_36.transpose(1, 2);  view_36 = None
    transpose_43 = transpose_41.transpose(3, 2)
    matmul_16 = torch.matmul(transpose_40, transpose_43);  transpose_40 = transpose_43 = None
    add_49 = matmul_16 + add_39;  matmul_16 = None
    float_11 = add_49.float()
    softmax_8 = torch.nn.functional.softmax(float_11, dim = -1, _stacklevel = 3, dtype = None);  float_11 = None
    type_as_8 = softmax_8.type_as(add_49);  softmax_8 = add_49 = None
    dropout_8 = torch.nn.functional.dropout(type_as_8, p = 0.1, training = False, inplace = False);  type_as_8 = None
    matmul_17 = torch.matmul(dropout_8, transpose_42);  dropout_8 = None
    transpose_44 = matmul_17.transpose(1, 2);  matmul_17 = None
    contiguous_8 = transpose_44.contiguous();  transpose_44 = None
    view_37 = contiguous_8.view(getitem_53, -1, 512);  contiguous_8 = getitem_53 = None
    decoder_block_1_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.o(view_37);  view_37 = None
    decoder_block_1_layer_0_dropout = getattr(getattr(self.decoder.block, "1").layer, "0").dropout(decoder_block_1_layer_0_self_attention_o);  decoder_block_1_layer_0_self_attention_o = None
    add_50 = add_47 + decoder_block_1_layer_0_dropout;  add_47 = decoder_block_1_layer_0_dropout = None
    getattr_59 = add_50.dtype
    eq_41 = getattr_59 == torch.float16;  getattr_59 = None
    size_18 = transpose_41.size()
    getitem_55 = size_18[2];  size_18 = None
    to_41 = add_50.to(torch.float32)
    pow_18 = to_41.pow(2);  to_41 = None
    mean_17 = pow_18.mean(-1, keepdim = True);  pow_18 = None
    add_51 = mean_17 + 1e-06;  mean_17 = None
    rsqrt_17 = torch.rsqrt(add_51);  add_51 = None
    mul_41 = add_50 * rsqrt_17;  rsqrt_17 = None
    decoder_block_1_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "1").layer, "1").layer_norm.weight
    getattr_60 = decoder_block_1_layer_1_layer_norm_weight.dtype
    eq_42 = getattr_60 == torch.float16;  getattr_60 = None
    getattr_61 = decoder_block_1_layer_1_layer_norm_weight.dtype
    to_42 = mul_41.to(getattr_61);  mul_41 = getattr_61 = None
    mul_42 = decoder_block_1_layer_1_layer_norm_weight * to_42;  decoder_block_1_layer_1_layer_norm_weight = to_42 = None
    size_19 = mul_42.size()
    getitem_56 = size_19[slice(None, 2, None)];  size_19 = None
    getitem_57 = getitem_56[0]
    getitem_58 = getitem_56[1];  getitem_56 = None
    size_20 = encoder_dropout_1.size()
    getitem_59 = size_20[1];  size_20 = None
    decoder_block_1_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.q(mul_42);  mul_42 = None
    view_38 = decoder_block_1_layer_1_enc_dec_attention_q.view(getitem_57, -1, 8, 64);  decoder_block_1_layer_1_enc_dec_attention_q = None
    transpose_45 = view_38.transpose(1, 2);  view_38 = None
    decoder_block_1_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_39 = decoder_block_1_layer_1_enc_dec_attention_k.view(getitem_57, -1, 8, 64);  decoder_block_1_layer_1_enc_dec_attention_k = None
    transpose_46 = view_39.transpose(1, 2);  view_39 = None
    decoder_block_1_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_40 = decoder_block_1_layer_1_enc_dec_attention_v.view(getitem_57, -1, 8, 64);  decoder_block_1_layer_1_enc_dec_attention_v = None
    transpose_47 = view_40.transpose(1, 2);  view_40 = None
    transpose_48 = transpose_46.transpose(3, 2)
    matmul_18 = torch.matmul(transpose_45, transpose_48);  transpose_45 = transpose_48 = None
    add_52 = matmul_18 + add_43;  matmul_18 = None
    float_12 = add_52.float()
    softmax_9 = torch.nn.functional.softmax(float_12, dim = -1, _stacklevel = 3, dtype = None);  float_12 = None
    type_as_9 = softmax_9.type_as(add_52);  softmax_9 = add_52 = None
    dropout_9 = torch.nn.functional.dropout(type_as_9, p = 0.1, training = False, inplace = False);  type_as_9 = None
    matmul_19 = torch.matmul(dropout_9, transpose_47);  dropout_9 = None
    transpose_49 = matmul_19.transpose(1, 2);  matmul_19 = None
    contiguous_9 = transpose_49.contiguous();  transpose_49 = None
    view_41 = contiguous_9.view(getitem_57, -1, 512);  contiguous_9 = getitem_57 = None
    decoder_block_1_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.o(view_41);  view_41 = None
    decoder_block_1_layer_1_dropout = getattr(getattr(self.decoder.block, "1").layer, "1").dropout(decoder_block_1_layer_1_enc_dec_attention_o);  decoder_block_1_layer_1_enc_dec_attention_o = None
    add_53 = add_50 + decoder_block_1_layer_1_dropout;  add_50 = decoder_block_1_layer_1_dropout = None
    getattr_62 = add_53.dtype
    eq_43 = getattr_62 == torch.float16;  getattr_62 = None
    to_43 = add_53.to(torch.float32)
    pow_19 = to_43.pow(2);  to_43 = None
    mean_18 = pow_19.mean(-1, keepdim = True);  pow_19 = None
    add_54 = mean_18 + 1e-06;  mean_18 = None
    rsqrt_18 = torch.rsqrt(add_54);  add_54 = None
    mul_43 = add_53 * rsqrt_18;  rsqrt_18 = None
    decoder_block_1_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "1").layer, "2").layer_norm.weight
    getattr_63 = decoder_block_1_layer_2_layer_norm_weight.dtype
    eq_44 = getattr_63 == torch.float16;  getattr_63 = None
    getattr_64 = decoder_block_1_layer_2_layer_norm_weight.dtype
    to_44 = mul_43.to(getattr_64);  mul_43 = getattr_64 = None
    mul_44 = decoder_block_1_layer_2_layer_norm_weight * to_44;  decoder_block_1_layer_2_layer_norm_weight = to_44 = None
    decoder_block_1_layer_2_dense_relu_dense_wi = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.wi(mul_44);  mul_44 = None
    decoder_block_1_layer_2_dense_relu_dense_act = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.act(decoder_block_1_layer_2_dense_relu_dense_wi);  decoder_block_1_layer_2_dense_relu_dense_wi = None
    decoder_block_1_layer_2_dense_relu_dense_dropout = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.dropout(decoder_block_1_layer_2_dense_relu_dense_act);  decoder_block_1_layer_2_dense_relu_dense_act = None
    decoder_block_1_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.wo.weight
    decoder_block_1_layer_2_dense_relu_dense_wo = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.wo(decoder_block_1_layer_2_dense_relu_dense_dropout);  decoder_block_1_layer_2_dense_relu_dense_dropout = None
    decoder_block_1_layer_2_dropout = getattr(getattr(self.decoder.block, "1").layer, "2").dropout(decoder_block_1_layer_2_dense_relu_dense_wo);  decoder_block_1_layer_2_dense_relu_dense_wo = None
    add_55 = add_53 + decoder_block_1_layer_2_dropout;  add_53 = decoder_block_1_layer_2_dropout = None
    getattr_65 = add_55.dtype
    eq_45 = getattr_65 == torch.float16;  getattr_65 = None
    to_45 = add_55.to(torch.float32)
    pow_20 = to_45.pow(2);  to_45 = None
    mean_19 = pow_20.mean(-1, keepdim = True);  pow_20 = None
    add_56 = mean_19 + 1e-06;  mean_19 = None
    rsqrt_19 = torch.rsqrt(add_56);  add_56 = None
    mul_45 = add_55 * rsqrt_19;  rsqrt_19 = None
    decoder_block_2_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "2").layer, "0").layer_norm.weight
    getattr_66 = decoder_block_2_layer_0_layer_norm_weight.dtype
    eq_46 = getattr_66 == torch.float16;  getattr_66 = None
    getattr_67 = decoder_block_2_layer_0_layer_norm_weight.dtype
    to_46 = mul_45.to(getattr_67);  mul_45 = getattr_67 = None
    mul_46 = decoder_block_2_layer_0_layer_norm_weight * to_46;  decoder_block_2_layer_0_layer_norm_weight = to_46 = None
    size_21 = mul_46.size()
    getitem_60 = size_21[slice(None, 2, None)];  size_21 = None
    getitem_61 = getitem_60[0]
    getitem_62 = getitem_60[1];  getitem_60 = None
    decoder_block_2_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.q(mul_46)
    view_42 = decoder_block_2_layer_0_self_attention_q.view(getitem_61, -1, 8, 64);  decoder_block_2_layer_0_self_attention_q = None
    transpose_50 = view_42.transpose(1, 2);  view_42 = None
    decoder_block_2_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.k(mul_46)
    view_43 = decoder_block_2_layer_0_self_attention_k.view(getitem_61, -1, 8, 64);  decoder_block_2_layer_0_self_attention_k = None
    transpose_51 = view_43.transpose(1, 2);  view_43 = None
    decoder_block_2_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.v(mul_46);  mul_46 = None
    view_44 = decoder_block_2_layer_0_self_attention_v.view(getitem_61, -1, 8, 64);  decoder_block_2_layer_0_self_attention_v = None
    transpose_52 = view_44.transpose(1, 2);  view_44 = None
    transpose_53 = transpose_51.transpose(3, 2)
    matmul_20 = torch.matmul(transpose_50, transpose_53);  transpose_50 = transpose_53 = None
    add_57 = matmul_20 + add_39;  matmul_20 = None
    float_13 = add_57.float()
    softmax_10 = torch.nn.functional.softmax(float_13, dim = -1, _stacklevel = 3, dtype = None);  float_13 = None
    type_as_10 = softmax_10.type_as(add_57);  softmax_10 = add_57 = None
    dropout_10 = torch.nn.functional.dropout(type_as_10, p = 0.1, training = False, inplace = False);  type_as_10 = None
    matmul_21 = torch.matmul(dropout_10, transpose_52);  dropout_10 = None
    transpose_54 = matmul_21.transpose(1, 2);  matmul_21 = None
    contiguous_10 = transpose_54.contiguous();  transpose_54 = None
    view_45 = contiguous_10.view(getitem_61, -1, 512);  contiguous_10 = getitem_61 = None
    decoder_block_2_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.o(view_45);  view_45 = None
    decoder_block_2_layer_0_dropout = getattr(getattr(self.decoder.block, "2").layer, "0").dropout(decoder_block_2_layer_0_self_attention_o);  decoder_block_2_layer_0_self_attention_o = None
    add_58 = add_55 + decoder_block_2_layer_0_dropout;  add_55 = decoder_block_2_layer_0_dropout = None
    getattr_68 = add_58.dtype
    eq_47 = getattr_68 == torch.float16;  getattr_68 = None
    size_22 = transpose_51.size()
    getitem_63 = size_22[2];  size_22 = None
    to_47 = add_58.to(torch.float32)
    pow_21 = to_47.pow(2);  to_47 = None
    mean_20 = pow_21.mean(-1, keepdim = True);  pow_21 = None
    add_59 = mean_20 + 1e-06;  mean_20 = None
    rsqrt_20 = torch.rsqrt(add_59);  add_59 = None
    mul_47 = add_58 * rsqrt_20;  rsqrt_20 = None
    decoder_block_2_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "2").layer, "1").layer_norm.weight
    getattr_69 = decoder_block_2_layer_1_layer_norm_weight.dtype
    eq_48 = getattr_69 == torch.float16;  getattr_69 = None
    getattr_70 = decoder_block_2_layer_1_layer_norm_weight.dtype
    to_48 = mul_47.to(getattr_70);  mul_47 = getattr_70 = None
    mul_48 = decoder_block_2_layer_1_layer_norm_weight * to_48;  decoder_block_2_layer_1_layer_norm_weight = to_48 = None
    size_23 = mul_48.size()
    getitem_64 = size_23[slice(None, 2, None)];  size_23 = None
    getitem_65 = getitem_64[0]
    getitem_66 = getitem_64[1];  getitem_64 = None
    size_24 = encoder_dropout_1.size()
    getitem_67 = size_24[1];  size_24 = None
    decoder_block_2_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.q(mul_48);  mul_48 = None
    view_46 = decoder_block_2_layer_1_enc_dec_attention_q.view(getitem_65, -1, 8, 64);  decoder_block_2_layer_1_enc_dec_attention_q = None
    transpose_55 = view_46.transpose(1, 2);  view_46 = None
    decoder_block_2_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_47 = decoder_block_2_layer_1_enc_dec_attention_k.view(getitem_65, -1, 8, 64);  decoder_block_2_layer_1_enc_dec_attention_k = None
    transpose_56 = view_47.transpose(1, 2);  view_47 = None
    decoder_block_2_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_48 = decoder_block_2_layer_1_enc_dec_attention_v.view(getitem_65, -1, 8, 64);  decoder_block_2_layer_1_enc_dec_attention_v = None
    transpose_57 = view_48.transpose(1, 2);  view_48 = None
    transpose_58 = transpose_56.transpose(3, 2)
    matmul_22 = torch.matmul(transpose_55, transpose_58);  transpose_55 = transpose_58 = None
    add_60 = matmul_22 + add_43;  matmul_22 = None
    float_14 = add_60.float()
    softmax_11 = torch.nn.functional.softmax(float_14, dim = -1, _stacklevel = 3, dtype = None);  float_14 = None
    type_as_11 = softmax_11.type_as(add_60);  softmax_11 = add_60 = None
    dropout_11 = torch.nn.functional.dropout(type_as_11, p = 0.1, training = False, inplace = False);  type_as_11 = None
    matmul_23 = torch.matmul(dropout_11, transpose_57);  dropout_11 = None
    transpose_59 = matmul_23.transpose(1, 2);  matmul_23 = None
    contiguous_11 = transpose_59.contiguous();  transpose_59 = None
    view_49 = contiguous_11.view(getitem_65, -1, 512);  contiguous_11 = getitem_65 = None
    decoder_block_2_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.o(view_49);  view_49 = None
    decoder_block_2_layer_1_dropout = getattr(getattr(self.decoder.block, "2").layer, "1").dropout(decoder_block_2_layer_1_enc_dec_attention_o);  decoder_block_2_layer_1_enc_dec_attention_o = None
    add_61 = add_58 + decoder_block_2_layer_1_dropout;  add_58 = decoder_block_2_layer_1_dropout = None
    getattr_71 = add_61.dtype
    eq_49 = getattr_71 == torch.float16;  getattr_71 = None
    to_49 = add_61.to(torch.float32)
    pow_22 = to_49.pow(2);  to_49 = None
    mean_21 = pow_22.mean(-1, keepdim = True);  pow_22 = None
    add_62 = mean_21 + 1e-06;  mean_21 = None
    rsqrt_21 = torch.rsqrt(add_62);  add_62 = None
    mul_49 = add_61 * rsqrt_21;  rsqrt_21 = None
    decoder_block_2_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "2").layer, "2").layer_norm.weight
    getattr_72 = decoder_block_2_layer_2_layer_norm_weight.dtype
    eq_50 = getattr_72 == torch.float16;  getattr_72 = None
    getattr_73 = decoder_block_2_layer_2_layer_norm_weight.dtype
    to_50 = mul_49.to(getattr_73);  mul_49 = getattr_73 = None
    mul_50 = decoder_block_2_layer_2_layer_norm_weight * to_50;  decoder_block_2_layer_2_layer_norm_weight = to_50 = None
    decoder_block_2_layer_2_dense_relu_dense_wi = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.wi(mul_50);  mul_50 = None
    decoder_block_2_layer_2_dense_relu_dense_act = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.act(decoder_block_2_layer_2_dense_relu_dense_wi);  decoder_block_2_layer_2_dense_relu_dense_wi = None
    decoder_block_2_layer_2_dense_relu_dense_dropout = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.dropout(decoder_block_2_layer_2_dense_relu_dense_act);  decoder_block_2_layer_2_dense_relu_dense_act = None
    decoder_block_2_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.wo.weight
    decoder_block_2_layer_2_dense_relu_dense_wo = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.wo(decoder_block_2_layer_2_dense_relu_dense_dropout);  decoder_block_2_layer_2_dense_relu_dense_dropout = None
    decoder_block_2_layer_2_dropout = getattr(getattr(self.decoder.block, "2").layer, "2").dropout(decoder_block_2_layer_2_dense_relu_dense_wo);  decoder_block_2_layer_2_dense_relu_dense_wo = None
    add_63 = add_61 + decoder_block_2_layer_2_dropout;  add_61 = decoder_block_2_layer_2_dropout = None
    getattr_74 = add_63.dtype
    eq_51 = getattr_74 == torch.float16;  getattr_74 = None
    to_51 = add_63.to(torch.float32)
    pow_23 = to_51.pow(2);  to_51 = None
    mean_22 = pow_23.mean(-1, keepdim = True);  pow_23 = None
    add_64 = mean_22 + 1e-06;  mean_22 = None
    rsqrt_22 = torch.rsqrt(add_64);  add_64 = None
    mul_51 = add_63 * rsqrt_22;  rsqrt_22 = None
    decoder_block_3_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "3").layer, "0").layer_norm.weight
    getattr_75 = decoder_block_3_layer_0_layer_norm_weight.dtype
    eq_52 = getattr_75 == torch.float16;  getattr_75 = None
    getattr_76 = decoder_block_3_layer_0_layer_norm_weight.dtype
    to_52 = mul_51.to(getattr_76);  mul_51 = getattr_76 = None
    mul_52 = decoder_block_3_layer_0_layer_norm_weight * to_52;  decoder_block_3_layer_0_layer_norm_weight = to_52 = None
    size_25 = mul_52.size()
    getitem_68 = size_25[slice(None, 2, None)];  size_25 = None
    getitem_69 = getitem_68[0]
    getitem_70 = getitem_68[1];  getitem_68 = None
    decoder_block_3_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.q(mul_52)
    view_50 = decoder_block_3_layer_0_self_attention_q.view(getitem_69, -1, 8, 64);  decoder_block_3_layer_0_self_attention_q = None
    transpose_60 = view_50.transpose(1, 2);  view_50 = None
    decoder_block_3_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.k(mul_52)
    view_51 = decoder_block_3_layer_0_self_attention_k.view(getitem_69, -1, 8, 64);  decoder_block_3_layer_0_self_attention_k = None
    transpose_61 = view_51.transpose(1, 2);  view_51 = None
    decoder_block_3_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.v(mul_52);  mul_52 = None
    view_52 = decoder_block_3_layer_0_self_attention_v.view(getitem_69, -1, 8, 64);  decoder_block_3_layer_0_self_attention_v = None
    transpose_62 = view_52.transpose(1, 2);  view_52 = None
    transpose_63 = transpose_61.transpose(3, 2)
    matmul_24 = torch.matmul(transpose_60, transpose_63);  transpose_60 = transpose_63 = None
    add_65 = matmul_24 + add_39;  matmul_24 = None
    float_15 = add_65.float()
    softmax_12 = torch.nn.functional.softmax(float_15, dim = -1, _stacklevel = 3, dtype = None);  float_15 = None
    type_as_12 = softmax_12.type_as(add_65);  softmax_12 = add_65 = None
    dropout_12 = torch.nn.functional.dropout(type_as_12, p = 0.1, training = False, inplace = False);  type_as_12 = None
    matmul_25 = torch.matmul(dropout_12, transpose_62);  dropout_12 = None
    transpose_64 = matmul_25.transpose(1, 2);  matmul_25 = None
    contiguous_12 = transpose_64.contiguous();  transpose_64 = None
    view_53 = contiguous_12.view(getitem_69, -1, 512);  contiguous_12 = getitem_69 = None
    decoder_block_3_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.o(view_53);  view_53 = None
    decoder_block_3_layer_0_dropout = getattr(getattr(self.decoder.block, "3").layer, "0").dropout(decoder_block_3_layer_0_self_attention_o);  decoder_block_3_layer_0_self_attention_o = None
    add_66 = add_63 + decoder_block_3_layer_0_dropout;  add_63 = decoder_block_3_layer_0_dropout = None
    getattr_77 = add_66.dtype
    eq_53 = getattr_77 == torch.float16;  getattr_77 = None
    size_26 = transpose_61.size()
    getitem_71 = size_26[2];  size_26 = None
    to_53 = add_66.to(torch.float32)
    pow_24 = to_53.pow(2);  to_53 = None
    mean_23 = pow_24.mean(-1, keepdim = True);  pow_24 = None
    add_67 = mean_23 + 1e-06;  mean_23 = None
    rsqrt_23 = torch.rsqrt(add_67);  add_67 = None
    mul_53 = add_66 * rsqrt_23;  rsqrt_23 = None
    decoder_block_3_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "3").layer, "1").layer_norm.weight
    getattr_78 = decoder_block_3_layer_1_layer_norm_weight.dtype
    eq_54 = getattr_78 == torch.float16;  getattr_78 = None
    getattr_79 = decoder_block_3_layer_1_layer_norm_weight.dtype
    to_54 = mul_53.to(getattr_79);  mul_53 = getattr_79 = None
    mul_54 = decoder_block_3_layer_1_layer_norm_weight * to_54;  decoder_block_3_layer_1_layer_norm_weight = to_54 = None
    size_27 = mul_54.size()
    getitem_72 = size_27[slice(None, 2, None)];  size_27 = None
    getitem_73 = getitem_72[0]
    getitem_74 = getitem_72[1];  getitem_72 = None
    size_28 = encoder_dropout_1.size()
    getitem_75 = size_28[1];  size_28 = None
    decoder_block_3_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.q(mul_54);  mul_54 = None
    view_54 = decoder_block_3_layer_1_enc_dec_attention_q.view(getitem_73, -1, 8, 64);  decoder_block_3_layer_1_enc_dec_attention_q = None
    transpose_65 = view_54.transpose(1, 2);  view_54 = None
    decoder_block_3_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_55 = decoder_block_3_layer_1_enc_dec_attention_k.view(getitem_73, -1, 8, 64);  decoder_block_3_layer_1_enc_dec_attention_k = None
    transpose_66 = view_55.transpose(1, 2);  view_55 = None
    decoder_block_3_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_56 = decoder_block_3_layer_1_enc_dec_attention_v.view(getitem_73, -1, 8, 64);  decoder_block_3_layer_1_enc_dec_attention_v = None
    transpose_67 = view_56.transpose(1, 2);  view_56 = None
    transpose_68 = transpose_66.transpose(3, 2)
    matmul_26 = torch.matmul(transpose_65, transpose_68);  transpose_65 = transpose_68 = None
    add_68 = matmul_26 + add_43;  matmul_26 = None
    float_16 = add_68.float()
    softmax_13 = torch.nn.functional.softmax(float_16, dim = -1, _stacklevel = 3, dtype = None);  float_16 = None
    type_as_13 = softmax_13.type_as(add_68);  softmax_13 = add_68 = None
    dropout_13 = torch.nn.functional.dropout(type_as_13, p = 0.1, training = False, inplace = False);  type_as_13 = None
    matmul_27 = torch.matmul(dropout_13, transpose_67);  dropout_13 = None
    transpose_69 = matmul_27.transpose(1, 2);  matmul_27 = None
    contiguous_13 = transpose_69.contiguous();  transpose_69 = None
    view_57 = contiguous_13.view(getitem_73, -1, 512);  contiguous_13 = getitem_73 = None
    decoder_block_3_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.o(view_57);  view_57 = None
    decoder_block_3_layer_1_dropout = getattr(getattr(self.decoder.block, "3").layer, "1").dropout(decoder_block_3_layer_1_enc_dec_attention_o);  decoder_block_3_layer_1_enc_dec_attention_o = None
    add_69 = add_66 + decoder_block_3_layer_1_dropout;  add_66 = decoder_block_3_layer_1_dropout = None
    getattr_80 = add_69.dtype
    eq_55 = getattr_80 == torch.float16;  getattr_80 = None
    to_55 = add_69.to(torch.float32)
    pow_25 = to_55.pow(2);  to_55 = None
    mean_24 = pow_25.mean(-1, keepdim = True);  pow_25 = None
    add_70 = mean_24 + 1e-06;  mean_24 = None
    rsqrt_24 = torch.rsqrt(add_70);  add_70 = None
    mul_55 = add_69 * rsqrt_24;  rsqrt_24 = None
    decoder_block_3_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "3").layer, "2").layer_norm.weight
    getattr_81 = decoder_block_3_layer_2_layer_norm_weight.dtype
    eq_56 = getattr_81 == torch.float16;  getattr_81 = None
    getattr_82 = decoder_block_3_layer_2_layer_norm_weight.dtype
    to_56 = mul_55.to(getattr_82);  mul_55 = getattr_82 = None
    mul_56 = decoder_block_3_layer_2_layer_norm_weight * to_56;  decoder_block_3_layer_2_layer_norm_weight = to_56 = None
    decoder_block_3_layer_2_dense_relu_dense_wi = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.wi(mul_56);  mul_56 = None
    decoder_block_3_layer_2_dense_relu_dense_act = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.act(decoder_block_3_layer_2_dense_relu_dense_wi);  decoder_block_3_layer_2_dense_relu_dense_wi = None
    decoder_block_3_layer_2_dense_relu_dense_dropout = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.dropout(decoder_block_3_layer_2_dense_relu_dense_act);  decoder_block_3_layer_2_dense_relu_dense_act = None
    decoder_block_3_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.wo.weight
    decoder_block_3_layer_2_dense_relu_dense_wo = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.wo(decoder_block_3_layer_2_dense_relu_dense_dropout);  decoder_block_3_layer_2_dense_relu_dense_dropout = None
    decoder_block_3_layer_2_dropout = getattr(getattr(self.decoder.block, "3").layer, "2").dropout(decoder_block_3_layer_2_dense_relu_dense_wo);  decoder_block_3_layer_2_dense_relu_dense_wo = None
    add_71 = add_69 + decoder_block_3_layer_2_dropout;  add_69 = decoder_block_3_layer_2_dropout = None
    getattr_83 = add_71.dtype
    eq_57 = getattr_83 == torch.float16;  getattr_83 = None
    to_57 = add_71.to(torch.float32)
    pow_26 = to_57.pow(2);  to_57 = None
    mean_25 = pow_26.mean(-1, keepdim = True);  pow_26 = None
    add_72 = mean_25 + 1e-06;  mean_25 = None
    rsqrt_25 = torch.rsqrt(add_72);  add_72 = None
    mul_57 = add_71 * rsqrt_25;  rsqrt_25 = None
    decoder_block_4_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "4").layer, "0").layer_norm.weight
    getattr_84 = decoder_block_4_layer_0_layer_norm_weight.dtype
    eq_58 = getattr_84 == torch.float16;  getattr_84 = None
    getattr_85 = decoder_block_4_layer_0_layer_norm_weight.dtype
    to_58 = mul_57.to(getattr_85);  mul_57 = getattr_85 = None
    mul_58 = decoder_block_4_layer_0_layer_norm_weight * to_58;  decoder_block_4_layer_0_layer_norm_weight = to_58 = None
    size_29 = mul_58.size()
    getitem_76 = size_29[slice(None, 2, None)];  size_29 = None
    getitem_77 = getitem_76[0]
    getitem_78 = getitem_76[1];  getitem_76 = None
    decoder_block_4_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.q(mul_58)
    view_58 = decoder_block_4_layer_0_self_attention_q.view(getitem_77, -1, 8, 64);  decoder_block_4_layer_0_self_attention_q = None
    transpose_70 = view_58.transpose(1, 2);  view_58 = None
    decoder_block_4_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.k(mul_58)
    view_59 = decoder_block_4_layer_0_self_attention_k.view(getitem_77, -1, 8, 64);  decoder_block_4_layer_0_self_attention_k = None
    transpose_71 = view_59.transpose(1, 2);  view_59 = None
    decoder_block_4_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.v(mul_58);  mul_58 = None
    view_60 = decoder_block_4_layer_0_self_attention_v.view(getitem_77, -1, 8, 64);  decoder_block_4_layer_0_self_attention_v = None
    transpose_72 = view_60.transpose(1, 2);  view_60 = None
    transpose_73 = transpose_71.transpose(3, 2)
    matmul_28 = torch.matmul(transpose_70, transpose_73);  transpose_70 = transpose_73 = None
    add_73 = matmul_28 + add_39;  matmul_28 = None
    float_17 = add_73.float()
    softmax_14 = torch.nn.functional.softmax(float_17, dim = -1, _stacklevel = 3, dtype = None);  float_17 = None
    type_as_14 = softmax_14.type_as(add_73);  softmax_14 = add_73 = None
    dropout_14 = torch.nn.functional.dropout(type_as_14, p = 0.1, training = False, inplace = False);  type_as_14 = None
    matmul_29 = torch.matmul(dropout_14, transpose_72);  dropout_14 = None
    transpose_74 = matmul_29.transpose(1, 2);  matmul_29 = None
    contiguous_14 = transpose_74.contiguous();  transpose_74 = None
    view_61 = contiguous_14.view(getitem_77, -1, 512);  contiguous_14 = getitem_77 = None
    decoder_block_4_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.o(view_61);  view_61 = None
    decoder_block_4_layer_0_dropout = getattr(getattr(self.decoder.block, "4").layer, "0").dropout(decoder_block_4_layer_0_self_attention_o);  decoder_block_4_layer_0_self_attention_o = None
    add_74 = add_71 + decoder_block_4_layer_0_dropout;  add_71 = decoder_block_4_layer_0_dropout = None
    getattr_86 = add_74.dtype
    eq_59 = getattr_86 == torch.float16;  getattr_86 = None
    size_30 = transpose_71.size()
    getitem_79 = size_30[2];  size_30 = None
    to_59 = add_74.to(torch.float32)
    pow_27 = to_59.pow(2);  to_59 = None
    mean_26 = pow_27.mean(-1, keepdim = True);  pow_27 = None
    add_75 = mean_26 + 1e-06;  mean_26 = None
    rsqrt_26 = torch.rsqrt(add_75);  add_75 = None
    mul_59 = add_74 * rsqrt_26;  rsqrt_26 = None
    decoder_block_4_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "4").layer, "1").layer_norm.weight
    getattr_87 = decoder_block_4_layer_1_layer_norm_weight.dtype
    eq_60 = getattr_87 == torch.float16;  getattr_87 = None
    getattr_88 = decoder_block_4_layer_1_layer_norm_weight.dtype
    to_60 = mul_59.to(getattr_88);  mul_59 = getattr_88 = None
    mul_60 = decoder_block_4_layer_1_layer_norm_weight * to_60;  decoder_block_4_layer_1_layer_norm_weight = to_60 = None
    size_31 = mul_60.size()
    getitem_80 = size_31[slice(None, 2, None)];  size_31 = None
    getitem_81 = getitem_80[0]
    getitem_82 = getitem_80[1];  getitem_80 = None
    size_32 = encoder_dropout_1.size()
    getitem_83 = size_32[1];  size_32 = None
    decoder_block_4_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.q(mul_60);  mul_60 = None
    view_62 = decoder_block_4_layer_1_enc_dec_attention_q.view(getitem_81, -1, 8, 64);  decoder_block_4_layer_1_enc_dec_attention_q = None
    transpose_75 = view_62.transpose(1, 2);  view_62 = None
    decoder_block_4_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_63 = decoder_block_4_layer_1_enc_dec_attention_k.view(getitem_81, -1, 8, 64);  decoder_block_4_layer_1_enc_dec_attention_k = None
    transpose_76 = view_63.transpose(1, 2);  view_63 = None
    decoder_block_4_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_64 = decoder_block_4_layer_1_enc_dec_attention_v.view(getitem_81, -1, 8, 64);  decoder_block_4_layer_1_enc_dec_attention_v = None
    transpose_77 = view_64.transpose(1, 2);  view_64 = None
    transpose_78 = transpose_76.transpose(3, 2)
    matmul_30 = torch.matmul(transpose_75, transpose_78);  transpose_75 = transpose_78 = None
    add_76 = matmul_30 + add_43;  matmul_30 = None
    float_18 = add_76.float()
    softmax_15 = torch.nn.functional.softmax(float_18, dim = -1, _stacklevel = 3, dtype = None);  float_18 = None
    type_as_15 = softmax_15.type_as(add_76);  softmax_15 = add_76 = None
    dropout_15 = torch.nn.functional.dropout(type_as_15, p = 0.1, training = False, inplace = False);  type_as_15 = None
    matmul_31 = torch.matmul(dropout_15, transpose_77);  dropout_15 = None
    transpose_79 = matmul_31.transpose(1, 2);  matmul_31 = None
    contiguous_15 = transpose_79.contiguous();  transpose_79 = None
    view_65 = contiguous_15.view(getitem_81, -1, 512);  contiguous_15 = getitem_81 = None
    decoder_block_4_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.o(view_65);  view_65 = None
    decoder_block_4_layer_1_dropout = getattr(getattr(self.decoder.block, "4").layer, "1").dropout(decoder_block_4_layer_1_enc_dec_attention_o);  decoder_block_4_layer_1_enc_dec_attention_o = None
    add_77 = add_74 + decoder_block_4_layer_1_dropout;  add_74 = decoder_block_4_layer_1_dropout = None
    getattr_89 = add_77.dtype
    eq_61 = getattr_89 == torch.float16;  getattr_89 = None
    to_61 = add_77.to(torch.float32)
    pow_28 = to_61.pow(2);  to_61 = None
    mean_27 = pow_28.mean(-1, keepdim = True);  pow_28 = None
    add_78 = mean_27 + 1e-06;  mean_27 = None
    rsqrt_27 = torch.rsqrt(add_78);  add_78 = None
    mul_61 = add_77 * rsqrt_27;  rsqrt_27 = None
    decoder_block_4_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "4").layer, "2").layer_norm.weight
    getattr_90 = decoder_block_4_layer_2_layer_norm_weight.dtype
    eq_62 = getattr_90 == torch.float16;  getattr_90 = None
    getattr_91 = decoder_block_4_layer_2_layer_norm_weight.dtype
    to_62 = mul_61.to(getattr_91);  mul_61 = getattr_91 = None
    mul_62 = decoder_block_4_layer_2_layer_norm_weight * to_62;  decoder_block_4_layer_2_layer_norm_weight = to_62 = None
    decoder_block_4_layer_2_dense_relu_dense_wi = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.wi(mul_62);  mul_62 = None
    decoder_block_4_layer_2_dense_relu_dense_act = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.act(decoder_block_4_layer_2_dense_relu_dense_wi);  decoder_block_4_layer_2_dense_relu_dense_wi = None
    decoder_block_4_layer_2_dense_relu_dense_dropout = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.dropout(decoder_block_4_layer_2_dense_relu_dense_act);  decoder_block_4_layer_2_dense_relu_dense_act = None
    decoder_block_4_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.wo.weight
    decoder_block_4_layer_2_dense_relu_dense_wo = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.wo(decoder_block_4_layer_2_dense_relu_dense_dropout);  decoder_block_4_layer_2_dense_relu_dense_dropout = None
    decoder_block_4_layer_2_dropout = getattr(getattr(self.decoder.block, "4").layer, "2").dropout(decoder_block_4_layer_2_dense_relu_dense_wo);  decoder_block_4_layer_2_dense_relu_dense_wo = None
    add_79 = add_77 + decoder_block_4_layer_2_dropout;  add_77 = decoder_block_4_layer_2_dropout = None
    getattr_92 = add_79.dtype
    eq_63 = getattr_92 == torch.float16;  getattr_92 = None
    to_63 = add_79.to(torch.float32)
    pow_29 = to_63.pow(2);  to_63 = None
    mean_28 = pow_29.mean(-1, keepdim = True);  pow_29 = None
    add_80 = mean_28 + 1e-06;  mean_28 = None
    rsqrt_28 = torch.rsqrt(add_80);  add_80 = None
    mul_63 = add_79 * rsqrt_28;  rsqrt_28 = None
    decoder_block_5_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "5").layer, "0").layer_norm.weight
    getattr_93 = decoder_block_5_layer_0_layer_norm_weight.dtype
    eq_64 = getattr_93 == torch.float16;  getattr_93 = None
    getattr_94 = decoder_block_5_layer_0_layer_norm_weight.dtype
    to_64 = mul_63.to(getattr_94);  mul_63 = getattr_94 = None
    mul_64 = decoder_block_5_layer_0_layer_norm_weight * to_64;  decoder_block_5_layer_0_layer_norm_weight = to_64 = None
    size_33 = mul_64.size()
    getitem_84 = size_33[slice(None, 2, None)];  size_33 = None
    getitem_85 = getitem_84[0]
    getitem_86 = getitem_84[1];  getitem_84 = None
    decoder_block_5_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.q(mul_64)
    view_66 = decoder_block_5_layer_0_self_attention_q.view(getitem_85, -1, 8, 64);  decoder_block_5_layer_0_self_attention_q = None
    transpose_80 = view_66.transpose(1, 2);  view_66 = None
    decoder_block_5_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.k(mul_64)
    view_67 = decoder_block_5_layer_0_self_attention_k.view(getitem_85, -1, 8, 64);  decoder_block_5_layer_0_self_attention_k = None
    transpose_81 = view_67.transpose(1, 2);  view_67 = None
    decoder_block_5_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.v(mul_64);  mul_64 = None
    view_68 = decoder_block_5_layer_0_self_attention_v.view(getitem_85, -1, 8, 64);  decoder_block_5_layer_0_self_attention_v = None
    transpose_82 = view_68.transpose(1, 2);  view_68 = None
    transpose_83 = transpose_81.transpose(3, 2)
    matmul_32 = torch.matmul(transpose_80, transpose_83);  transpose_80 = transpose_83 = None
    add_81 = matmul_32 + add_39;  matmul_32 = add_39 = None
    float_19 = add_81.float()
    softmax_16 = torch.nn.functional.softmax(float_19, dim = -1, _stacklevel = 3, dtype = None);  float_19 = None
    type_as_16 = softmax_16.type_as(add_81);  softmax_16 = add_81 = None
    dropout_16 = torch.nn.functional.dropout(type_as_16, p = 0.1, training = False, inplace = False);  type_as_16 = None
    matmul_33 = torch.matmul(dropout_16, transpose_82);  dropout_16 = None
    transpose_84 = matmul_33.transpose(1, 2);  matmul_33 = None
    contiguous_16 = transpose_84.contiguous();  transpose_84 = None
    view_69 = contiguous_16.view(getitem_85, -1, 512);  contiguous_16 = getitem_85 = None
    decoder_block_5_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.o(view_69);  view_69 = None
    decoder_block_5_layer_0_dropout = getattr(getattr(self.decoder.block, "5").layer, "0").dropout(decoder_block_5_layer_0_self_attention_o);  decoder_block_5_layer_0_self_attention_o = None
    add_82 = add_79 + decoder_block_5_layer_0_dropout;  add_79 = decoder_block_5_layer_0_dropout = None
    getattr_95 = add_82.dtype
    eq_65 = getattr_95 == torch.float16;  getattr_95 = None
    size_34 = transpose_81.size()
    getitem_87 = size_34[2];  size_34 = None
    to_65 = add_82.to(torch.float32)
    pow_30 = to_65.pow(2);  to_65 = None
    mean_29 = pow_30.mean(-1, keepdim = True);  pow_30 = None
    add_83 = mean_29 + 1e-06;  mean_29 = None
    rsqrt_29 = torch.rsqrt(add_83);  add_83 = None
    mul_65 = add_82 * rsqrt_29;  rsqrt_29 = None
    decoder_block_5_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "5").layer, "1").layer_norm.weight
    getattr_96 = decoder_block_5_layer_1_layer_norm_weight.dtype
    eq_66 = getattr_96 == torch.float16;  getattr_96 = None
    getattr_97 = decoder_block_5_layer_1_layer_norm_weight.dtype
    to_66 = mul_65.to(getattr_97);  mul_65 = getattr_97 = None
    mul_66 = decoder_block_5_layer_1_layer_norm_weight * to_66;  decoder_block_5_layer_1_layer_norm_weight = to_66 = None
    size_35 = mul_66.size()
    getitem_88 = size_35[slice(None, 2, None)];  size_35 = None
    getitem_89 = getitem_88[0]
    getitem_90 = getitem_88[1];  getitem_88 = None
    size_36 = encoder_dropout_1.size()
    getitem_91 = size_36[1];  size_36 = None
    decoder_block_5_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.q(mul_66);  mul_66 = None
    view_70 = decoder_block_5_layer_1_enc_dec_attention_q.view(getitem_89, -1, 8, 64);  decoder_block_5_layer_1_enc_dec_attention_q = None
    transpose_85 = view_70.transpose(1, 2);  view_70 = None
    decoder_block_5_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_71 = decoder_block_5_layer_1_enc_dec_attention_k.view(getitem_89, -1, 8, 64);  decoder_block_5_layer_1_enc_dec_attention_k = None
    transpose_86 = view_71.transpose(1, 2);  view_71 = None
    decoder_block_5_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_72 = decoder_block_5_layer_1_enc_dec_attention_v.view(getitem_89, -1, 8, 64);  decoder_block_5_layer_1_enc_dec_attention_v = None
    transpose_87 = view_72.transpose(1, 2);  view_72 = None
    transpose_88 = transpose_86.transpose(3, 2)
    matmul_34 = torch.matmul(transpose_85, transpose_88);  transpose_85 = transpose_88 = None
    add_84 = matmul_34 + add_43;  matmul_34 = add_43 = None
    float_20 = add_84.float()
    softmax_17 = torch.nn.functional.softmax(float_20, dim = -1, _stacklevel = 3, dtype = None);  float_20 = None
    type_as_17 = softmax_17.type_as(add_84);  softmax_17 = add_84 = None
    dropout_17 = torch.nn.functional.dropout(type_as_17, p = 0.1, training = False, inplace = False);  type_as_17 = None
    matmul_35 = torch.matmul(dropout_17, transpose_87);  dropout_17 = None
    transpose_89 = matmul_35.transpose(1, 2);  matmul_35 = None
    contiguous_17 = transpose_89.contiguous();  transpose_89 = None
    view_73 = contiguous_17.view(getitem_89, -1, 512);  contiguous_17 = getitem_89 = None
    decoder_block_5_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.o(view_73);  view_73 = None
    decoder_block_5_layer_1_dropout = getattr(getattr(self.decoder.block, "5").layer, "1").dropout(decoder_block_5_layer_1_enc_dec_attention_o);  decoder_block_5_layer_1_enc_dec_attention_o = None
    add_85 = add_82 + decoder_block_5_layer_1_dropout;  add_82 = decoder_block_5_layer_1_dropout = None
    getattr_98 = add_85.dtype
    eq_67 = getattr_98 == torch.float16;  getattr_98 = None
    to_67 = add_85.to(torch.float32)
    pow_31 = to_67.pow(2);  to_67 = None
    mean_30 = pow_31.mean(-1, keepdim = True);  pow_31 = None
    add_86 = mean_30 + 1e-06;  mean_30 = None
    rsqrt_30 = torch.rsqrt(add_86);  add_86 = None
    mul_67 = add_85 * rsqrt_30;  rsqrt_30 = None
    decoder_block_5_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "5").layer, "2").layer_norm.weight
    getattr_99 = decoder_block_5_layer_2_layer_norm_weight.dtype
    eq_68 = getattr_99 == torch.float16;  getattr_99 = None
    getattr_100 = decoder_block_5_layer_2_layer_norm_weight.dtype
    to_68 = mul_67.to(getattr_100);  mul_67 = getattr_100 = None
    mul_68 = decoder_block_5_layer_2_layer_norm_weight * to_68;  decoder_block_5_layer_2_layer_norm_weight = to_68 = None
    decoder_block_5_layer_2_dense_relu_dense_wi = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.wi(mul_68);  mul_68 = None
    decoder_block_5_layer_2_dense_relu_dense_act = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.act(decoder_block_5_layer_2_dense_relu_dense_wi);  decoder_block_5_layer_2_dense_relu_dense_wi = None
    decoder_block_5_layer_2_dense_relu_dense_dropout = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.dropout(decoder_block_5_layer_2_dense_relu_dense_act);  decoder_block_5_layer_2_dense_relu_dense_act = None
    decoder_block_5_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.wo.weight
    decoder_block_5_layer_2_dense_relu_dense_wo = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.wo(decoder_block_5_layer_2_dense_relu_dense_dropout);  decoder_block_5_layer_2_dense_relu_dense_dropout = None
    decoder_block_5_layer_2_dropout = getattr(getattr(self.decoder.block, "5").layer, "2").dropout(decoder_block_5_layer_2_dense_relu_dense_wo);  decoder_block_5_layer_2_dense_relu_dense_wo = None
    add_87 = add_85 + decoder_block_5_layer_2_dropout;  add_85 = decoder_block_5_layer_2_dropout = None
    getattr_101 = add_87.dtype
    eq_69 = getattr_101 == torch.float16;  getattr_101 = None
    to_69 = add_87.to(torch.float32)
    pow_32 = to_69.pow(2);  to_69 = None
    mean_31 = pow_32.mean(-1, keepdim = True);  pow_32 = None
    add_88 = mean_31 + 1e-06;  mean_31 = None
    rsqrt_31 = torch.rsqrt(add_88);  add_88 = None
    mul_69 = add_87 * rsqrt_31;  add_87 = rsqrt_31 = None
    decoder_final_layer_norm_weight = self.decoder.final_layer_norm.weight
    getattr_102 = decoder_final_layer_norm_weight.dtype
    eq_70 = getattr_102 == torch.float16;  getattr_102 = None
    getattr_103 = decoder_final_layer_norm_weight.dtype
    to_70 = mul_69.to(getattr_103);  mul_69 = getattr_103 = None
    mul_70 = decoder_final_layer_norm_weight * to_70;  decoder_final_layer_norm_weight = to_70 = None
    decoder_dropout_1 = self.decoder.dropout(mul_70);  mul_70 = None
    mul_71 = decoder_dropout_1 * 0.04419417382415922;  decoder_dropout_1 = None
    lm_head = self.lm_head(mul_71);  mul_71 = None
    getattr_104 = lm_head.device
    to_71 = labels.to(getattr_104);  labels = getattr_104 = None
    size_37 = lm_head.size(-1)
    view_74 = lm_head.view(-1, size_37);  size_37 = None
    view_75 = to_71.view(-1);  to_71 = None
    crossentropyloss_0 = self.crossentropyloss_0(view_74, view_75);  view_74 = view_75 = None
    return {'loss': crossentropyloss_0, 'logits': lm_head, 'past_key_values': ((transpose_31, transpose_32, transpose_36, transpose_37), (transpose_41, transpose_42, transpose_46, transpose_47), (transpose_51, transpose_52, transpose_56, transpose_57), (transpose_61, transpose_62, transpose_66, transpose_67), (transpose_71, transpose_72, transpose_76, transpose_77), (transpose_81, transpose_82, transpose_86, transpose_87)), 'encoder_last_hidden_state': encoder_dropout_1}
    
********************************************************************************************************************************************************************************************************

torch.fx._symbolic_trace.wrap("src_patch_linear_layer_linear_layer_triton_wrapper")

def forward(self, input_ids : torch.Tensor, labels : torch.Tensor):
    size = input_ids.size()
    getitem = size[-1]
    view = input_ids.view(-1, getitem);  input_ids = getitem = None
    shared = self.shared(view);  view = None
    getitem_1 = size[0]
    getitem_2 = size[1];  size = None
    getattr_1 = shared.device
    ones = torch.ones(getitem_1, getitem_2, device = getattr_1);  getitem_1 = getitem_2 = getattr_1 = None
    dim = ones.dim()
    eq = dim == 2;  dim = None
    dim_1 = ones.dim()
    eq_1 = dim_1 == 3;  dim_1 = None
    dim_2 = ones.dim()
    eq_2 = dim_2 == 2;  dim_2 = None
    getitem_3 = ones[(slice(None, None, None), None, None, slice(None, None, None))];  ones = None
    to = getitem_3.to(dtype = torch.float16);  getitem_3 = None
    sub = 1.0 - to;  to = None
    mul = sub * -65504.0;  sub = None
    encoder_dropout = self.encoder.dropout(shared);  shared = None
    to_1 = encoder_dropout.to(torch.float32)
    pow_1 = to_1.pow(2);  to_1 = None
    mean = pow_1.mean(-1, keepdim = True);  pow_1 = None
    add = mean + 1e-06;  mean = None
    rsqrt = torch.rsqrt(add);  add = None
    mul_1 = encoder_dropout * rsqrt;  rsqrt = None
    encoder_block_0_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "0").layer, "0").layer_norm.weight
    getattr_2 = encoder_block_0_layer_0_layer_norm_weight.dtype
    eq_3 = getattr_2 == torch.float16;  getattr_2 = None
    getattr_3 = encoder_block_0_layer_0_layer_norm_weight.dtype
    to_2 = mul_1.to(getattr_3);  mul_1 = getattr_3 = None
    mul_2 = encoder_block_0_layer_0_layer_norm_weight * to_2;  encoder_block_0_layer_0_layer_norm_weight = to_2 = None
    size_1 = mul_2.size()
    getitem_4 = size_1[slice(None, 2, None)];  size_1 = None
    getitem_5 = getitem_4[0]
    getitem_6 = getitem_4[1];  getitem_4 = None
    encoder_block_0_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.q(mul_2)
    view_1 = encoder_block_0_layer_0_self_attention_q.view(getitem_5, -1, 8, 64);  encoder_block_0_layer_0_self_attention_q = None
    transpose = view_1.transpose(1, 2);  view_1 = None
    encoder_block_0_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.k(mul_2)
    view_2 = encoder_block_0_layer_0_self_attention_k.view(getitem_5, -1, 8, 64);  encoder_block_0_layer_0_self_attention_k = None
    transpose_1 = view_2.transpose(1, 2);  view_2 = None
    encoder_block_0_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.v(mul_2);  mul_2 = None
    view_3 = encoder_block_0_layer_0_self_attention_v.view(getitem_5, -1, 8, 64);  encoder_block_0_layer_0_self_attention_v = None
    transpose_2 = view_3.transpose(1, 2);  view_3 = None
    transpose_3 = transpose_1.transpose(3, 2);  transpose_1 = None
    matmul = torch.matmul(transpose, transpose_3);  transpose = transpose_3 = None
    getattr_4 = matmul.device
    arange = torch.arange(getitem_6, dtype = torch.int64, device = getattr_4)
    getitem_7 = arange[(slice(None, None, None), None)];  arange = None
    arange_1 = torch.arange(getitem_6, dtype = torch.int64, device = getattr_4);  getitem_6 = getattr_4 = None
    getitem_8 = arange_1[(None, slice(None, None, None))];  arange_1 = None
    sub_1 = getitem_8 - getitem_7;  getitem_8 = getitem_7 = None
    gt = sub_1 > 0
    to_3 = gt.to(torch.int64);  gt = None
    mul_3 = to_3 * 16;  to_3 = None
    add_1 = 0 + mul_3;  mul_3 = None
    abs_1 = torch.abs(sub_1);  sub_1 = None
    lt = abs_1 < 8
    float_1 = abs_1.float()
    truediv = float_1 / 8;  float_1 = None
    log = torch.log(truediv);  truediv = None
    truediv_1 = log / 2.772588722239781;  log = None
    mul_4 = truediv_1 * 8;  truediv_1 = None
    to_4 = mul_4.to(torch.int64);  mul_4 = None
    add_2 = 8 + to_4;  to_4 = None
    full_like = torch.full_like(add_2, 15)
    min_1 = torch.min(add_2, full_like);  add_2 = full_like = None
    where = torch.where(lt, abs_1, min_1);  lt = abs_1 = min_1 = None
    add_3 = add_1 + where;  add_1 = where = None
    encoder_block_0_layer_0_self_attention_relative_attention_bias = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.relative_attention_bias(add_3);  add_3 = None
    permute = encoder_block_0_layer_0_self_attention_relative_attention_bias.permute([2, 0, 1]);  encoder_block_0_layer_0_self_attention_relative_attention_bias = None
    unsqueeze = permute.unsqueeze(0);  permute = None
    add_4 = unsqueeze + mul;  unsqueeze = mul = None
    add_5 = matmul + add_4;  matmul = None
    float_2 = add_5.float()
    softmax = torch.nn.functional.softmax(float_2, dim = -1, _stacklevel = 3, dtype = None);  float_2 = None
    type_as = softmax.type_as(add_5);  softmax = add_5 = None
    dropout = torch.nn.functional.dropout(type_as, p = 0.1, training = False, inplace = False);  type_as = None
    matmul_1 = torch.matmul(dropout, transpose_2);  dropout = transpose_2 = None
    transpose_4 = matmul_1.transpose(1, 2);  matmul_1 = None
    contiguous = transpose_4.contiguous();  transpose_4 = None
    view_4 = contiguous.view(getitem_5, -1, 512);  contiguous = getitem_5 = None
    encoder_block_0_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "0").layer, "0").SelfAttention.o(view_4);  view_4 = None
    encoder_block_0_layer_0_dropout = getattr(getattr(self.encoder.block, "0").layer, "0").dropout(encoder_block_0_layer_0_self_attention_o);  encoder_block_0_layer_0_self_attention_o = None
    add_6 = encoder_dropout + encoder_block_0_layer_0_dropout;  encoder_dropout = encoder_block_0_layer_0_dropout = None
    getattr_5 = add_6.dtype
    eq_4 = getattr_5 == torch.float16;  getattr_5 = None
    to_5 = add_6.to(torch.float32)
    pow_2 = to_5.pow(2);  to_5 = None
    mean_1 = pow_2.mean(-1, keepdim = True);  pow_2 = None
    add_7 = mean_1 + 1e-06;  mean_1 = None
    rsqrt_1 = torch.rsqrt(add_7);  add_7 = None
    mul_5 = add_6 * rsqrt_1;  rsqrt_1 = None
    encoder_block_0_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "0").layer, "1").layer_norm.weight
    getattr_6 = encoder_block_0_layer_1_layer_norm_weight.dtype
    eq_5 = getattr_6 == torch.float16;  getattr_6 = None
    getattr_7 = encoder_block_0_layer_1_layer_norm_weight.dtype
    to_6 = mul_5.to(getattr_7);  mul_5 = getattr_7 = None
    mul_6 = encoder_block_0_layer_1_layer_norm_weight * to_6;  encoder_block_0_layer_1_layer_norm_weight = to_6 = None
    encoder_block_0_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.wo.weight
    linear1 = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.wi
    linear_layer_triton_wrapper = src_patch_linear_layer_linear_layer_triton_wrapper(mul_6, linear1, activation = 'relu');  mul_6 = linear1 = None
    dropout_18 = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.dropout(linear_layer_triton_wrapper);  linear_layer_triton_wrapper = None
    linear2 = getattr(getattr(self.encoder.block, "0").layer, "1").DenseReluDense.wo(dropout_18);  dropout_18 = None
    encoder_block_0_layer_1_dropout = getattr(getattr(self.encoder.block, "0").layer, "1").dropout(linear2);  linear2 = None
    add_8 = add_6 + encoder_block_0_layer_1_dropout;  add_6 = encoder_block_0_layer_1_dropout = None
    getattr_8 = add_8.dtype
    eq_6 = getattr_8 == torch.float16;  getattr_8 = None
    to_7 = add_8.to(torch.float32)
    pow_3 = to_7.pow(2);  to_7 = None
    mean_2 = pow_3.mean(-1, keepdim = True);  pow_3 = None
    add_9 = mean_2 + 1e-06;  mean_2 = None
    rsqrt_2 = torch.rsqrt(add_9);  add_9 = None
    mul_7 = add_8 * rsqrt_2;  rsqrt_2 = None
    encoder_block_1_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "1").layer, "0").layer_norm.weight
    getattr_9 = encoder_block_1_layer_0_layer_norm_weight.dtype
    eq_7 = getattr_9 == torch.float16;  getattr_9 = None
    getattr_10 = encoder_block_1_layer_0_layer_norm_weight.dtype
    to_8 = mul_7.to(getattr_10);  mul_7 = getattr_10 = None
    mul_8 = encoder_block_1_layer_0_layer_norm_weight * to_8;  encoder_block_1_layer_0_layer_norm_weight = to_8 = None
    size_2 = mul_8.size()
    getitem_9 = size_2[slice(None, 2, None)];  size_2 = None
    getitem_10 = getitem_9[0]
    getitem_11 = getitem_9[1];  getitem_9 = None
    encoder_block_1_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.q(mul_8)
    view_5 = encoder_block_1_layer_0_self_attention_q.view(getitem_10, -1, 8, 64);  encoder_block_1_layer_0_self_attention_q = None
    transpose_5 = view_5.transpose(1, 2);  view_5 = None
    encoder_block_1_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.k(mul_8)
    view_6 = encoder_block_1_layer_0_self_attention_k.view(getitem_10, -1, 8, 64);  encoder_block_1_layer_0_self_attention_k = None
    transpose_6 = view_6.transpose(1, 2);  view_6 = None
    encoder_block_1_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.v(mul_8);  mul_8 = None
    view_7 = encoder_block_1_layer_0_self_attention_v.view(getitem_10, -1, 8, 64);  encoder_block_1_layer_0_self_attention_v = None
    transpose_7 = view_7.transpose(1, 2);  view_7 = None
    transpose_8 = transpose_6.transpose(3, 2);  transpose_6 = None
    matmul_2 = torch.matmul(transpose_5, transpose_8);  transpose_5 = transpose_8 = None
    add_10 = matmul_2 + add_4;  matmul_2 = None
    float_3 = add_10.float()
    softmax_1 = torch.nn.functional.softmax(float_3, dim = -1, _stacklevel = 3, dtype = None);  float_3 = None
    type_as_1 = softmax_1.type_as(add_10);  softmax_1 = add_10 = None
    dropout_1 = torch.nn.functional.dropout(type_as_1, p = 0.1, training = False, inplace = False);  type_as_1 = None
    matmul_3 = torch.matmul(dropout_1, transpose_7);  dropout_1 = transpose_7 = None
    transpose_9 = matmul_3.transpose(1, 2);  matmul_3 = None
    contiguous_1 = transpose_9.contiguous();  transpose_9 = None
    view_8 = contiguous_1.view(getitem_10, -1, 512);  contiguous_1 = getitem_10 = None
    encoder_block_1_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "1").layer, "0").SelfAttention.o(view_8);  view_8 = None
    encoder_block_1_layer_0_dropout = getattr(getattr(self.encoder.block, "1").layer, "0").dropout(encoder_block_1_layer_0_self_attention_o);  encoder_block_1_layer_0_self_attention_o = None
    add_11 = add_8 + encoder_block_1_layer_0_dropout;  add_8 = encoder_block_1_layer_0_dropout = None
    getattr_11 = add_11.dtype
    eq_8 = getattr_11 == torch.float16;  getattr_11 = None
    to_9 = add_11.to(torch.float32)
    pow_4 = to_9.pow(2);  to_9 = None
    mean_3 = pow_4.mean(-1, keepdim = True);  pow_4 = None
    add_12 = mean_3 + 1e-06;  mean_3 = None
    rsqrt_3 = torch.rsqrt(add_12);  add_12 = None
    mul_9 = add_11 * rsqrt_3;  rsqrt_3 = None
    encoder_block_1_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "1").layer, "1").layer_norm.weight
    getattr_12 = encoder_block_1_layer_1_layer_norm_weight.dtype
    eq_9 = getattr_12 == torch.float16;  getattr_12 = None
    getattr_13 = encoder_block_1_layer_1_layer_norm_weight.dtype
    to_10 = mul_9.to(getattr_13);  mul_9 = getattr_13 = None
    mul_10 = encoder_block_1_layer_1_layer_norm_weight * to_10;  encoder_block_1_layer_1_layer_norm_weight = to_10 = None
    encoder_block_1_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.wo.weight
    linear1_1 = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.wi
    linear_layer_triton_wrapper_1 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_10, linear1_1, activation = 'relu');  mul_10 = linear1_1 = None
    dropout_19 = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.dropout(linear_layer_triton_wrapper_1);  linear_layer_triton_wrapper_1 = None
    linear2_1 = getattr(getattr(self.encoder.block, "1").layer, "1").DenseReluDense.wo(dropout_19);  dropout_19 = None
    encoder_block_1_layer_1_dropout = getattr(getattr(self.encoder.block, "1").layer, "1").dropout(linear2_1);  linear2_1 = None
    add_13 = add_11 + encoder_block_1_layer_1_dropout;  add_11 = encoder_block_1_layer_1_dropout = None
    getattr_14 = add_13.dtype
    eq_10 = getattr_14 == torch.float16;  getattr_14 = None
    to_11 = add_13.to(torch.float32)
    pow_5 = to_11.pow(2);  to_11 = None
    mean_4 = pow_5.mean(-1, keepdim = True);  pow_5 = None
    add_14 = mean_4 + 1e-06;  mean_4 = None
    rsqrt_4 = torch.rsqrt(add_14);  add_14 = None
    mul_11 = add_13 * rsqrt_4;  rsqrt_4 = None
    encoder_block_2_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "2").layer, "0").layer_norm.weight
    getattr_15 = encoder_block_2_layer_0_layer_norm_weight.dtype
    eq_11 = getattr_15 == torch.float16;  getattr_15 = None
    getattr_16 = encoder_block_2_layer_0_layer_norm_weight.dtype
    to_12 = mul_11.to(getattr_16);  mul_11 = getattr_16 = None
    mul_12 = encoder_block_2_layer_0_layer_norm_weight * to_12;  encoder_block_2_layer_0_layer_norm_weight = to_12 = None
    size_3 = mul_12.size()
    getitem_12 = size_3[slice(None, 2, None)];  size_3 = None
    getitem_13 = getitem_12[0]
    getitem_14 = getitem_12[1];  getitem_12 = None
    encoder_block_2_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.q(mul_12)
    view_9 = encoder_block_2_layer_0_self_attention_q.view(getitem_13, -1, 8, 64);  encoder_block_2_layer_0_self_attention_q = None
    transpose_10 = view_9.transpose(1, 2);  view_9 = None
    encoder_block_2_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.k(mul_12)
    view_10 = encoder_block_2_layer_0_self_attention_k.view(getitem_13, -1, 8, 64);  encoder_block_2_layer_0_self_attention_k = None
    transpose_11 = view_10.transpose(1, 2);  view_10 = None
    encoder_block_2_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.v(mul_12);  mul_12 = None
    view_11 = encoder_block_2_layer_0_self_attention_v.view(getitem_13, -1, 8, 64);  encoder_block_2_layer_0_self_attention_v = None
    transpose_12 = view_11.transpose(1, 2);  view_11 = None
    transpose_13 = transpose_11.transpose(3, 2);  transpose_11 = None
    matmul_4 = torch.matmul(transpose_10, transpose_13);  transpose_10 = transpose_13 = None
    add_15 = matmul_4 + add_4;  matmul_4 = None
    float_4 = add_15.float()
    softmax_2 = torch.nn.functional.softmax(float_4, dim = -1, _stacklevel = 3, dtype = None);  float_4 = None
    type_as_2 = softmax_2.type_as(add_15);  softmax_2 = add_15 = None
    dropout_2 = torch.nn.functional.dropout(type_as_2, p = 0.1, training = False, inplace = False);  type_as_2 = None
    matmul_5 = torch.matmul(dropout_2, transpose_12);  dropout_2 = transpose_12 = None
    transpose_14 = matmul_5.transpose(1, 2);  matmul_5 = None
    contiguous_2 = transpose_14.contiguous();  transpose_14 = None
    view_12 = contiguous_2.view(getitem_13, -1, 512);  contiguous_2 = getitem_13 = None
    encoder_block_2_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "2").layer, "0").SelfAttention.o(view_12);  view_12 = None
    encoder_block_2_layer_0_dropout = getattr(getattr(self.encoder.block, "2").layer, "0").dropout(encoder_block_2_layer_0_self_attention_o);  encoder_block_2_layer_0_self_attention_o = None
    add_16 = add_13 + encoder_block_2_layer_0_dropout;  add_13 = encoder_block_2_layer_0_dropout = None
    getattr_17 = add_16.dtype
    eq_12 = getattr_17 == torch.float16;  getattr_17 = None
    to_13 = add_16.to(torch.float32)
    pow_6 = to_13.pow(2);  to_13 = None
    mean_5 = pow_6.mean(-1, keepdim = True);  pow_6 = None
    add_17 = mean_5 + 1e-06;  mean_5 = None
    rsqrt_5 = torch.rsqrt(add_17);  add_17 = None
    mul_13 = add_16 * rsqrt_5;  rsqrt_5 = None
    encoder_block_2_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "2").layer, "1").layer_norm.weight
    getattr_18 = encoder_block_2_layer_1_layer_norm_weight.dtype
    eq_13 = getattr_18 == torch.float16;  getattr_18 = None
    getattr_19 = encoder_block_2_layer_1_layer_norm_weight.dtype
    to_14 = mul_13.to(getattr_19);  mul_13 = getattr_19 = None
    mul_14 = encoder_block_2_layer_1_layer_norm_weight * to_14;  encoder_block_2_layer_1_layer_norm_weight = to_14 = None
    encoder_block_2_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.wo.weight
    linear1_2 = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.wi
    linear_layer_triton_wrapper_2 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_14, linear1_2, activation = 'relu');  mul_14 = linear1_2 = None
    dropout_20 = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.dropout(linear_layer_triton_wrapper_2);  linear_layer_triton_wrapper_2 = None
    linear2_2 = getattr(getattr(self.encoder.block, "2").layer, "1").DenseReluDense.wo(dropout_20);  dropout_20 = None
    encoder_block_2_layer_1_dropout = getattr(getattr(self.encoder.block, "2").layer, "1").dropout(linear2_2);  linear2_2 = None
    add_18 = add_16 + encoder_block_2_layer_1_dropout;  add_16 = encoder_block_2_layer_1_dropout = None
    getattr_20 = add_18.dtype
    eq_14 = getattr_20 == torch.float16;  getattr_20 = None
    to_15 = add_18.to(torch.float32)
    pow_7 = to_15.pow(2);  to_15 = None
    mean_6 = pow_7.mean(-1, keepdim = True);  pow_7 = None
    add_19 = mean_6 + 1e-06;  mean_6 = None
    rsqrt_6 = torch.rsqrt(add_19);  add_19 = None
    mul_15 = add_18 * rsqrt_6;  rsqrt_6 = None
    encoder_block_3_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "3").layer, "0").layer_norm.weight
    getattr_21 = encoder_block_3_layer_0_layer_norm_weight.dtype
    eq_15 = getattr_21 == torch.float16;  getattr_21 = None
    getattr_22 = encoder_block_3_layer_0_layer_norm_weight.dtype
    to_16 = mul_15.to(getattr_22);  mul_15 = getattr_22 = None
    mul_16 = encoder_block_3_layer_0_layer_norm_weight * to_16;  encoder_block_3_layer_0_layer_norm_weight = to_16 = None
    size_4 = mul_16.size()
    getitem_15 = size_4[slice(None, 2, None)];  size_4 = None
    getitem_16 = getitem_15[0]
    getitem_17 = getitem_15[1];  getitem_15 = None
    encoder_block_3_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.q(mul_16)
    view_13 = encoder_block_3_layer_0_self_attention_q.view(getitem_16, -1, 8, 64);  encoder_block_3_layer_0_self_attention_q = None
    transpose_15 = view_13.transpose(1, 2);  view_13 = None
    encoder_block_3_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.k(mul_16)
    view_14 = encoder_block_3_layer_0_self_attention_k.view(getitem_16, -1, 8, 64);  encoder_block_3_layer_0_self_attention_k = None
    transpose_16 = view_14.transpose(1, 2);  view_14 = None
    encoder_block_3_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.v(mul_16);  mul_16 = None
    view_15 = encoder_block_3_layer_0_self_attention_v.view(getitem_16, -1, 8, 64);  encoder_block_3_layer_0_self_attention_v = None
    transpose_17 = view_15.transpose(1, 2);  view_15 = None
    transpose_18 = transpose_16.transpose(3, 2);  transpose_16 = None
    matmul_6 = torch.matmul(transpose_15, transpose_18);  transpose_15 = transpose_18 = None
    add_20 = matmul_6 + add_4;  matmul_6 = None
    float_5 = add_20.float()
    softmax_3 = torch.nn.functional.softmax(float_5, dim = -1, _stacklevel = 3, dtype = None);  float_5 = None
    type_as_3 = softmax_3.type_as(add_20);  softmax_3 = add_20 = None
    dropout_3 = torch.nn.functional.dropout(type_as_3, p = 0.1, training = False, inplace = False);  type_as_3 = None
    matmul_7 = torch.matmul(dropout_3, transpose_17);  dropout_3 = transpose_17 = None
    transpose_19 = matmul_7.transpose(1, 2);  matmul_7 = None
    contiguous_3 = transpose_19.contiguous();  transpose_19 = None
    view_16 = contiguous_3.view(getitem_16, -1, 512);  contiguous_3 = getitem_16 = None
    encoder_block_3_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "3").layer, "0").SelfAttention.o(view_16);  view_16 = None
    encoder_block_3_layer_0_dropout = getattr(getattr(self.encoder.block, "3").layer, "0").dropout(encoder_block_3_layer_0_self_attention_o);  encoder_block_3_layer_0_self_attention_o = None
    add_21 = add_18 + encoder_block_3_layer_0_dropout;  add_18 = encoder_block_3_layer_0_dropout = None
    getattr_23 = add_21.dtype
    eq_16 = getattr_23 == torch.float16;  getattr_23 = None
    to_17 = add_21.to(torch.float32)
    pow_8 = to_17.pow(2);  to_17 = None
    mean_7 = pow_8.mean(-1, keepdim = True);  pow_8 = None
    add_22 = mean_7 + 1e-06;  mean_7 = None
    rsqrt_7 = torch.rsqrt(add_22);  add_22 = None
    mul_17 = add_21 * rsqrt_7;  rsqrt_7 = None
    encoder_block_3_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "3").layer, "1").layer_norm.weight
    getattr_24 = encoder_block_3_layer_1_layer_norm_weight.dtype
    eq_17 = getattr_24 == torch.float16;  getattr_24 = None
    getattr_25 = encoder_block_3_layer_1_layer_norm_weight.dtype
    to_18 = mul_17.to(getattr_25);  mul_17 = getattr_25 = None
    mul_18 = encoder_block_3_layer_1_layer_norm_weight * to_18;  encoder_block_3_layer_1_layer_norm_weight = to_18 = None
    encoder_block_3_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.wo.weight
    linear1_3 = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.wi
    linear_layer_triton_wrapper_3 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_18, linear1_3, activation = 'relu');  mul_18 = linear1_3 = None
    dropout_21 = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.dropout(linear_layer_triton_wrapper_3);  linear_layer_triton_wrapper_3 = None
    linear2_3 = getattr(getattr(self.encoder.block, "3").layer, "1").DenseReluDense.wo(dropout_21);  dropout_21 = None
    encoder_block_3_layer_1_dropout = getattr(getattr(self.encoder.block, "3").layer, "1").dropout(linear2_3);  linear2_3 = None
    add_23 = add_21 + encoder_block_3_layer_1_dropout;  add_21 = encoder_block_3_layer_1_dropout = None
    getattr_26 = add_23.dtype
    eq_18 = getattr_26 == torch.float16;  getattr_26 = None
    to_19 = add_23.to(torch.float32)
    pow_9 = to_19.pow(2);  to_19 = None
    mean_8 = pow_9.mean(-1, keepdim = True);  pow_9 = None
    add_24 = mean_8 + 1e-06;  mean_8 = None
    rsqrt_8 = torch.rsqrt(add_24);  add_24 = None
    mul_19 = add_23 * rsqrt_8;  rsqrt_8 = None
    encoder_block_4_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "4").layer, "0").layer_norm.weight
    getattr_27 = encoder_block_4_layer_0_layer_norm_weight.dtype
    eq_19 = getattr_27 == torch.float16;  getattr_27 = None
    getattr_28 = encoder_block_4_layer_0_layer_norm_weight.dtype
    to_20 = mul_19.to(getattr_28);  mul_19 = getattr_28 = None
    mul_20 = encoder_block_4_layer_0_layer_norm_weight * to_20;  encoder_block_4_layer_0_layer_norm_weight = to_20 = None
    size_5 = mul_20.size()
    getitem_18 = size_5[slice(None, 2, None)];  size_5 = None
    getitem_19 = getitem_18[0]
    getitem_20 = getitem_18[1];  getitem_18 = None
    encoder_block_4_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.q(mul_20)
    view_17 = encoder_block_4_layer_0_self_attention_q.view(getitem_19, -1, 8, 64);  encoder_block_4_layer_0_self_attention_q = None
    transpose_20 = view_17.transpose(1, 2);  view_17 = None
    encoder_block_4_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.k(mul_20)
    view_18 = encoder_block_4_layer_0_self_attention_k.view(getitem_19, -1, 8, 64);  encoder_block_4_layer_0_self_attention_k = None
    transpose_21 = view_18.transpose(1, 2);  view_18 = None
    encoder_block_4_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.v(mul_20);  mul_20 = None
    view_19 = encoder_block_4_layer_0_self_attention_v.view(getitem_19, -1, 8, 64);  encoder_block_4_layer_0_self_attention_v = None
    transpose_22 = view_19.transpose(1, 2);  view_19 = None
    transpose_23 = transpose_21.transpose(3, 2);  transpose_21 = None
    matmul_8 = torch.matmul(transpose_20, transpose_23);  transpose_20 = transpose_23 = None
    add_25 = matmul_8 + add_4;  matmul_8 = None
    float_6 = add_25.float()
    softmax_4 = torch.nn.functional.softmax(float_6, dim = -1, _stacklevel = 3, dtype = None);  float_6 = None
    type_as_4 = softmax_4.type_as(add_25);  softmax_4 = add_25 = None
    dropout_4 = torch.nn.functional.dropout(type_as_4, p = 0.1, training = False, inplace = False);  type_as_4 = None
    matmul_9 = torch.matmul(dropout_4, transpose_22);  dropout_4 = transpose_22 = None
    transpose_24 = matmul_9.transpose(1, 2);  matmul_9 = None
    contiguous_4 = transpose_24.contiguous();  transpose_24 = None
    view_20 = contiguous_4.view(getitem_19, -1, 512);  contiguous_4 = getitem_19 = None
    encoder_block_4_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "4").layer, "0").SelfAttention.o(view_20);  view_20 = None
    encoder_block_4_layer_0_dropout = getattr(getattr(self.encoder.block, "4").layer, "0").dropout(encoder_block_4_layer_0_self_attention_o);  encoder_block_4_layer_0_self_attention_o = None
    add_26 = add_23 + encoder_block_4_layer_0_dropout;  add_23 = encoder_block_4_layer_0_dropout = None
    getattr_29 = add_26.dtype
    eq_20 = getattr_29 == torch.float16;  getattr_29 = None
    to_21 = add_26.to(torch.float32)
    pow_10 = to_21.pow(2);  to_21 = None
    mean_9 = pow_10.mean(-1, keepdim = True);  pow_10 = None
    add_27 = mean_9 + 1e-06;  mean_9 = None
    rsqrt_9 = torch.rsqrt(add_27);  add_27 = None
    mul_21 = add_26 * rsqrt_9;  rsqrt_9 = None
    encoder_block_4_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "4").layer, "1").layer_norm.weight
    getattr_30 = encoder_block_4_layer_1_layer_norm_weight.dtype
    eq_21 = getattr_30 == torch.float16;  getattr_30 = None
    getattr_31 = encoder_block_4_layer_1_layer_norm_weight.dtype
    to_22 = mul_21.to(getattr_31);  mul_21 = getattr_31 = None
    mul_22 = encoder_block_4_layer_1_layer_norm_weight * to_22;  encoder_block_4_layer_1_layer_norm_weight = to_22 = None
    encoder_block_4_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.wo.weight
    linear1_4 = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.wi
    linear_layer_triton_wrapper_4 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_22, linear1_4, activation = 'relu');  mul_22 = linear1_4 = None
    dropout_22 = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.dropout(linear_layer_triton_wrapper_4);  linear_layer_triton_wrapper_4 = None
    linear2_4 = getattr(getattr(self.encoder.block, "4").layer, "1").DenseReluDense.wo(dropout_22);  dropout_22 = None
    encoder_block_4_layer_1_dropout = getattr(getattr(self.encoder.block, "4").layer, "1").dropout(linear2_4);  linear2_4 = None
    add_28 = add_26 + encoder_block_4_layer_1_dropout;  add_26 = encoder_block_4_layer_1_dropout = None
    getattr_32 = add_28.dtype
    eq_22 = getattr_32 == torch.float16;  getattr_32 = None
    to_23 = add_28.to(torch.float32)
    pow_11 = to_23.pow(2);  to_23 = None
    mean_10 = pow_11.mean(-1, keepdim = True);  pow_11 = None
    add_29 = mean_10 + 1e-06;  mean_10 = None
    rsqrt_10 = torch.rsqrt(add_29);  add_29 = None
    mul_23 = add_28 * rsqrt_10;  rsqrt_10 = None
    encoder_block_5_layer_0_layer_norm_weight = getattr(getattr(self.encoder.block, "5").layer, "0").layer_norm.weight
    getattr_33 = encoder_block_5_layer_0_layer_norm_weight.dtype
    eq_23 = getattr_33 == torch.float16;  getattr_33 = None
    getattr_34 = encoder_block_5_layer_0_layer_norm_weight.dtype
    to_24 = mul_23.to(getattr_34);  mul_23 = getattr_34 = None
    mul_24 = encoder_block_5_layer_0_layer_norm_weight * to_24;  encoder_block_5_layer_0_layer_norm_weight = to_24 = None
    size_6 = mul_24.size()
    getitem_21 = size_6[slice(None, 2, None)];  size_6 = None
    getitem_22 = getitem_21[0]
    getitem_23 = getitem_21[1];  getitem_21 = None
    encoder_block_5_layer_0_self_attention_q = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.q(mul_24)
    view_21 = encoder_block_5_layer_0_self_attention_q.view(getitem_22, -1, 8, 64);  encoder_block_5_layer_0_self_attention_q = None
    transpose_25 = view_21.transpose(1, 2);  view_21 = None
    encoder_block_5_layer_0_self_attention_k = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.k(mul_24)
    view_22 = encoder_block_5_layer_0_self_attention_k.view(getitem_22, -1, 8, 64);  encoder_block_5_layer_0_self_attention_k = None
    transpose_26 = view_22.transpose(1, 2);  view_22 = None
    encoder_block_5_layer_0_self_attention_v = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.v(mul_24);  mul_24 = None
    view_23 = encoder_block_5_layer_0_self_attention_v.view(getitem_22, -1, 8, 64);  encoder_block_5_layer_0_self_attention_v = None
    transpose_27 = view_23.transpose(1, 2);  view_23 = None
    transpose_28 = transpose_26.transpose(3, 2);  transpose_26 = None
    matmul_10 = torch.matmul(transpose_25, transpose_28);  transpose_25 = transpose_28 = None
    add_30 = matmul_10 + add_4;  matmul_10 = add_4 = None
    float_7 = add_30.float()
    softmax_5 = torch.nn.functional.softmax(float_7, dim = -1, _stacklevel = 3, dtype = None);  float_7 = None
    type_as_5 = softmax_5.type_as(add_30);  softmax_5 = add_30 = None
    dropout_5 = torch.nn.functional.dropout(type_as_5, p = 0.1, training = False, inplace = False);  type_as_5 = None
    matmul_11 = torch.matmul(dropout_5, transpose_27);  dropout_5 = transpose_27 = None
    transpose_29 = matmul_11.transpose(1, 2);  matmul_11 = None
    contiguous_5 = transpose_29.contiguous();  transpose_29 = None
    view_24 = contiguous_5.view(getitem_22, -1, 512);  contiguous_5 = getitem_22 = None
    encoder_block_5_layer_0_self_attention_o = getattr(getattr(self.encoder.block, "5").layer, "0").SelfAttention.o(view_24);  view_24 = None
    encoder_block_5_layer_0_dropout = getattr(getattr(self.encoder.block, "5").layer, "0").dropout(encoder_block_5_layer_0_self_attention_o);  encoder_block_5_layer_0_self_attention_o = None
    add_31 = add_28 + encoder_block_5_layer_0_dropout;  add_28 = encoder_block_5_layer_0_dropout = None
    getattr_35 = add_31.dtype
    eq_24 = getattr_35 == torch.float16;  getattr_35 = None
    to_25 = add_31.to(torch.float32)
    pow_12 = to_25.pow(2);  to_25 = None
    mean_11 = pow_12.mean(-1, keepdim = True);  pow_12 = None
    add_32 = mean_11 + 1e-06;  mean_11 = None
    rsqrt_11 = torch.rsqrt(add_32);  add_32 = None
    mul_25 = add_31 * rsqrt_11;  rsqrt_11 = None
    encoder_block_5_layer_1_layer_norm_weight = getattr(getattr(self.encoder.block, "5").layer, "1").layer_norm.weight
    getattr_36 = encoder_block_5_layer_1_layer_norm_weight.dtype
    eq_25 = getattr_36 == torch.float16;  getattr_36 = None
    getattr_37 = encoder_block_5_layer_1_layer_norm_weight.dtype
    to_26 = mul_25.to(getattr_37);  mul_25 = getattr_37 = None
    mul_26 = encoder_block_5_layer_1_layer_norm_weight * to_26;  encoder_block_5_layer_1_layer_norm_weight = to_26 = None
    encoder_block_5_layer_1_dense_relu_dense_wo_weight = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.wo.weight
    linear1_5 = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.wi
    linear_layer_triton_wrapper_5 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_26, linear1_5, activation = 'relu');  mul_26 = linear1_5 = None
    dropout_23 = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.dropout(linear_layer_triton_wrapper_5);  linear_layer_triton_wrapper_5 = None
    linear2_5 = getattr(getattr(self.encoder.block, "5").layer, "1").DenseReluDense.wo(dropout_23);  dropout_23 = None
    encoder_block_5_layer_1_dropout = getattr(getattr(self.encoder.block, "5").layer, "1").dropout(linear2_5);  linear2_5 = None
    add_33 = add_31 + encoder_block_5_layer_1_dropout;  add_31 = encoder_block_5_layer_1_dropout = None
    getattr_38 = add_33.dtype
    eq_26 = getattr_38 == torch.float16;  getattr_38 = None
    to_27 = add_33.to(torch.float32)
    pow_13 = to_27.pow(2);  to_27 = None
    mean_12 = pow_13.mean(-1, keepdim = True);  pow_13 = None
    add_34 = mean_12 + 1e-06;  mean_12 = None
    rsqrt_12 = torch.rsqrt(add_34);  add_34 = None
    mul_27 = add_33 * rsqrt_12;  add_33 = rsqrt_12 = None
    encoder_final_layer_norm_weight = self.encoder.final_layer_norm.weight
    getattr_39 = encoder_final_layer_norm_weight.dtype
    eq_27 = getattr_39 == torch.float16;  getattr_39 = None
    getattr_40 = encoder_final_layer_norm_weight.dtype
    to_28 = mul_27.to(getattr_40);  mul_27 = getattr_40 = None
    mul_28 = encoder_final_layer_norm_weight * to_28;  encoder_final_layer_norm_weight = to_28 = None
    encoder_dropout_1 = self.encoder.dropout(mul_28);  mul_28 = None
    size_7 = labels.size()
    getitem_24 = size_7[slice(None, -1, None)];  size_7 = None
    add_35 = getitem_24 + (1,);  getitem_24 = None
    full = torch.full(add_35, 0);  add_35 = None
    getitem_25 = labels[(Ellipsis, slice(None, -1, None))]
    cat = torch.cat([full, getitem_25], dim = -1);  full = getitem_25 = None
    eq_28 = cat == -100
    masked_fill_ = cat.masked_fill_(eq_28, 0);  eq_28 = None
    size_8 = cat.size()
    getitem_26 = size_8[-1]
    view_25 = cat.view(-1, getitem_26);  cat = getitem_26 = None
    shared_1 = self.shared(view_25);  view_25 = None
    getitem_27 = size_8[0]
    getitem_28 = size_8[1]
    getattr_41 = shared_1.device
    ones_1 = torch.ones(getitem_27, getitem_28, device = getattr_41);  getitem_28 = getattr_41 = None
    size_9 = encoder_dropout_1.size()
    getitem_29 = size_9[1];  size_9 = None
    getattr_42 = shared_1.device
    ones_2 = torch.ones(getitem_27, getitem_29, device = getattr_42, dtype = torch.int64);  getitem_27 = getitem_29 = getattr_42 = None
    dim_3 = ones_1.dim()
    eq_29 = dim_3 == 2;  dim_3 = None
    dim_4 = ones_1.dim()
    eq_30 = dim_4 == 3;  dim_4 = None
    dim_5 = ones_1.dim()
    eq_31 = dim_5 == 2;  dim_5 = None
    getitem_30 = size_8[0]
    getitem_31 = size_8[1];  size_8 = None
    getattr_43 = ones_1.device
    arange_2 = torch.arange(getitem_31, device = getattr_43);  getattr_43 = None
    getitem_32 = arange_2[(None, None, slice(None, None, None))]
    repeat = getitem_32.repeat(getitem_30, getitem_31, 1);  getitem_32 = getitem_30 = getitem_31 = None
    getitem_33 = arange_2[(None, slice(None, None, None), None)];  arange_2 = None
    le = repeat <= getitem_33;  repeat = getitem_33 = None
    getattr_44 = ones_1.dtype
    to_29 = le.to(getattr_44);  le = getattr_44 = None
    size_10 = to_29.size()
    getitem_34 = size_10[1];  size_10 = None
    size_11 = ones_1.size()
    getitem_35 = size_11[1];  size_11 = None
    lt_1 = getitem_34 < getitem_35;  getitem_34 = getitem_35 = None
    getitem_36 = to_29[(slice(None, None, None), None, slice(None, None, None), slice(None, None, None))];  to_29 = None
    getitem_37 = ones_1[(slice(None, None, None), None, None, slice(None, None, None))];  ones_1 = None
    mul_29 = getitem_36 * getitem_37;  getitem_36 = getitem_37 = None
    to_30 = mul_29.to(dtype = torch.float16);  mul_29 = None
    sub_2 = 1.0 - to_30;  to_30 = None
    mul_30 = sub_2 * -65504.0;  sub_2 = None
    size_12 = encoder_dropout_1.size()
    getitem_38 = size_12[0]
    getitem_39 = size_12[1]
    getitem_40 = size_12[2];  size_12 = None
    dim_6 = ones_2.dim()
    eq_32 = dim_6 == 3;  dim_6 = None
    dim_7 = ones_2.dim()
    eq_33 = dim_7 == 2;  dim_7 = None
    getitem_41 = ones_2[(slice(None, None, None), None, None, slice(None, None, None))];  ones_2 = None
    to_31 = getitem_41.to(dtype = torch.float16);  getitem_41 = None
    sub_3 = 1.0 - to_31;  to_31 = None
    mul_31 = sub_3 * -65504.0;  sub_3 = None
    decoder_dropout = self.decoder.dropout(shared_1);  shared_1 = None
    to_32 = decoder_dropout.to(torch.float32)
    pow_14 = to_32.pow(2);  to_32 = None
    mean_13 = pow_14.mean(-1, keepdim = True);  pow_14 = None
    add_36 = mean_13 + 1e-06;  mean_13 = None
    rsqrt_13 = torch.rsqrt(add_36);  add_36 = None
    mul_32 = decoder_dropout * rsqrt_13;  rsqrt_13 = None
    decoder_block_0_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "0").layer, "0").layer_norm.weight
    getattr_45 = decoder_block_0_layer_0_layer_norm_weight.dtype
    eq_34 = getattr_45 == torch.float16;  getattr_45 = None
    getattr_46 = decoder_block_0_layer_0_layer_norm_weight.dtype
    to_33 = mul_32.to(getattr_46);  mul_32 = getattr_46 = None
    mul_33 = decoder_block_0_layer_0_layer_norm_weight * to_33;  decoder_block_0_layer_0_layer_norm_weight = to_33 = None
    size_13 = mul_33.size()
    getitem_42 = size_13[slice(None, 2, None)];  size_13 = None
    getitem_43 = getitem_42[0]
    getitem_44 = getitem_42[1];  getitem_42 = None
    decoder_block_0_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.q(mul_33)
    view_26 = decoder_block_0_layer_0_self_attention_q.view(getitem_43, -1, 8, 64);  decoder_block_0_layer_0_self_attention_q = None
    transpose_30 = view_26.transpose(1, 2);  view_26 = None
    decoder_block_0_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.k(mul_33)
    view_27 = decoder_block_0_layer_0_self_attention_k.view(getitem_43, -1, 8, 64);  decoder_block_0_layer_0_self_attention_k = None
    transpose_31 = view_27.transpose(1, 2);  view_27 = None
    decoder_block_0_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.v(mul_33);  mul_33 = None
    view_28 = decoder_block_0_layer_0_self_attention_v.view(getitem_43, -1, 8, 64);  decoder_block_0_layer_0_self_attention_v = None
    transpose_32 = view_28.transpose(1, 2);  view_28 = None
    transpose_33 = transpose_31.transpose(3, 2)
    matmul_12 = torch.matmul(transpose_30, transpose_33);  transpose_30 = transpose_33 = None
    getattr_47 = matmul_12.device
    arange_3 = torch.arange(getitem_44, dtype = torch.int64, device = getattr_47)
    getitem_45 = arange_3[(slice(None, None, None), None)];  arange_3 = None
    arange_4 = torch.arange(getitem_44, dtype = torch.int64, device = getattr_47);  getitem_44 = getattr_47 = None
    getitem_46 = arange_4[(None, slice(None, None, None))];  arange_4 = None
    sub_4 = getitem_46 - getitem_45;  getitem_46 = getitem_45 = None
    zeros_like = torch.zeros_like(sub_4)
    min_2 = torch.min(sub_4, zeros_like);  sub_4 = zeros_like = None
    neg = -min_2;  min_2 = None
    lt_2 = neg < 16
    float_8 = neg.float()
    truediv_2 = float_8 / 16;  float_8 = None
    log_1 = torch.log(truediv_2);  truediv_2 = None
    truediv_3 = log_1 / 2.0794415416798357;  log_1 = None
    mul_34 = truediv_3 * 16;  truediv_3 = None
    to_34 = mul_34.to(torch.int64);  mul_34 = None
    add_37 = 16 + to_34;  to_34 = None
    full_like_1 = torch.full_like(add_37, 31)
    min_3 = torch.min(add_37, full_like_1);  add_37 = full_like_1 = None
    where_1 = torch.where(lt_2, neg, min_3);  lt_2 = neg = min_3 = None
    add_38 = 0 + where_1;  where_1 = None
    decoder_block_0_layer_0_self_attention_relative_attention_bias = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.relative_attention_bias(add_38);  add_38 = None
    permute_1 = decoder_block_0_layer_0_self_attention_relative_attention_bias.permute([2, 0, 1]);  decoder_block_0_layer_0_self_attention_relative_attention_bias = None
    unsqueeze_1 = permute_1.unsqueeze(0);  permute_1 = None
    add_39 = unsqueeze_1 + mul_30;  unsqueeze_1 = mul_30 = None
    add_40 = matmul_12 + add_39;  matmul_12 = None
    float_9 = add_40.float()
    softmax_6 = torch.nn.functional.softmax(float_9, dim = -1, _stacklevel = 3, dtype = None);  float_9 = None
    type_as_6 = softmax_6.type_as(add_40);  softmax_6 = add_40 = None
    dropout_6 = torch.nn.functional.dropout(type_as_6, p = 0.1, training = False, inplace = False);  type_as_6 = None
    matmul_13 = torch.matmul(dropout_6, transpose_32);  dropout_6 = None
    transpose_34 = matmul_13.transpose(1, 2);  matmul_13 = None
    contiguous_6 = transpose_34.contiguous();  transpose_34 = None
    view_29 = contiguous_6.view(getitem_43, -1, 512);  contiguous_6 = getitem_43 = None
    decoder_block_0_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "0").layer, "0").SelfAttention.o(view_29);  view_29 = None
    decoder_block_0_layer_0_dropout = getattr(getattr(self.decoder.block, "0").layer, "0").dropout(decoder_block_0_layer_0_self_attention_o);  decoder_block_0_layer_0_self_attention_o = None
    add_41 = decoder_dropout + decoder_block_0_layer_0_dropout;  decoder_dropout = decoder_block_0_layer_0_dropout = None
    getattr_48 = add_41.dtype
    eq_35 = getattr_48 == torch.float16;  getattr_48 = None
    size_14 = transpose_31.size()
    getitem_47 = size_14[2];  size_14 = None
    to_35 = add_41.to(torch.float32)
    pow_15 = to_35.pow(2);  to_35 = None
    mean_14 = pow_15.mean(-1, keepdim = True);  pow_15 = None
    add_42 = mean_14 + 1e-06;  mean_14 = None
    rsqrt_14 = torch.rsqrt(add_42);  add_42 = None
    mul_35 = add_41 * rsqrt_14;  rsqrt_14 = None
    decoder_block_0_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "0").layer, "1").layer_norm.weight
    getattr_49 = decoder_block_0_layer_1_layer_norm_weight.dtype
    eq_36 = getattr_49 == torch.float16;  getattr_49 = None
    getattr_50 = decoder_block_0_layer_1_layer_norm_weight.dtype
    to_36 = mul_35.to(getattr_50);  mul_35 = getattr_50 = None
    mul_36 = decoder_block_0_layer_1_layer_norm_weight * to_36;  decoder_block_0_layer_1_layer_norm_weight = to_36 = None
    size_15 = mul_36.size()
    getitem_48 = size_15[slice(None, 2, None)];  size_15 = None
    getitem_49 = getitem_48[0]
    getitem_50 = getitem_48[1];  getitem_48 = None
    size_16 = encoder_dropout_1.size()
    getitem_51 = size_16[1];  size_16 = None
    decoder_block_0_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.q(mul_36);  mul_36 = None
    view_30 = decoder_block_0_layer_1_enc_dec_attention_q.view(getitem_49, -1, 8, 64);  decoder_block_0_layer_1_enc_dec_attention_q = None
    transpose_35 = view_30.transpose(1, 2);  view_30 = None
    decoder_block_0_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_31 = decoder_block_0_layer_1_enc_dec_attention_k.view(getitem_49, -1, 8, 64);  decoder_block_0_layer_1_enc_dec_attention_k = None
    transpose_36 = view_31.transpose(1, 2);  view_31 = None
    decoder_block_0_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_32 = decoder_block_0_layer_1_enc_dec_attention_v.view(getitem_49, -1, 8, 64);  decoder_block_0_layer_1_enc_dec_attention_v = None
    transpose_37 = view_32.transpose(1, 2);  view_32 = None
    transpose_38 = transpose_36.transpose(3, 2)
    matmul_14 = torch.matmul(transpose_35, transpose_38);  transpose_35 = transpose_38 = None
    getattr_51 = matmul_14.device
    getattr_52 = matmul_14.dtype
    zeros = torch.zeros((1, 8, getitem_50, getitem_51), device = getattr_51, dtype = getattr_52);  getitem_50 = getitem_51 = getattr_51 = getattr_52 = None
    add_43 = zeros + mul_31;  zeros = mul_31 = None
    add_44 = matmul_14 + add_43;  matmul_14 = None
    float_10 = add_44.float()
    softmax_7 = torch.nn.functional.softmax(float_10, dim = -1, _stacklevel = 3, dtype = None);  float_10 = None
    type_as_7 = softmax_7.type_as(add_44);  softmax_7 = add_44 = None
    dropout_7 = torch.nn.functional.dropout(type_as_7, p = 0.1, training = False, inplace = False);  type_as_7 = None
    matmul_15 = torch.matmul(dropout_7, transpose_37);  dropout_7 = None
    transpose_39 = matmul_15.transpose(1, 2);  matmul_15 = None
    contiguous_7 = transpose_39.contiguous();  transpose_39 = None
    view_33 = contiguous_7.view(getitem_49, -1, 512);  contiguous_7 = getitem_49 = None
    decoder_block_0_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "0").layer, "1").EncDecAttention.o(view_33);  view_33 = None
    decoder_block_0_layer_1_dropout = getattr(getattr(self.decoder.block, "0").layer, "1").dropout(decoder_block_0_layer_1_enc_dec_attention_o);  decoder_block_0_layer_1_enc_dec_attention_o = None
    add_45 = add_41 + decoder_block_0_layer_1_dropout;  add_41 = decoder_block_0_layer_1_dropout = None
    getattr_53 = add_45.dtype
    eq_37 = getattr_53 == torch.float16;  getattr_53 = None
    to_37 = add_45.to(torch.float32)
    pow_16 = to_37.pow(2);  to_37 = None
    mean_15 = pow_16.mean(-1, keepdim = True);  pow_16 = None
    add_46 = mean_15 + 1e-06;  mean_15 = None
    rsqrt_15 = torch.rsqrt(add_46);  add_46 = None
    mul_37 = add_45 * rsqrt_15;  rsqrt_15 = None
    decoder_block_0_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "0").layer, "2").layer_norm.weight
    getattr_54 = decoder_block_0_layer_2_layer_norm_weight.dtype
    eq_38 = getattr_54 == torch.float16;  getattr_54 = None
    getattr_55 = decoder_block_0_layer_2_layer_norm_weight.dtype
    to_38 = mul_37.to(getattr_55);  mul_37 = getattr_55 = None
    mul_38 = decoder_block_0_layer_2_layer_norm_weight * to_38;  decoder_block_0_layer_2_layer_norm_weight = to_38 = None
    decoder_block_0_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.wo.weight
    linear1_6 = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.wi
    linear_layer_triton_wrapper_6 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_38, linear1_6, activation = 'relu');  mul_38 = linear1_6 = None
    dropout_24 = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.dropout(linear_layer_triton_wrapper_6);  linear_layer_triton_wrapper_6 = None
    linear2_6 = getattr(getattr(self.decoder.block, "0").layer, "2").DenseReluDense.wo(dropout_24);  dropout_24 = None
    decoder_block_0_layer_2_dropout = getattr(getattr(self.decoder.block, "0").layer, "2").dropout(linear2_6);  linear2_6 = None
    add_47 = add_45 + decoder_block_0_layer_2_dropout;  add_45 = decoder_block_0_layer_2_dropout = None
    getattr_56 = add_47.dtype
    eq_39 = getattr_56 == torch.float16;  getattr_56 = None
    to_39 = add_47.to(torch.float32)
    pow_17 = to_39.pow(2);  to_39 = None
    mean_16 = pow_17.mean(-1, keepdim = True);  pow_17 = None
    add_48 = mean_16 + 1e-06;  mean_16 = None
    rsqrt_16 = torch.rsqrt(add_48);  add_48 = None
    mul_39 = add_47 * rsqrt_16;  rsqrt_16 = None
    decoder_block_1_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "1").layer, "0").layer_norm.weight
    getattr_57 = decoder_block_1_layer_0_layer_norm_weight.dtype
    eq_40 = getattr_57 == torch.float16;  getattr_57 = None
    getattr_58 = decoder_block_1_layer_0_layer_norm_weight.dtype
    to_40 = mul_39.to(getattr_58);  mul_39 = getattr_58 = None
    mul_40 = decoder_block_1_layer_0_layer_norm_weight * to_40;  decoder_block_1_layer_0_layer_norm_weight = to_40 = None
    size_17 = mul_40.size()
    getitem_52 = size_17[slice(None, 2, None)];  size_17 = None
    getitem_53 = getitem_52[0]
    getitem_54 = getitem_52[1];  getitem_52 = None
    decoder_block_1_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.q(mul_40)
    view_34 = decoder_block_1_layer_0_self_attention_q.view(getitem_53, -1, 8, 64);  decoder_block_1_layer_0_self_attention_q = None
    transpose_40 = view_34.transpose(1, 2);  view_34 = None
    decoder_block_1_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.k(mul_40)
    view_35 = decoder_block_1_layer_0_self_attention_k.view(getitem_53, -1, 8, 64);  decoder_block_1_layer_0_self_attention_k = None
    transpose_41 = view_35.transpose(1, 2);  view_35 = None
    decoder_block_1_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.v(mul_40);  mul_40 = None
    view_36 = decoder_block_1_layer_0_self_attention_v.view(getitem_53, -1, 8, 64);  decoder_block_1_layer_0_self_attention_v = None
    transpose_42 = view_36.transpose(1, 2);  view_36 = None
    transpose_43 = transpose_41.transpose(3, 2)
    matmul_16 = torch.matmul(transpose_40, transpose_43);  transpose_40 = transpose_43 = None
    add_49 = matmul_16 + add_39;  matmul_16 = None
    float_11 = add_49.float()
    softmax_8 = torch.nn.functional.softmax(float_11, dim = -1, _stacklevel = 3, dtype = None);  float_11 = None
    type_as_8 = softmax_8.type_as(add_49);  softmax_8 = add_49 = None
    dropout_8 = torch.nn.functional.dropout(type_as_8, p = 0.1, training = False, inplace = False);  type_as_8 = None
    matmul_17 = torch.matmul(dropout_8, transpose_42);  dropout_8 = None
    transpose_44 = matmul_17.transpose(1, 2);  matmul_17 = None
    contiguous_8 = transpose_44.contiguous();  transpose_44 = None
    view_37 = contiguous_8.view(getitem_53, -1, 512);  contiguous_8 = getitem_53 = None
    decoder_block_1_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "1").layer, "0").SelfAttention.o(view_37);  view_37 = None
    decoder_block_1_layer_0_dropout = getattr(getattr(self.decoder.block, "1").layer, "0").dropout(decoder_block_1_layer_0_self_attention_o);  decoder_block_1_layer_0_self_attention_o = None
    add_50 = add_47 + decoder_block_1_layer_0_dropout;  add_47 = decoder_block_1_layer_0_dropout = None
    getattr_59 = add_50.dtype
    eq_41 = getattr_59 == torch.float16;  getattr_59 = None
    size_18 = transpose_41.size()
    getitem_55 = size_18[2];  size_18 = None
    to_41 = add_50.to(torch.float32)
    pow_18 = to_41.pow(2);  to_41 = None
    mean_17 = pow_18.mean(-1, keepdim = True);  pow_18 = None
    add_51 = mean_17 + 1e-06;  mean_17 = None
    rsqrt_17 = torch.rsqrt(add_51);  add_51 = None
    mul_41 = add_50 * rsqrt_17;  rsqrt_17 = None
    decoder_block_1_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "1").layer, "1").layer_norm.weight
    getattr_60 = decoder_block_1_layer_1_layer_norm_weight.dtype
    eq_42 = getattr_60 == torch.float16;  getattr_60 = None
    getattr_61 = decoder_block_1_layer_1_layer_norm_weight.dtype
    to_42 = mul_41.to(getattr_61);  mul_41 = getattr_61 = None
    mul_42 = decoder_block_1_layer_1_layer_norm_weight * to_42;  decoder_block_1_layer_1_layer_norm_weight = to_42 = None
    size_19 = mul_42.size()
    getitem_56 = size_19[slice(None, 2, None)];  size_19 = None
    getitem_57 = getitem_56[0]
    getitem_58 = getitem_56[1];  getitem_56 = None
    size_20 = encoder_dropout_1.size()
    getitem_59 = size_20[1];  size_20 = None
    decoder_block_1_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.q(mul_42);  mul_42 = None
    view_38 = decoder_block_1_layer_1_enc_dec_attention_q.view(getitem_57, -1, 8, 64);  decoder_block_1_layer_1_enc_dec_attention_q = None
    transpose_45 = view_38.transpose(1, 2);  view_38 = None
    decoder_block_1_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_39 = decoder_block_1_layer_1_enc_dec_attention_k.view(getitem_57, -1, 8, 64);  decoder_block_1_layer_1_enc_dec_attention_k = None
    transpose_46 = view_39.transpose(1, 2);  view_39 = None
    decoder_block_1_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_40 = decoder_block_1_layer_1_enc_dec_attention_v.view(getitem_57, -1, 8, 64);  decoder_block_1_layer_1_enc_dec_attention_v = None
    transpose_47 = view_40.transpose(1, 2);  view_40 = None
    transpose_48 = transpose_46.transpose(3, 2)
    matmul_18 = torch.matmul(transpose_45, transpose_48);  transpose_45 = transpose_48 = None
    add_52 = matmul_18 + add_43;  matmul_18 = None
    float_12 = add_52.float()
    softmax_9 = torch.nn.functional.softmax(float_12, dim = -1, _stacklevel = 3, dtype = None);  float_12 = None
    type_as_9 = softmax_9.type_as(add_52);  softmax_9 = add_52 = None
    dropout_9 = torch.nn.functional.dropout(type_as_9, p = 0.1, training = False, inplace = False);  type_as_9 = None
    matmul_19 = torch.matmul(dropout_9, transpose_47);  dropout_9 = None
    transpose_49 = matmul_19.transpose(1, 2);  matmul_19 = None
    contiguous_9 = transpose_49.contiguous();  transpose_49 = None
    view_41 = contiguous_9.view(getitem_57, -1, 512);  contiguous_9 = getitem_57 = None
    decoder_block_1_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "1").layer, "1").EncDecAttention.o(view_41);  view_41 = None
    decoder_block_1_layer_1_dropout = getattr(getattr(self.decoder.block, "1").layer, "1").dropout(decoder_block_1_layer_1_enc_dec_attention_o);  decoder_block_1_layer_1_enc_dec_attention_o = None
    add_53 = add_50 + decoder_block_1_layer_1_dropout;  add_50 = decoder_block_1_layer_1_dropout = None
    getattr_62 = add_53.dtype
    eq_43 = getattr_62 == torch.float16;  getattr_62 = None
    to_43 = add_53.to(torch.float32)
    pow_19 = to_43.pow(2);  to_43 = None
    mean_18 = pow_19.mean(-1, keepdim = True);  pow_19 = None
    add_54 = mean_18 + 1e-06;  mean_18 = None
    rsqrt_18 = torch.rsqrt(add_54);  add_54 = None
    mul_43 = add_53 * rsqrt_18;  rsqrt_18 = None
    decoder_block_1_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "1").layer, "2").layer_norm.weight
    getattr_63 = decoder_block_1_layer_2_layer_norm_weight.dtype
    eq_44 = getattr_63 == torch.float16;  getattr_63 = None
    getattr_64 = decoder_block_1_layer_2_layer_norm_weight.dtype
    to_44 = mul_43.to(getattr_64);  mul_43 = getattr_64 = None
    mul_44 = decoder_block_1_layer_2_layer_norm_weight * to_44;  decoder_block_1_layer_2_layer_norm_weight = to_44 = None
    decoder_block_1_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.wo.weight
    linear1_7 = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.wi
    linear_layer_triton_wrapper_7 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_44, linear1_7, activation = 'relu');  mul_44 = linear1_7 = None
    dropout_25 = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.dropout(linear_layer_triton_wrapper_7);  linear_layer_triton_wrapper_7 = None
    linear2_7 = getattr(getattr(self.decoder.block, "1").layer, "2").DenseReluDense.wo(dropout_25);  dropout_25 = None
    decoder_block_1_layer_2_dropout = getattr(getattr(self.decoder.block, "1").layer, "2").dropout(linear2_7);  linear2_7 = None
    add_55 = add_53 + decoder_block_1_layer_2_dropout;  add_53 = decoder_block_1_layer_2_dropout = None
    getattr_65 = add_55.dtype
    eq_45 = getattr_65 == torch.float16;  getattr_65 = None
    to_45 = add_55.to(torch.float32)
    pow_20 = to_45.pow(2);  to_45 = None
    mean_19 = pow_20.mean(-1, keepdim = True);  pow_20 = None
    add_56 = mean_19 + 1e-06;  mean_19 = None
    rsqrt_19 = torch.rsqrt(add_56);  add_56 = None
    mul_45 = add_55 * rsqrt_19;  rsqrt_19 = None
    decoder_block_2_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "2").layer, "0").layer_norm.weight
    getattr_66 = decoder_block_2_layer_0_layer_norm_weight.dtype
    eq_46 = getattr_66 == torch.float16;  getattr_66 = None
    getattr_67 = decoder_block_2_layer_0_layer_norm_weight.dtype
    to_46 = mul_45.to(getattr_67);  mul_45 = getattr_67 = None
    mul_46 = decoder_block_2_layer_0_layer_norm_weight * to_46;  decoder_block_2_layer_0_layer_norm_weight = to_46 = None
    size_21 = mul_46.size()
    getitem_60 = size_21[slice(None, 2, None)];  size_21 = None
    getitem_61 = getitem_60[0]
    getitem_62 = getitem_60[1];  getitem_60 = None
    decoder_block_2_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.q(mul_46)
    view_42 = decoder_block_2_layer_0_self_attention_q.view(getitem_61, -1, 8, 64);  decoder_block_2_layer_0_self_attention_q = None
    transpose_50 = view_42.transpose(1, 2);  view_42 = None
    decoder_block_2_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.k(mul_46)
    view_43 = decoder_block_2_layer_0_self_attention_k.view(getitem_61, -1, 8, 64);  decoder_block_2_layer_0_self_attention_k = None
    transpose_51 = view_43.transpose(1, 2);  view_43 = None
    decoder_block_2_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.v(mul_46);  mul_46 = None
    view_44 = decoder_block_2_layer_0_self_attention_v.view(getitem_61, -1, 8, 64);  decoder_block_2_layer_0_self_attention_v = None
    transpose_52 = view_44.transpose(1, 2);  view_44 = None
    transpose_53 = transpose_51.transpose(3, 2)
    matmul_20 = torch.matmul(transpose_50, transpose_53);  transpose_50 = transpose_53 = None
    add_57 = matmul_20 + add_39;  matmul_20 = None
    float_13 = add_57.float()
    softmax_10 = torch.nn.functional.softmax(float_13, dim = -1, _stacklevel = 3, dtype = None);  float_13 = None
    type_as_10 = softmax_10.type_as(add_57);  softmax_10 = add_57 = None
    dropout_10 = torch.nn.functional.dropout(type_as_10, p = 0.1, training = False, inplace = False);  type_as_10 = None
    matmul_21 = torch.matmul(dropout_10, transpose_52);  dropout_10 = None
    transpose_54 = matmul_21.transpose(1, 2);  matmul_21 = None
    contiguous_10 = transpose_54.contiguous();  transpose_54 = None
    view_45 = contiguous_10.view(getitem_61, -1, 512);  contiguous_10 = getitem_61 = None
    decoder_block_2_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "2").layer, "0").SelfAttention.o(view_45);  view_45 = None
    decoder_block_2_layer_0_dropout = getattr(getattr(self.decoder.block, "2").layer, "0").dropout(decoder_block_2_layer_0_self_attention_o);  decoder_block_2_layer_0_self_attention_o = None
    add_58 = add_55 + decoder_block_2_layer_0_dropout;  add_55 = decoder_block_2_layer_0_dropout = None
    getattr_68 = add_58.dtype
    eq_47 = getattr_68 == torch.float16;  getattr_68 = None
    size_22 = transpose_51.size()
    getitem_63 = size_22[2];  size_22 = None
    to_47 = add_58.to(torch.float32)
    pow_21 = to_47.pow(2);  to_47 = None
    mean_20 = pow_21.mean(-1, keepdim = True);  pow_21 = None
    add_59 = mean_20 + 1e-06;  mean_20 = None
    rsqrt_20 = torch.rsqrt(add_59);  add_59 = None
    mul_47 = add_58 * rsqrt_20;  rsqrt_20 = None
    decoder_block_2_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "2").layer, "1").layer_norm.weight
    getattr_69 = decoder_block_2_layer_1_layer_norm_weight.dtype
    eq_48 = getattr_69 == torch.float16;  getattr_69 = None
    getattr_70 = decoder_block_2_layer_1_layer_norm_weight.dtype
    to_48 = mul_47.to(getattr_70);  mul_47 = getattr_70 = None
    mul_48 = decoder_block_2_layer_1_layer_norm_weight * to_48;  decoder_block_2_layer_1_layer_norm_weight = to_48 = None
    size_23 = mul_48.size()
    getitem_64 = size_23[slice(None, 2, None)];  size_23 = None
    getitem_65 = getitem_64[0]
    getitem_66 = getitem_64[1];  getitem_64 = None
    size_24 = encoder_dropout_1.size()
    getitem_67 = size_24[1];  size_24 = None
    decoder_block_2_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.q(mul_48);  mul_48 = None
    view_46 = decoder_block_2_layer_1_enc_dec_attention_q.view(getitem_65, -1, 8, 64);  decoder_block_2_layer_1_enc_dec_attention_q = None
    transpose_55 = view_46.transpose(1, 2);  view_46 = None
    decoder_block_2_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_47 = decoder_block_2_layer_1_enc_dec_attention_k.view(getitem_65, -1, 8, 64);  decoder_block_2_layer_1_enc_dec_attention_k = None
    transpose_56 = view_47.transpose(1, 2);  view_47 = None
    decoder_block_2_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_48 = decoder_block_2_layer_1_enc_dec_attention_v.view(getitem_65, -1, 8, 64);  decoder_block_2_layer_1_enc_dec_attention_v = None
    transpose_57 = view_48.transpose(1, 2);  view_48 = None
    transpose_58 = transpose_56.transpose(3, 2)
    matmul_22 = torch.matmul(transpose_55, transpose_58);  transpose_55 = transpose_58 = None
    add_60 = matmul_22 + add_43;  matmul_22 = None
    float_14 = add_60.float()
    softmax_11 = torch.nn.functional.softmax(float_14, dim = -1, _stacklevel = 3, dtype = None);  float_14 = None
    type_as_11 = softmax_11.type_as(add_60);  softmax_11 = add_60 = None
    dropout_11 = torch.nn.functional.dropout(type_as_11, p = 0.1, training = False, inplace = False);  type_as_11 = None
    matmul_23 = torch.matmul(dropout_11, transpose_57);  dropout_11 = None
    transpose_59 = matmul_23.transpose(1, 2);  matmul_23 = None
    contiguous_11 = transpose_59.contiguous();  transpose_59 = None
    view_49 = contiguous_11.view(getitem_65, -1, 512);  contiguous_11 = getitem_65 = None
    decoder_block_2_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "2").layer, "1").EncDecAttention.o(view_49);  view_49 = None
    decoder_block_2_layer_1_dropout = getattr(getattr(self.decoder.block, "2").layer, "1").dropout(decoder_block_2_layer_1_enc_dec_attention_o);  decoder_block_2_layer_1_enc_dec_attention_o = None
    add_61 = add_58 + decoder_block_2_layer_1_dropout;  add_58 = decoder_block_2_layer_1_dropout = None
    getattr_71 = add_61.dtype
    eq_49 = getattr_71 == torch.float16;  getattr_71 = None
    to_49 = add_61.to(torch.float32)
    pow_22 = to_49.pow(2);  to_49 = None
    mean_21 = pow_22.mean(-1, keepdim = True);  pow_22 = None
    add_62 = mean_21 + 1e-06;  mean_21 = None
    rsqrt_21 = torch.rsqrt(add_62);  add_62 = None
    mul_49 = add_61 * rsqrt_21;  rsqrt_21 = None
    decoder_block_2_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "2").layer, "2").layer_norm.weight
    getattr_72 = decoder_block_2_layer_2_layer_norm_weight.dtype
    eq_50 = getattr_72 == torch.float16;  getattr_72 = None
    getattr_73 = decoder_block_2_layer_2_layer_norm_weight.dtype
    to_50 = mul_49.to(getattr_73);  mul_49 = getattr_73 = None
    mul_50 = decoder_block_2_layer_2_layer_norm_weight * to_50;  decoder_block_2_layer_2_layer_norm_weight = to_50 = None
    decoder_block_2_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.wo.weight
    linear1_8 = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.wi
    linear_layer_triton_wrapper_8 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_50, linear1_8, activation = 'relu');  mul_50 = linear1_8 = None
    dropout_26 = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.dropout(linear_layer_triton_wrapper_8);  linear_layer_triton_wrapper_8 = None
    linear2_8 = getattr(getattr(self.decoder.block, "2").layer, "2").DenseReluDense.wo(dropout_26);  dropout_26 = None
    decoder_block_2_layer_2_dropout = getattr(getattr(self.decoder.block, "2").layer, "2").dropout(linear2_8);  linear2_8 = None
    add_63 = add_61 + decoder_block_2_layer_2_dropout;  add_61 = decoder_block_2_layer_2_dropout = None
    getattr_74 = add_63.dtype
    eq_51 = getattr_74 == torch.float16;  getattr_74 = None
    to_51 = add_63.to(torch.float32)
    pow_23 = to_51.pow(2);  to_51 = None
    mean_22 = pow_23.mean(-1, keepdim = True);  pow_23 = None
    add_64 = mean_22 + 1e-06;  mean_22 = None
    rsqrt_22 = torch.rsqrt(add_64);  add_64 = None
    mul_51 = add_63 * rsqrt_22;  rsqrt_22 = None
    decoder_block_3_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "3").layer, "0").layer_norm.weight
    getattr_75 = decoder_block_3_layer_0_layer_norm_weight.dtype
    eq_52 = getattr_75 == torch.float16;  getattr_75 = None
    getattr_76 = decoder_block_3_layer_0_layer_norm_weight.dtype
    to_52 = mul_51.to(getattr_76);  mul_51 = getattr_76 = None
    mul_52 = decoder_block_3_layer_0_layer_norm_weight * to_52;  decoder_block_3_layer_0_layer_norm_weight = to_52 = None
    size_25 = mul_52.size()
    getitem_68 = size_25[slice(None, 2, None)];  size_25 = None
    getitem_69 = getitem_68[0]
    getitem_70 = getitem_68[1];  getitem_68 = None
    decoder_block_3_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.q(mul_52)
    view_50 = decoder_block_3_layer_0_self_attention_q.view(getitem_69, -1, 8, 64);  decoder_block_3_layer_0_self_attention_q = None
    transpose_60 = view_50.transpose(1, 2);  view_50 = None
    decoder_block_3_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.k(mul_52)
    view_51 = decoder_block_3_layer_0_self_attention_k.view(getitem_69, -1, 8, 64);  decoder_block_3_layer_0_self_attention_k = None
    transpose_61 = view_51.transpose(1, 2);  view_51 = None
    decoder_block_3_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.v(mul_52);  mul_52 = None
    view_52 = decoder_block_3_layer_0_self_attention_v.view(getitem_69, -1, 8, 64);  decoder_block_3_layer_0_self_attention_v = None
    transpose_62 = view_52.transpose(1, 2);  view_52 = None
    transpose_63 = transpose_61.transpose(3, 2)
    matmul_24 = torch.matmul(transpose_60, transpose_63);  transpose_60 = transpose_63 = None
    add_65 = matmul_24 + add_39;  matmul_24 = None
    float_15 = add_65.float()
    softmax_12 = torch.nn.functional.softmax(float_15, dim = -1, _stacklevel = 3, dtype = None);  float_15 = None
    type_as_12 = softmax_12.type_as(add_65);  softmax_12 = add_65 = None
    dropout_12 = torch.nn.functional.dropout(type_as_12, p = 0.1, training = False, inplace = False);  type_as_12 = None
    matmul_25 = torch.matmul(dropout_12, transpose_62);  dropout_12 = None
    transpose_64 = matmul_25.transpose(1, 2);  matmul_25 = None
    contiguous_12 = transpose_64.contiguous();  transpose_64 = None
    view_53 = contiguous_12.view(getitem_69, -1, 512);  contiguous_12 = getitem_69 = None
    decoder_block_3_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "3").layer, "0").SelfAttention.o(view_53);  view_53 = None
    decoder_block_3_layer_0_dropout = getattr(getattr(self.decoder.block, "3").layer, "0").dropout(decoder_block_3_layer_0_self_attention_o);  decoder_block_3_layer_0_self_attention_o = None
    add_66 = add_63 + decoder_block_3_layer_0_dropout;  add_63 = decoder_block_3_layer_0_dropout = None
    getattr_77 = add_66.dtype
    eq_53 = getattr_77 == torch.float16;  getattr_77 = None
    size_26 = transpose_61.size()
    getitem_71 = size_26[2];  size_26 = None
    to_53 = add_66.to(torch.float32)
    pow_24 = to_53.pow(2);  to_53 = None
    mean_23 = pow_24.mean(-1, keepdim = True);  pow_24 = None
    add_67 = mean_23 + 1e-06;  mean_23 = None
    rsqrt_23 = torch.rsqrt(add_67);  add_67 = None
    mul_53 = add_66 * rsqrt_23;  rsqrt_23 = None
    decoder_block_3_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "3").layer, "1").layer_norm.weight
    getattr_78 = decoder_block_3_layer_1_layer_norm_weight.dtype
    eq_54 = getattr_78 == torch.float16;  getattr_78 = None
    getattr_79 = decoder_block_3_layer_1_layer_norm_weight.dtype
    to_54 = mul_53.to(getattr_79);  mul_53 = getattr_79 = None
    mul_54 = decoder_block_3_layer_1_layer_norm_weight * to_54;  decoder_block_3_layer_1_layer_norm_weight = to_54 = None
    size_27 = mul_54.size()
    getitem_72 = size_27[slice(None, 2, None)];  size_27 = None
    getitem_73 = getitem_72[0]
    getitem_74 = getitem_72[1];  getitem_72 = None
    size_28 = encoder_dropout_1.size()
    getitem_75 = size_28[1];  size_28 = None
    decoder_block_3_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.q(mul_54);  mul_54 = None
    view_54 = decoder_block_3_layer_1_enc_dec_attention_q.view(getitem_73, -1, 8, 64);  decoder_block_3_layer_1_enc_dec_attention_q = None
    transpose_65 = view_54.transpose(1, 2);  view_54 = None
    decoder_block_3_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_55 = decoder_block_3_layer_1_enc_dec_attention_k.view(getitem_73, -1, 8, 64);  decoder_block_3_layer_1_enc_dec_attention_k = None
    transpose_66 = view_55.transpose(1, 2);  view_55 = None
    decoder_block_3_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_56 = decoder_block_3_layer_1_enc_dec_attention_v.view(getitem_73, -1, 8, 64);  decoder_block_3_layer_1_enc_dec_attention_v = None
    transpose_67 = view_56.transpose(1, 2);  view_56 = None
    transpose_68 = transpose_66.transpose(3, 2)
    matmul_26 = torch.matmul(transpose_65, transpose_68);  transpose_65 = transpose_68 = None
    add_68 = matmul_26 + add_43;  matmul_26 = None
    float_16 = add_68.float()
    softmax_13 = torch.nn.functional.softmax(float_16, dim = -1, _stacklevel = 3, dtype = None);  float_16 = None
    type_as_13 = softmax_13.type_as(add_68);  softmax_13 = add_68 = None
    dropout_13 = torch.nn.functional.dropout(type_as_13, p = 0.1, training = False, inplace = False);  type_as_13 = None
    matmul_27 = torch.matmul(dropout_13, transpose_67);  dropout_13 = None
    transpose_69 = matmul_27.transpose(1, 2);  matmul_27 = None
    contiguous_13 = transpose_69.contiguous();  transpose_69 = None
    view_57 = contiguous_13.view(getitem_73, -1, 512);  contiguous_13 = getitem_73 = None
    decoder_block_3_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "3").layer, "1").EncDecAttention.o(view_57);  view_57 = None
    decoder_block_3_layer_1_dropout = getattr(getattr(self.decoder.block, "3").layer, "1").dropout(decoder_block_3_layer_1_enc_dec_attention_o);  decoder_block_3_layer_1_enc_dec_attention_o = None
    add_69 = add_66 + decoder_block_3_layer_1_dropout;  add_66 = decoder_block_3_layer_1_dropout = None
    getattr_80 = add_69.dtype
    eq_55 = getattr_80 == torch.float16;  getattr_80 = None
    to_55 = add_69.to(torch.float32)
    pow_25 = to_55.pow(2);  to_55 = None
    mean_24 = pow_25.mean(-1, keepdim = True);  pow_25 = None
    add_70 = mean_24 + 1e-06;  mean_24 = None
    rsqrt_24 = torch.rsqrt(add_70);  add_70 = None
    mul_55 = add_69 * rsqrt_24;  rsqrt_24 = None
    decoder_block_3_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "3").layer, "2").layer_norm.weight
    getattr_81 = decoder_block_3_layer_2_layer_norm_weight.dtype
    eq_56 = getattr_81 == torch.float16;  getattr_81 = None
    getattr_82 = decoder_block_3_layer_2_layer_norm_weight.dtype
    to_56 = mul_55.to(getattr_82);  mul_55 = getattr_82 = None
    mul_56 = decoder_block_3_layer_2_layer_norm_weight * to_56;  decoder_block_3_layer_2_layer_norm_weight = to_56 = None
    decoder_block_3_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.wo.weight
    linear1_9 = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.wi
    linear_layer_triton_wrapper_9 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_56, linear1_9, activation = 'relu');  mul_56 = linear1_9 = None
    dropout_27 = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.dropout(linear_layer_triton_wrapper_9);  linear_layer_triton_wrapper_9 = None
    linear2_9 = getattr(getattr(self.decoder.block, "3").layer, "2").DenseReluDense.wo(dropout_27);  dropout_27 = None
    decoder_block_3_layer_2_dropout = getattr(getattr(self.decoder.block, "3").layer, "2").dropout(linear2_9);  linear2_9 = None
    add_71 = add_69 + decoder_block_3_layer_2_dropout;  add_69 = decoder_block_3_layer_2_dropout = None
    getattr_83 = add_71.dtype
    eq_57 = getattr_83 == torch.float16;  getattr_83 = None
    to_57 = add_71.to(torch.float32)
    pow_26 = to_57.pow(2);  to_57 = None
    mean_25 = pow_26.mean(-1, keepdim = True);  pow_26 = None
    add_72 = mean_25 + 1e-06;  mean_25 = None
    rsqrt_25 = torch.rsqrt(add_72);  add_72 = None
    mul_57 = add_71 * rsqrt_25;  rsqrt_25 = None
    decoder_block_4_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "4").layer, "0").layer_norm.weight
    getattr_84 = decoder_block_4_layer_0_layer_norm_weight.dtype
    eq_58 = getattr_84 == torch.float16;  getattr_84 = None
    getattr_85 = decoder_block_4_layer_0_layer_norm_weight.dtype
    to_58 = mul_57.to(getattr_85);  mul_57 = getattr_85 = None
    mul_58 = decoder_block_4_layer_0_layer_norm_weight * to_58;  decoder_block_4_layer_0_layer_norm_weight = to_58 = None
    size_29 = mul_58.size()
    getitem_76 = size_29[slice(None, 2, None)];  size_29 = None
    getitem_77 = getitem_76[0]
    getitem_78 = getitem_76[1];  getitem_76 = None
    decoder_block_4_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.q(mul_58)
    view_58 = decoder_block_4_layer_0_self_attention_q.view(getitem_77, -1, 8, 64);  decoder_block_4_layer_0_self_attention_q = None
    transpose_70 = view_58.transpose(1, 2);  view_58 = None
    decoder_block_4_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.k(mul_58)
    view_59 = decoder_block_4_layer_0_self_attention_k.view(getitem_77, -1, 8, 64);  decoder_block_4_layer_0_self_attention_k = None
    transpose_71 = view_59.transpose(1, 2);  view_59 = None
    decoder_block_4_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.v(mul_58);  mul_58 = None
    view_60 = decoder_block_4_layer_0_self_attention_v.view(getitem_77, -1, 8, 64);  decoder_block_4_layer_0_self_attention_v = None
    transpose_72 = view_60.transpose(1, 2);  view_60 = None
    transpose_73 = transpose_71.transpose(3, 2)
    matmul_28 = torch.matmul(transpose_70, transpose_73);  transpose_70 = transpose_73 = None
    add_73 = matmul_28 + add_39;  matmul_28 = None
    float_17 = add_73.float()
    softmax_14 = torch.nn.functional.softmax(float_17, dim = -1, _stacklevel = 3, dtype = None);  float_17 = None
    type_as_14 = softmax_14.type_as(add_73);  softmax_14 = add_73 = None
    dropout_14 = torch.nn.functional.dropout(type_as_14, p = 0.1, training = False, inplace = False);  type_as_14 = None
    matmul_29 = torch.matmul(dropout_14, transpose_72);  dropout_14 = None
    transpose_74 = matmul_29.transpose(1, 2);  matmul_29 = None
    contiguous_14 = transpose_74.contiguous();  transpose_74 = None
    view_61 = contiguous_14.view(getitem_77, -1, 512);  contiguous_14 = getitem_77 = None
    decoder_block_4_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "4").layer, "0").SelfAttention.o(view_61);  view_61 = None
    decoder_block_4_layer_0_dropout = getattr(getattr(self.decoder.block, "4").layer, "0").dropout(decoder_block_4_layer_0_self_attention_o);  decoder_block_4_layer_0_self_attention_o = None
    add_74 = add_71 + decoder_block_4_layer_0_dropout;  add_71 = decoder_block_4_layer_0_dropout = None
    getattr_86 = add_74.dtype
    eq_59 = getattr_86 == torch.float16;  getattr_86 = None
    size_30 = transpose_71.size()
    getitem_79 = size_30[2];  size_30 = None
    to_59 = add_74.to(torch.float32)
    pow_27 = to_59.pow(2);  to_59 = None
    mean_26 = pow_27.mean(-1, keepdim = True);  pow_27 = None
    add_75 = mean_26 + 1e-06;  mean_26 = None
    rsqrt_26 = torch.rsqrt(add_75);  add_75 = None
    mul_59 = add_74 * rsqrt_26;  rsqrt_26 = None
    decoder_block_4_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "4").layer, "1").layer_norm.weight
    getattr_87 = decoder_block_4_layer_1_layer_norm_weight.dtype
    eq_60 = getattr_87 == torch.float16;  getattr_87 = None
    getattr_88 = decoder_block_4_layer_1_layer_norm_weight.dtype
    to_60 = mul_59.to(getattr_88);  mul_59 = getattr_88 = None
    mul_60 = decoder_block_4_layer_1_layer_norm_weight * to_60;  decoder_block_4_layer_1_layer_norm_weight = to_60 = None
    size_31 = mul_60.size()
    getitem_80 = size_31[slice(None, 2, None)];  size_31 = None
    getitem_81 = getitem_80[0]
    getitem_82 = getitem_80[1];  getitem_80 = None
    size_32 = encoder_dropout_1.size()
    getitem_83 = size_32[1];  size_32 = None
    decoder_block_4_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.q(mul_60);  mul_60 = None
    view_62 = decoder_block_4_layer_1_enc_dec_attention_q.view(getitem_81, -1, 8, 64);  decoder_block_4_layer_1_enc_dec_attention_q = None
    transpose_75 = view_62.transpose(1, 2);  view_62 = None
    decoder_block_4_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_63 = decoder_block_4_layer_1_enc_dec_attention_k.view(getitem_81, -1, 8, 64);  decoder_block_4_layer_1_enc_dec_attention_k = None
    transpose_76 = view_63.transpose(1, 2);  view_63 = None
    decoder_block_4_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_64 = decoder_block_4_layer_1_enc_dec_attention_v.view(getitem_81, -1, 8, 64);  decoder_block_4_layer_1_enc_dec_attention_v = None
    transpose_77 = view_64.transpose(1, 2);  view_64 = None
    transpose_78 = transpose_76.transpose(3, 2)
    matmul_30 = torch.matmul(transpose_75, transpose_78);  transpose_75 = transpose_78 = None
    add_76 = matmul_30 + add_43;  matmul_30 = None
    float_18 = add_76.float()
    softmax_15 = torch.nn.functional.softmax(float_18, dim = -1, _stacklevel = 3, dtype = None);  float_18 = None
    type_as_15 = softmax_15.type_as(add_76);  softmax_15 = add_76 = None
    dropout_15 = torch.nn.functional.dropout(type_as_15, p = 0.1, training = False, inplace = False);  type_as_15 = None
    matmul_31 = torch.matmul(dropout_15, transpose_77);  dropout_15 = None
    transpose_79 = matmul_31.transpose(1, 2);  matmul_31 = None
    contiguous_15 = transpose_79.contiguous();  transpose_79 = None
    view_65 = contiguous_15.view(getitem_81, -1, 512);  contiguous_15 = getitem_81 = None
    decoder_block_4_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "4").layer, "1").EncDecAttention.o(view_65);  view_65 = None
    decoder_block_4_layer_1_dropout = getattr(getattr(self.decoder.block, "4").layer, "1").dropout(decoder_block_4_layer_1_enc_dec_attention_o);  decoder_block_4_layer_1_enc_dec_attention_o = None
    add_77 = add_74 + decoder_block_4_layer_1_dropout;  add_74 = decoder_block_4_layer_1_dropout = None
    getattr_89 = add_77.dtype
    eq_61 = getattr_89 == torch.float16;  getattr_89 = None
    to_61 = add_77.to(torch.float32)
    pow_28 = to_61.pow(2);  to_61 = None
    mean_27 = pow_28.mean(-1, keepdim = True);  pow_28 = None
    add_78 = mean_27 + 1e-06;  mean_27 = None
    rsqrt_27 = torch.rsqrt(add_78);  add_78 = None
    mul_61 = add_77 * rsqrt_27;  rsqrt_27 = None
    decoder_block_4_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "4").layer, "2").layer_norm.weight
    getattr_90 = decoder_block_4_layer_2_layer_norm_weight.dtype
    eq_62 = getattr_90 == torch.float16;  getattr_90 = None
    getattr_91 = decoder_block_4_layer_2_layer_norm_weight.dtype
    to_62 = mul_61.to(getattr_91);  mul_61 = getattr_91 = None
    mul_62 = decoder_block_4_layer_2_layer_norm_weight * to_62;  decoder_block_4_layer_2_layer_norm_weight = to_62 = None
    decoder_block_4_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.wo.weight
    linear1_10 = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.wi
    linear_layer_triton_wrapper_10 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_62, linear1_10, activation = 'relu');  mul_62 = linear1_10 = None
    dropout_28 = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.dropout(linear_layer_triton_wrapper_10);  linear_layer_triton_wrapper_10 = None
    linear2_10 = getattr(getattr(self.decoder.block, "4").layer, "2").DenseReluDense.wo(dropout_28);  dropout_28 = None
    decoder_block_4_layer_2_dropout = getattr(getattr(self.decoder.block, "4").layer, "2").dropout(linear2_10);  linear2_10 = None
    add_79 = add_77 + decoder_block_4_layer_2_dropout;  add_77 = decoder_block_4_layer_2_dropout = None
    getattr_92 = add_79.dtype
    eq_63 = getattr_92 == torch.float16;  getattr_92 = None
    to_63 = add_79.to(torch.float32)
    pow_29 = to_63.pow(2);  to_63 = None
    mean_28 = pow_29.mean(-1, keepdim = True);  pow_29 = None
    add_80 = mean_28 + 1e-06;  mean_28 = None
    rsqrt_28 = torch.rsqrt(add_80);  add_80 = None
    mul_63 = add_79 * rsqrt_28;  rsqrt_28 = None
    decoder_block_5_layer_0_layer_norm_weight = getattr(getattr(self.decoder.block, "5").layer, "0").layer_norm.weight
    getattr_93 = decoder_block_5_layer_0_layer_norm_weight.dtype
    eq_64 = getattr_93 == torch.float16;  getattr_93 = None
    getattr_94 = decoder_block_5_layer_0_layer_norm_weight.dtype
    to_64 = mul_63.to(getattr_94);  mul_63 = getattr_94 = None
    mul_64 = decoder_block_5_layer_0_layer_norm_weight * to_64;  decoder_block_5_layer_0_layer_norm_weight = to_64 = None
    size_33 = mul_64.size()
    getitem_84 = size_33[slice(None, 2, None)];  size_33 = None
    getitem_85 = getitem_84[0]
    getitem_86 = getitem_84[1];  getitem_84 = None
    decoder_block_5_layer_0_self_attention_q = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.q(mul_64)
    view_66 = decoder_block_5_layer_0_self_attention_q.view(getitem_85, -1, 8, 64);  decoder_block_5_layer_0_self_attention_q = None
    transpose_80 = view_66.transpose(1, 2);  view_66 = None
    decoder_block_5_layer_0_self_attention_k = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.k(mul_64)
    view_67 = decoder_block_5_layer_0_self_attention_k.view(getitem_85, -1, 8, 64);  decoder_block_5_layer_0_self_attention_k = None
    transpose_81 = view_67.transpose(1, 2);  view_67 = None
    decoder_block_5_layer_0_self_attention_v = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.v(mul_64);  mul_64 = None
    view_68 = decoder_block_5_layer_0_self_attention_v.view(getitem_85, -1, 8, 64);  decoder_block_5_layer_0_self_attention_v = None
    transpose_82 = view_68.transpose(1, 2);  view_68 = None
    transpose_83 = transpose_81.transpose(3, 2)
    matmul_32 = torch.matmul(transpose_80, transpose_83);  transpose_80 = transpose_83 = None
    add_81 = matmul_32 + add_39;  matmul_32 = add_39 = None
    float_19 = add_81.float()
    softmax_16 = torch.nn.functional.softmax(float_19, dim = -1, _stacklevel = 3, dtype = None);  float_19 = None
    type_as_16 = softmax_16.type_as(add_81);  softmax_16 = add_81 = None
    dropout_16 = torch.nn.functional.dropout(type_as_16, p = 0.1, training = False, inplace = False);  type_as_16 = None
    matmul_33 = torch.matmul(dropout_16, transpose_82);  dropout_16 = None
    transpose_84 = matmul_33.transpose(1, 2);  matmul_33 = None
    contiguous_16 = transpose_84.contiguous();  transpose_84 = None
    view_69 = contiguous_16.view(getitem_85, -1, 512);  contiguous_16 = getitem_85 = None
    decoder_block_5_layer_0_self_attention_o = getattr(getattr(self.decoder.block, "5").layer, "0").SelfAttention.o(view_69);  view_69 = None
    decoder_block_5_layer_0_dropout = getattr(getattr(self.decoder.block, "5").layer, "0").dropout(decoder_block_5_layer_0_self_attention_o);  decoder_block_5_layer_0_self_attention_o = None
    add_82 = add_79 + decoder_block_5_layer_0_dropout;  add_79 = decoder_block_5_layer_0_dropout = None
    getattr_95 = add_82.dtype
    eq_65 = getattr_95 == torch.float16;  getattr_95 = None
    size_34 = transpose_81.size()
    getitem_87 = size_34[2];  size_34 = None
    to_65 = add_82.to(torch.float32)
    pow_30 = to_65.pow(2);  to_65 = None
    mean_29 = pow_30.mean(-1, keepdim = True);  pow_30 = None
    add_83 = mean_29 + 1e-06;  mean_29 = None
    rsqrt_29 = torch.rsqrt(add_83);  add_83 = None
    mul_65 = add_82 * rsqrt_29;  rsqrt_29 = None
    decoder_block_5_layer_1_layer_norm_weight = getattr(getattr(self.decoder.block, "5").layer, "1").layer_norm.weight
    getattr_96 = decoder_block_5_layer_1_layer_norm_weight.dtype
    eq_66 = getattr_96 == torch.float16;  getattr_96 = None
    getattr_97 = decoder_block_5_layer_1_layer_norm_weight.dtype
    to_66 = mul_65.to(getattr_97);  mul_65 = getattr_97 = None
    mul_66 = decoder_block_5_layer_1_layer_norm_weight * to_66;  decoder_block_5_layer_1_layer_norm_weight = to_66 = None
    size_35 = mul_66.size()
    getitem_88 = size_35[slice(None, 2, None)];  size_35 = None
    getitem_89 = getitem_88[0]
    getitem_90 = getitem_88[1];  getitem_88 = None
    size_36 = encoder_dropout_1.size()
    getitem_91 = size_36[1];  size_36 = None
    decoder_block_5_layer_1_enc_dec_attention_q = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.q(mul_66);  mul_66 = None
    view_70 = decoder_block_5_layer_1_enc_dec_attention_q.view(getitem_89, -1, 8, 64);  decoder_block_5_layer_1_enc_dec_attention_q = None
    transpose_85 = view_70.transpose(1, 2);  view_70 = None
    decoder_block_5_layer_1_enc_dec_attention_k = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.k(encoder_dropout_1)
    view_71 = decoder_block_5_layer_1_enc_dec_attention_k.view(getitem_89, -1, 8, 64);  decoder_block_5_layer_1_enc_dec_attention_k = None
    transpose_86 = view_71.transpose(1, 2);  view_71 = None
    decoder_block_5_layer_1_enc_dec_attention_v = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.v(encoder_dropout_1)
    view_72 = decoder_block_5_layer_1_enc_dec_attention_v.view(getitem_89, -1, 8, 64);  decoder_block_5_layer_1_enc_dec_attention_v = None
    transpose_87 = view_72.transpose(1, 2);  view_72 = None
    transpose_88 = transpose_86.transpose(3, 2)
    matmul_34 = torch.matmul(transpose_85, transpose_88);  transpose_85 = transpose_88 = None
    add_84 = matmul_34 + add_43;  matmul_34 = add_43 = None
    float_20 = add_84.float()
    softmax_17 = torch.nn.functional.softmax(float_20, dim = -1, _stacklevel = 3, dtype = None);  float_20 = None
    type_as_17 = softmax_17.type_as(add_84);  softmax_17 = add_84 = None
    dropout_17 = torch.nn.functional.dropout(type_as_17, p = 0.1, training = False, inplace = False);  type_as_17 = None
    matmul_35 = torch.matmul(dropout_17, transpose_87);  dropout_17 = None
    transpose_89 = matmul_35.transpose(1, 2);  matmul_35 = None
    contiguous_17 = transpose_89.contiguous();  transpose_89 = None
    view_73 = contiguous_17.view(getitem_89, -1, 512);  contiguous_17 = getitem_89 = None
    decoder_block_5_layer_1_enc_dec_attention_o = getattr(getattr(self.decoder.block, "5").layer, "1").EncDecAttention.o(view_73);  view_73 = None
    decoder_block_5_layer_1_dropout = getattr(getattr(self.decoder.block, "5").layer, "1").dropout(decoder_block_5_layer_1_enc_dec_attention_o);  decoder_block_5_layer_1_enc_dec_attention_o = None
    add_85 = add_82 + decoder_block_5_layer_1_dropout;  add_82 = decoder_block_5_layer_1_dropout = None
    getattr_98 = add_85.dtype
    eq_67 = getattr_98 == torch.float16;  getattr_98 = None
    to_67 = add_85.to(torch.float32)
    pow_31 = to_67.pow(2);  to_67 = None
    mean_30 = pow_31.mean(-1, keepdim = True);  pow_31 = None
    add_86 = mean_30 + 1e-06;  mean_30 = None
    rsqrt_30 = torch.rsqrt(add_86);  add_86 = None
    mul_67 = add_85 * rsqrt_30;  rsqrt_30 = None
    decoder_block_5_layer_2_layer_norm_weight = getattr(getattr(self.decoder.block, "5").layer, "2").layer_norm.weight
    getattr_99 = decoder_block_5_layer_2_layer_norm_weight.dtype
    eq_68 = getattr_99 == torch.float16;  getattr_99 = None
    getattr_100 = decoder_block_5_layer_2_layer_norm_weight.dtype
    to_68 = mul_67.to(getattr_100);  mul_67 = getattr_100 = None
    mul_68 = decoder_block_5_layer_2_layer_norm_weight * to_68;  decoder_block_5_layer_2_layer_norm_weight = to_68 = None
    decoder_block_5_layer_2_dense_relu_dense_wo_weight = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.wo.weight
    linear1_11 = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.wi
    linear_layer_triton_wrapper_11 = src_patch_linear_layer_linear_layer_triton_wrapper(mul_68, linear1_11, activation = 'relu');  mul_68 = linear1_11 = None
    dropout_29 = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.dropout(linear_layer_triton_wrapper_11);  linear_layer_triton_wrapper_11 = None
    linear2_11 = getattr(getattr(self.decoder.block, "5").layer, "2").DenseReluDense.wo(dropout_29);  dropout_29 = None
    decoder_block_5_layer_2_dropout = getattr(getattr(self.decoder.block, "5").layer, "2").dropout(linear2_11);  linear2_11 = None
    add_87 = add_85 + decoder_block_5_layer_2_dropout;  add_85 = decoder_block_5_layer_2_dropout = None
    getattr_101 = add_87.dtype
    eq_69 = getattr_101 == torch.float16;  getattr_101 = None
    to_69 = add_87.to(torch.float32)
    pow_32 = to_69.pow(2);  to_69 = None
    mean_31 = pow_32.mean(-1, keepdim = True);  pow_32 = None
    add_88 = mean_31 + 1e-06;  mean_31 = None
    rsqrt_31 = torch.rsqrt(add_88);  add_88 = None
    mul_69 = add_87 * rsqrt_31;  add_87 = rsqrt_31 = None
    decoder_final_layer_norm_weight = self.decoder.final_layer_norm.weight
    getattr_102 = decoder_final_layer_norm_weight.dtype
    eq_70 = getattr_102 == torch.float16;  getattr_102 = None
    getattr_103 = decoder_final_layer_norm_weight.dtype
    to_70 = mul_69.to(getattr_103);  mul_69 = getattr_103 = None
    mul_70 = decoder_final_layer_norm_weight * to_70;  decoder_final_layer_norm_weight = to_70 = None
    decoder_dropout_1 = self.decoder.dropout(mul_70);  mul_70 = None
    mul_71 = decoder_dropout_1 * 0.04419417382415922;  decoder_dropout_1 = None
    lm_head = self.lm_head(mul_71);  mul_71 = None
    getattr_104 = lm_head.device
    to_71 = labels.to(getattr_104);  labels = getattr_104 = None
    size_37 = lm_head.size(-1)
    view_74 = lm_head.view(-1, size_37);  size_37 = None
    view_75 = to_71.view(-1);  to_71 = None
    crossentropyloss_0 = self.crossentropyloss_0(view_74, view_75);  view_74 = view_75 = None
    return {'loss': crossentropyloss_0, 'logits': lm_head, 'past_key_values': ((transpose_31, transpose_32, transpose_36, transpose_37), (transpose_41, transpose_42, transpose_46, transpose_47), (transpose_51, transpose_52, transpose_56, transpose_57), (transpose_61, transpose_62, transpose_66, transpose_67), (transpose_71, transpose_72, transpose_76, transpose_77), (transpose_81, transpose_82, transpose_86, transpose_87)), 'encoder_last_hidden_state': encoder_dropout_1}
    
